{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ee5de7-0e18-43c3-aac9-056533042c81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m use_multiprocessing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m num_processes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mt\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "from ecmwfapi import ECMWFDataServer\n",
    "from glob import glob\n",
    "from ecmwf.opendata import Client  #https://github.com/ecmwf/ecmwf-opendata/tree/main\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "use_multiprocessing = True\n",
    "num_processes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db872a07-bf79-4e28-9dde-7ad00f6f1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "global save_dir_base\n",
    "save_dir_base = f'/glade/derecho/scratch/klesinger/FD_RZSM_deep_learning/Data/raw_downloads/ECMWF'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b294f-8801-40f2-b258-6d6e1ac863da",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## Realtime date starting with 2020-01-02. This is because we are interested in getting data from 2000-2020 and ECMWF only goes back 20 years from the realtime date\n",
    "\n",
    "## We need to grab the previous 20 years from the realtime date. We will only grab the closest files once we have the data better organized (when compared to GEFSv12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93fc75-60c5-4b46-8655-da9cc1004866",
   "metadata": {},
   "source": [
    "# Now we have the dates which the GEFSv12 was initialized on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df8af6-d9d4-4fc6-8445-c6b8dc99a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'soilw_bgrnd'\n",
    "\n",
    "os.system(f'mkdir -p {var_name}')\n",
    "\n",
    "#To not flood the ECMWF portal with failed requests, I have saved the good model files into a text file\n",
    "\n",
    "txt_name = 'good_model_dates.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98077f-e758-49e0-a456-eee58c7d589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the hindcast date list\n",
    "\n",
    "# Define start and end dates (need data 20 years back and these are the most recent model runs)\n",
    "start_date = datetime(2015, 5, 14)\n",
    "end_date = datetime(2024, 2, 22)\n",
    "\n",
    "# Calculate the number of days between start and end dates\n",
    "delta = end_date - start_date\n",
    "\n",
    "# Create a list of all dates in the range\n",
    "hindcast_date_list = [pd.to_datetime(start_date + timedelta(days=i)) for i in range(delta.days + 1)]\n",
    "\n",
    "#Reverse the date list so that we get the most recent ones first\n",
    "hindcast_date_list.reverse()\n",
    "\n",
    "#Testing _date = hindcast_date_list[0]\n",
    "\n",
    "#Now only grab the dates that are on Monday or Thursday (according to website documentation)\n",
    "\n",
    "hindcast_date_list = [i for i in hindcast_date_list if i.dayofweek in [0, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb08268-7eba-472d-82c2-3f83752d1c8b",
   "metadata": {},
   "source": [
    "# This will begin downloading the most recent set of hindcasts from 2024 until the previous.\n",
    "\n",
    "## This will help to make sure that we get as many hindcasts as possible to eventually get the files to be as close as possible to the GEFSv12 hindcast dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090534dd-6fd2-44a7-8fd4-9f39dbfe019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the APIException class\n",
    "class APIException(Exception):\n",
    "    \"\"\"Custom exception class for API errors.\"\"\"\n",
    "    def __init__(self, message=\"An error occurred with the API\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b2af8-8674-41ec-8495-3f4d8c9ac2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_hdates(_date):\n",
    "    year_ = _date.year\n",
    "    \n",
    "    if (_date.month == 2) and (_date.day == 29):\n",
    "        '''Must move back one day because of the leap year'''\n",
    "        hdates = [f'{year_-i}-02-28' for i in range(1,21)]\n",
    "    else:\n",
    "        hdates = [f'{year_-i}-{_date.month:02}-{_date.day:02}' for i in range(1,21)]\n",
    "\n",
    "    return(hdates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c84a2-f523-4cd7-9bfd-c8d75d58773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have different leads seperated into 15 chunk slices\n",
    "def download_by_day_control_RZSM(_date):\n",
    "    print(f'\\nTrying FIRST Date {_date}')\n",
    "    #test \n",
    "    # _date = hindcast_date_list[0]\n",
    "    \n",
    "    dates_with_no_data = []\n",
    "    good_model_dates = []\n",
    "    \n",
    "    var_name = 'soilw_bgrnd'\n",
    "    \n",
    "    realization = 'control'\n",
    "\n",
    "    save_dir = f'{save_dir_base}/{var_name}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    \n",
    "    #Now get the previous 20 years of the date\n",
    "    #to not have to worry about the leap year, don't use time delta\n",
    "\n",
    "    hdates = return_hdates(_date)\n",
    "\n",
    "    for hdate in hdates:\n",
    "        # break\n",
    "        save_name = f'{save_dir}/{var_name}_{hdate}_{realization}.nc'\n",
    "        \n",
    "        if os.path.exists(save_name):\n",
    "            pass\n",
    "        else:\n",
    "            if hdate[5:] in dates_with_no_data:\n",
    "                break\n",
    "            else:\n",
    "                print(f'\\nTrying date {hdate}')\n",
    "                try:\n",
    "                    server = ECMWFDataServer()\n",
    "                    \n",
    "                    server.retrieve({\n",
    "                        \"class\": \"s2\",\n",
    "                        \"dataset\": \"s2s\",\n",
    "                        \"date\": f\"{_date.year}-{_date.month:02}-{_date.day:02}\",\n",
    "                        \"expver\": \"prod\",\n",
    "                        \"hdate\": hdate,\n",
    "                        \"levtype\": \"sfc\",\n",
    "                        \"model\": \"glob\",\n",
    "                        \"origin\": \"ecmf\",\n",
    "                        \"param\": \"228087\",\n",
    "                        \"step\": \"0-24/24-48/48-72/72-96/96-120/120-144/144-168/168-192/192-216/216-240/240-264/264-288/288-312/312-336/336-360/360-384/384-408/408-432/432-456/456-480/480-504/504-528/528-552/552-576/576-600/600-624/624-648/648-672/672-696/696-720/720-744/744-768/768-792/792-816/816-840/840-864/888-912/912-936/936-960/960-984/984-1008/1008-1032/1032-1056/1056-1080/1080-1104\",\n",
    "                        \"stream\": \"enfh\",\n",
    "                        \"time\": \"00:00:00\",\n",
    "                        \"type\": \"cf\",\n",
    "                        \"target\": save_name\n",
    "                    })\n",
    "                    good_model_dates.append(_date)\n",
    "                    \n",
    "                except APIException as e:\n",
    "                    print('Cannot download this file')\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                except Exception as e:\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                    pass\n",
    "                #This means that there is no data available for that date\n",
    "\n",
    "    if len(good_model_dates) ==0:\n",
    "        return()\n",
    "    else:\n",
    "        return(good_model_dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe8387-d1ac-4e22-8f71-aa3bbc7c35ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _date in hindcast_date_list:\n",
    "    download_by_day_control_RZSM(_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc338b-20a6-4455-80cf-c5a371b94796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     if use_multiprocessing == True:\n",
    "#         p=Pool(num_processes)\n",
    "#         p.map(download_by_day_control_RZSM, hindcast_date_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3521d-b382-4fa8-a21a-50822df3c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have different leads seperated into 15 chunk slices\n",
    "def download_by_day_control_other_variables(_date):\n",
    "\n",
    "    #test \n",
    "    # _date = hindcast_date_list[0]\n",
    "    \n",
    "    dates_with_no_data = []\n",
    "    good_model_dates = []\n",
    "    \n",
    "    var_name = 'temp_pwat_dewpoint'\n",
    "    \n",
    "    realization = 'control'\n",
    "\n",
    "    save_dir = f'{save_dir_base}/{var_name}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    \n",
    "    #Now get the previous 20 years of the date\n",
    "    #to not have to worry about the leap year, don't use time delta\n",
    "\n",
    "    year_ = _date.year\n",
    "    \n",
    "    hdates = return_hdates(_date)\n",
    "\n",
    "    \n",
    "    for hdate in hdates:\n",
    "        # break\n",
    "        save_name = f'{save_dir}/{var_name}_{hdate}_{realization}.nc'\n",
    "        \n",
    "        if os.path.exists(save_name):\n",
    "            good_model_dates.append(_date)\n",
    "            pass\n",
    "        else:\n",
    "            if hdate[5:] in dates_with_no_data:\n",
    "                break\n",
    "            else:\n",
    "                print(f'\\nTrying date {hdate}')\n",
    "                try:\n",
    "                    server = ECMWFDataServer()\n",
    "                    \n",
    "                    server.retrieve({\n",
    "                        \"class\": \"s2\",\n",
    "                        \"dataset\": \"s2s\",\n",
    "                        \"date\": f\"{_date.year}-{_date.month:02}-{_date.day:02}\",\n",
    "                        \"expver\": \"prod\",\n",
    "                        \"hdate\": hdate,\n",
    "                        \"levtype\": \"sfc\",\n",
    "                        \"model\": \"glob\",\n",
    "                        \"origin\": \"ecmf\",\n",
    "                        \"param\": \"136/167/168\",\n",
    "                        \"step\": \"0-24/24-48/48-72/72-96/96-120/120-144/144-168/168-192/192-216/216-240/240-264/264-288/288-312/312-336/336-360/360-384/384-408/408-432/432-456/456-480/480-504/504-528/528-552/552-576/576-600/600-624/624-648/648-672/672-696/696-720/720-744/744-768/768-792/792-816/816-840/840-864/888-912/912-936/936-960/960-984/984-1008/1008-1032/1032-1056/1056-1080/1080-1104\",\n",
    "                        \"stream\": \"enfh\",\n",
    "                        \"time\": \"00:00:00\",\n",
    "                        \"type\": \"cf\",\n",
    "                        \"target\": save_name\n",
    "                    })\n",
    "                    good_model_dates.append(_date)\n",
    "                    \n",
    "                except APIException as e:\n",
    "                    print('Cannot download this file')\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                except Exception as e:\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                    pass\n",
    "                #This means that there is no data available for that date\n",
    "\n",
    "    if len(good_model_dates) ==0:\n",
    "        return()\n",
    "    else:\n",
    "        return(good_model_dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e6897-a831-43c6-a7aa-d0b50cafa25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _date in hindcast_date_list:\n",
    "    download_by_day_control_other_variables(_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38daf41-351c-43b7-b66d-c8950876456a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     if use_multiprocessing == True:\n",
    "#         p=Pool(num_processes)\n",
    "#         p.map(download_by_day_control_other_variables, hindcast_date_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39651bb-2307-4ef6-8b24-e6c1cfaf0adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have different leads seperated into 15 chunk slices\n",
    "def download_by_day_perturbed_realization_RZSM(_date):\n",
    "    var_name = 'soilw_bgrnd'\n",
    "\n",
    "    save_dir = f'{save_dir_base}/{var_name}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    dates_with_no_data = []\n",
    "    \n",
    "    #Now get the previous 20 years of the date\n",
    "    #to not have to worry about the leap year, don't use time delta\n",
    "\n",
    "    year_ = _date.year\n",
    "    \n",
    "    hdates = return_hdates(_date)\n",
    "\n",
    "    \n",
    "    for hdate in hdates:\n",
    "        # break\n",
    "        save_name = f'{save_dir}/{var_name}_{hdate}_perturbed.nc'\n",
    "        \n",
    "        if os.path.exists(save_name):\n",
    "            print('file exists')\n",
    "            pass\n",
    "        else:\n",
    "            if hdate[5:] in dates_with_no_data:\n",
    "                break\n",
    "            else:\n",
    "                print(f'\\nTrying date {hdate}')\n",
    "                try:\n",
    "                    server = ECMWFDataServer()\n",
    "                    \n",
    "                    server.retrieve({\n",
    "                        \"class\": \"s2\",\n",
    "                        \"dataset\": \"s2s\",\n",
    "                        \"date\": f\"{_date.year}-{_date.month:02}-{_date.day:02}\",\n",
    "                        \"expver\": \"prod\",\n",
    "                        \"hdate\": hdate,\n",
    "                        \"levtype\": \"sfc\",\n",
    "                        \"model\": \"glob\",\n",
    "                        \"origin\": \"ecmf\",\n",
    "                        \"param\": \"228087\",\n",
    "                        \"number\": \"1/2/3/4/5/6/7/8/9/10\",\n",
    "                        \"step\": \"0-24/24-48/48-72/72-96/96-120/120-144/144-168/168-192/192-216/216-240/240-264/264-288/288-312/312-336/336-360/360-384/384-408/408-432/432-456/456-480/480-504/504-528/528-552/552-576/576-600/600-624/624-648/648-672/672-696/696-720/720-744/744-768/768-792/792-816/816-840/840-864/888-912/912-936/936-960/960-984/984-1008/1008-1032/1032-1056/1056-1080/1080-1104\",\n",
    "                        \"stream\": \"enfh\",\n",
    "                        \"time\": \"00:00:00\",\n",
    "                        \"type\": \"pf\",\n",
    "                        \"target\": save_name\n",
    "                    })\n",
    "                except APIException as e:\n",
    "                    print('Cannot download this file')\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                except Exception as e:\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                    pass\n",
    "                    #This means that there is no data available for that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49d342-c00a-4010-b9f5-f17faf03e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _date in hindcast_date_list:\n",
    "    download_by_day_perturbed_realization_RZSM(_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f75d2c-6568-43e7-993c-40eb7686e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have different leads seperated into 15 chunk slices\n",
    "def download_by_day_perturbed_realization_other_variables(_date):\n",
    "    \n",
    "    var_name = 'temp_pwat_dewpoint'\n",
    "\n",
    "    save_dir = f'{save_dir_base}/{var_name}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    dates_with_no_data = []\n",
    "    \n",
    "    #Now get the previous 20 years of the date\n",
    "    #to not have to worry about the leap year, don't use time delta\n",
    "\n",
    "    year_ = _date.year\n",
    "    \n",
    "    hdates = return_hdates(_date)\n",
    "\n",
    "    for hdate in hdates:\n",
    "        # break\n",
    "        save_name = f'{save_dir}/{var_name}_{hdate}_perturbed.nc'\n",
    "        \n",
    "        if os.path.exists(save_name):\n",
    "            # print('file exists')\n",
    "            pass\n",
    "        else:\n",
    "            if hdate[5:] in dates_with_no_data:\n",
    "                break\n",
    "            else:\n",
    "                # print(f'\\nTrying date {hdate}')\n",
    "                try:\n",
    "                    server = ECMWFDataServer()\n",
    "                    \n",
    "                    server.retrieve({\n",
    "                        \"class\": \"s2\",\n",
    "                        \"dataset\": \"s2s\",\n",
    "                        \"date\": f\"{_date.year}-{_date.month:02}-{_date.day:02}\",\n",
    "                        \"expver\": \"prod\",\n",
    "                        \"hdate\": hdate,\n",
    "                        \"levtype\": \"sfc\",\n",
    "                        \"model\": \"glob\",\n",
    "                        \"origin\": \"ecmf\",\n",
    "                        \"param\": \"136/167/168\",\n",
    "                        \"number\": \"1/2/3/4/5/6/7/8/9/10\",\n",
    "                        \"step\": \"0-24/24-48/48-72/72-96/96-120/120-144/144-168/168-192/192-216/216-240/240-264/264-288/288-312/312-336/336-360/360-384/384-408/408-432/432-456/456-480/480-504/504-528/528-552/552-576/576-600/600-624/624-648/648-672/672-696/696-720/720-744/744-768/768-792/792-816/816-840/840-864/888-912/912-936/936-960/960-984/984-1008/1008-1032/1032-1056/1056-1080/1080-1104\",\n",
    "                        \"stream\": \"enfh\",\n",
    "                        \"time\": \"00:00:00\",\n",
    "                        \"type\": \"pf\",\n",
    "                        \"target\": save_name\n",
    "                    })\n",
    "                except APIException as e:\n",
    "                    print('Cannot download this file')\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                except Exception as e:\n",
    "                    dates_with_no_data.append(hdate[5:]) #Reduce the number of failed requests\n",
    "                    print(f'Not downloading anymore dates for {hdate}')\n",
    "                    pass\n",
    "                    #This means that there is no data available for that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a4367-9fbd-4f31-aaf1-6d5add22627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    if use_multiprocessing == True:\n",
    "        p=Pool(num_processes)\n",
    "        p.map(download_by_day_perturbed_realization_other_variables, hindcast_date_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b36b8-cb18-4ad2-b4e9-4241d96d8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _date in hindcast_date_list:\n",
    "#     download_by_day_perturbed_realization_other_variables(_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49eff4d-4d56-4a4d-965a-451bccb510c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf210gpu]",
   "language": "python",
   "name": "conda-env-tf210gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
