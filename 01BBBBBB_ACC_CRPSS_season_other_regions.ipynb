{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302f239-5aba-4164-8125-86df134c9bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mt\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from numpy import meshgrid\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter, LatitudeLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, TwoSlopeNorm\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from ridgeplot import ridgeplot\n",
    "import joypy\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import climpred\n",
    "from xclim import sdba\n",
    "from climpred.options import OPTIONS\n",
    "import json\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from matplotlib.lines import Line2D  # For custom legend entries\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.gridspec as gridspec\n",
    "import hydroeval as he\n",
    "import re\n",
    "\n",
    "from function import preprocessUtils as putils\n",
    "from function import masks\n",
    "from function import verifications\n",
    "from function import funs as f\n",
    "from function import conf\n",
    "from function import loadbias\n",
    "from function import quikplot as qp\n",
    "from function import dataLoad\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "global dim_order, region_name, test_year, leads_\n",
    "dim_order = conf.dim_order\n",
    "\n",
    "test_year = 2019\n",
    "leads_ = [6,13,20,27]\n",
    "\n",
    "dir = '/glade/work/klesinger/FD_RZSM_deep_learning'\n",
    "assert test_year == 2019, 'This is only the script for when the testing years are 2018-2019. Test year must = 2019.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de812b8-6c9d-4442-a28f-51a77786f8db",
   "metadata": {},
   "source": [
    "## This script only works if there is a single experiment done for china and australia\n",
    "### We are doing EX29 only\n",
    "### For both ECMWF and GEFSv12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22849d64-0a7b-42c5-874c-f0f8720c51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = 'china' #['australia','china']\n",
    "obs_source = 'ERA5' #['GLEAM','ERA5']\n",
    "\n",
    "if obs_source == 'ERA5':\n",
    "    soil_dir = conf.era_data\n",
    "elif obs_source == 'GLEAM':\n",
    "    soil_dir = conf.gleam_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3c50b-ae23-42d5-83d7-fb6d15d55902",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, mask_anom = masks.load_mask_vals(region_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f38e61-2f06-4ffc-baf6-999766e5d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global custom_names\n",
    "'''This is for the final plot for ACC and CRPS'''\n",
    "custom_names = {\n",
    "    'GEFSv12': 'GEFSv12','GEFSv12-BC': 'GEFSv12-BC', 'DL-DM_GEFSv12': 'DL-DM-GEFSv12','DL-DM_ECMWF': 'DL-DM-ECMWF',\n",
    "    'ECMWF':'ECMWF', 'ECMWF-BC':'ECMWF-BC',\n",
    "}\n",
    "\n",
    "        \n",
    "def return_name(name):\n",
    "    if 'XGBOOST' in name:\n",
    "        name_out = 'ML_NWP_OBS'\n",
    "    else:\n",
    "        name_out = name\n",
    "    custom_names = {name: name_out}\n",
    "\n",
    "    return(custom_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46ab7f-c07d-4455-a5f4-608adcf2b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing and validation dates only for the year 2019'''\n",
    "\n",
    "test_start = '2018-01-01'\n",
    "test_end = '2019-12-31'\n",
    "val_start = '2016-01-01'\n",
    "val_end = '2017-12-31'\n",
    "train_start  = '2000-01-01'\n",
    "\n",
    "\n",
    "'''Test subsets of obs, ecmwf raw, gefsv12 raw '''\n",
    "global obs_anomaly_SubX_format, baseline_gefs, baseline_ecmwf, var_OUT, template_testing_only\n",
    "obs_anomaly_SubX_format, baseline_gefs, baseline_ecmwf, var_OUT, template_testing_only = verifications.open_obs_and_baseline_files_multiple_leads(region_name, leads_, test_start, test_end, mask_anom, soil_dir)\n",
    "\n",
    "init_dates, dt_dates, only_testing_dates = dataLoad.return_init_and_testing_dates(region_name,test_start,test_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195a196-df73-4d68-b47a-bb2a3d41d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "global obs_original,obs_raw\n",
    "obs_original,obs_raw = dataLoad.load_rzsm_observations(soil_dir, region_name)\n",
    "obs_original[\"time\"] = obs_original[\"time\"].dt.floor(\"D\")\n",
    "obs_raw[\"time\"] = obs_raw[\"time\"].dt.floor(\"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a20f0-8be7-48d9-9ad8-f6ea300f6ff8",
   "metadata": {},
   "source": [
    "# Lineplot ACC and CRPS all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698a07f-8836-4613-bd8f-465faae51593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_lineplot_to_dataframe(df,fcst_vals,name_of_fcst, metric,week, mean_or_median):\n",
    "    # df = pd.DataFrame()\n",
    "    def return_color(name_of_fcst):\n",
    "        black = ['EX0','EX13'] # bias-corrected DL\n",
    "        red = ['EX14','EX15','EX16','EX17','EX22','EX23','EX24','EX25'] #Observation driven\n",
    "        blue = ['EX1','EX2','EX3','EX4','EX5','EX6','EX7','EX8','EX9','EX10','EX11','EX12',\n",
    "               'EX18','EX19','EX20','EX21','EX27','EX28','EX29'] #Hybrid\n",
    "\n",
    "        black2 = ['DM-BC_DL']\n",
    "        red2 = ['DL']\n",
    "        blue2 = ['DL-DM']\n",
    "        \n",
    "        green = ['ECMWF','GEFSv12']\n",
    "        \n",
    "        purple = 'GEFSv12-BC'\n",
    "\n",
    "        orange = 'ECMWF-BC'\n",
    "\n",
    "        yellow = 'EMOS'\n",
    "\n",
    "        if (name_of_fcst in black) or (name_of_fcst in black2):\n",
    "            color = 'black'\n",
    "        elif (name_of_fcst in red) or (name_of_fcst in red2):\n",
    "            color = 'red'\n",
    "        elif (name_of_fcst in blue) or (name_of_fcst in blue2):\n",
    "            color = 'blue'\n",
    "        elif name_of_fcst in green:\n",
    "            color = 'green'\n",
    "        elif purple in name_of_fcst:\n",
    "            color = 'purple'\n",
    "        elif yellow in name_of_fcst:\n",
    "            color = 'yellow'\n",
    "        elif orange in name_of_fcst:\n",
    "            color='orange'\n",
    "        return(color)\n",
    "\n",
    "    if week==10:\n",
    "        for idx,lead in enumerate([6,13,20,27]):\n",
    "            if mean_or_median == 'mean':\n",
    "                try:\n",
    "                    data = fcst_vals.sel(lead=lead).mean()[putils.xarray_varname(fcst_vals)].values\n",
    "                except KeyError:\n",
    "                    data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "            if mean_or_median == 'median':\n",
    "                try:\n",
    "                    data = fcst_vals.sel(lead=lead).median()[putils.xarray_varname(fcst_vals)].values\n",
    "                except AttributeError:\n",
    "                    data = np.nanmedian(fcst_vals[idx,:,:])\n",
    "            dict_ = {'Forecast':[name_of_fcst], 'Week':[idx+1], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "            df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    else:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.median()[putils.xarray_varname(fcst_vals)].values\n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[week], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "'''Only the single value for all the experiments'''\n",
    "\n",
    "def add_lineplot_to_dataframe_average(df,fcst_vals,name_of_fcst, metric,week, mean_or_median):\n",
    "    # df = pd.DataFrame()\n",
    "\n",
    "    def return_color(name_of_fcst):\n",
    "        black = ['DM-BC_DL']\n",
    "        red = ['DL']\n",
    "        blue = ['DL-DM_GEFSv12']\n",
    "        purple = ['DL-DM_ECMWF']\n",
    "        \n",
    "        green = ['ECMWF','GEFSv12']\n",
    "        \n",
    "\n",
    "        yellow = 'EMOS'\n",
    "\n",
    "        if name_of_fcst in black:\n",
    "            color = 'black'\n",
    "        elif name_of_fcst in red:\n",
    "            color = 'red'\n",
    "        elif name_of_fcst in blue:\n",
    "            color = 'blue'\n",
    "        elif name_of_fcst in green:\n",
    "            color = 'green'\n",
    "        elif name_of_fcst in purple:\n",
    "            color = 'purple'\n",
    "        elif name_of_fcst in yellow:\n",
    "            color = 'yellow'\n",
    "            \n",
    "        return(color)\n",
    "\n",
    "    if week==10:\n",
    "        for idx,lead in enumerate([6,13,20,27]):\n",
    "            if mean_or_median == 'mean':\n",
    "                data = fcst_vals.sel(lead=lead).mean()[putils.xarray_varname(fcst_vals)].values\n",
    "            elif mean_or_median == 'median':\n",
    "                try:\n",
    "                    data = fcst_vals.sel(lead=lead).median()[putils.xarray_varname(fcst_vals)].values\n",
    "                except AttributeError:\n",
    "                    data = np.nanmedian(fcst_vals[idx,:,:])\n",
    "            dict_ = {'Forecast':[name_of_fcst], 'Week':[idx+1], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "            df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    else:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.median()[putils.xarray_varname(fcst_vals)].values\n",
    "            \n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[week], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def add_lineplot_to_dataframe_average_by_week(df,fcst_vals,name_of_fcst, metric,week, mean_or_median, lead, idLead):\n",
    "    # df = pd.DataFrame()\n",
    "\n",
    "    # df = df_crps_djf\n",
    "    # fcst_vals = seasonal_crps[season]\n",
    "    # name_of_fcst = name\n",
    "    # metric = 'CRPSS'\n",
    "    # week = 10\n",
    "    # mean_or_median = 'median'\n",
    "    # lead=day_num\n",
    "    # idLead = idLead\n",
    "    \n",
    "    def return_color(name_of_fcst):\n",
    "        black = ['DM-BC_DL']\n",
    "        red = ['DL']\n",
    "        blue = ['DL-DM_GEFSv12']\n",
    "        purple = ['DL-DM_ECMWF']\n",
    "        \n",
    "        green = ['ECMWF','GEFSv12']\n",
    "\n",
    "\n",
    "        yellow = 'EMOS'\n",
    "\n",
    "        if name_of_fcst in black:\n",
    "            color = 'black'\n",
    "        elif name_of_fcst in red:\n",
    "            color = 'red'\n",
    "        elif name_of_fcst in blue:\n",
    "            color = 'blue'\n",
    "        elif name_of_fcst in green:\n",
    "            color = 'green'\n",
    "        elif name_of_fcst in purple:\n",
    "            color = 'purple'\n",
    "        elif name_of_fcst in yellow:\n",
    "            color = 'yellow'\n",
    "            \n",
    "        return(color)\n",
    "\n",
    "    if week==10:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.sel(lead=lead).mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.sel(lead=lead).median()\n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[idLead+1], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        try:\n",
    "            df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "        except TypeError:\n",
    "            dict_ = {'Forecast':[name_of_fcst], 'Week':[idLead+1], f'{metric}': [data[putils.xarray_varname(data)].values], 'Color':return_color(name_of_fcst)}\n",
    "            df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "            \n",
    "    else:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.median()[putils.xarray_varname(fcst_vals)].values\n",
    "            \n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[week], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fa9e0-a53c-4795-b982-17ed6d4ee491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_UNET_experiments(correct_experiments, obs_source):\n",
    "    only_RZSM = [j for j in correct_experiments if 'RZSM' in j] \n",
    "    only_ensemble= [j for j in only_RZSM if 'final' not in j]\n",
    "    only_ensemble = [j for j in only_ensemble if 'Residual' not in j]\n",
    "    only_2019 = [j for j in only_ensemble if '2012' not in j]\n",
    "    if obs_source == 'GLEAM':\n",
    "        only_2019 = [j for j in only_ensemble if 'ERA5' not in j]\n",
    "    elif obs_source == 'ERA5':\n",
    "        only_2019 = [j for j in only_ensemble if 'ERA5' in j]\n",
    "    return(only_2019)\n",
    "\n",
    "def common_UNET_no_regular_experiments(correct_experiments):\n",
    "    only_RZSM = [j for j in correct_experiments if 'RZSM' in j] \n",
    "    only_ensemble= [j for j in only_RZSM if 'final' not in j]\n",
    "    only_ensemble = [j for j in only_ensemble if 'Residual' not in j]\n",
    "    only_ensemble = [j for j in only_ensemble if 'regular' not in j]\n",
    "    only_2019 = [j for j in only_ensemble if '2012' not in j]\n",
    "    return(only_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d132f85-aaf4-45da-b083-4a79dfd8ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_files_by_ex_GEFS(file_list, color_list, week_,obs_source):\n",
    "    filtered_files = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        if obs_source== 'GLEAM':\n",
    "            match = re.search(rf'Wk{week_}_testing_EX(\\d+)_regular_RZSM', file)\n",
    "        elif obs_source == 'ERA5':\n",
    "            match = re.search(rf'Wk{week_}_testing_EX(\\d+)_regular_ERA5_RZSM', file)\n",
    "        if match:\n",
    "            ex_value = f\"EX{match.group(1)}\"\n",
    "            if ex_value in color_list:\n",
    "                filtered_files.append(file)\n",
    "    \n",
    "    return filtered_files\n",
    "\n",
    "def filter_files_by_ex_ECMWF(file_list, color_list, week_,obs_source):\n",
    "    filtered_files = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        if obs_source =='GLEAM':\n",
    "            match = re.search(rf'Wk{week_}_testing_EX(\\d+)_ECMWF_regular_RZSM', file)\n",
    "        elif obs_source == 'ERA5':\n",
    "            match = re.search(rf'Wk{week_}_testing_EX(\\d+)_ECMWF_regular_ERA5_RZSM', file)\n",
    "        if match:\n",
    "            ex_value = f\"EX{match.group(1)}\"\n",
    "            if ex_value in color_list:\n",
    "                filtered_files.append(file)\n",
    "    \n",
    "    return filtered_files\n",
    "\n",
    "def return_file_list_by_category(region_name, week_,obs_source):\n",
    "    black = ['EX0','EX13']\n",
    "    red = ['EX14','EX15','EX16','EX17','EX22','EX23','EX24','EX25']\n",
    "    blue = ['EX1','EX2','EX3','EX4','EX5','EX6','EX7','EX8','EX9','EX10','EX11','EX12',\n",
    "           'EX18','EX19','EX20','EX21','EX27','EX28','EX29']\n",
    "    \n",
    "    unet_files = sorted(glob(f'predictions/{region_name}/Wk{week_}_testing/*')) #With a specific subset of data\n",
    "    #First find the correct experiments\n",
    "    bias_correction_black_G = filter_files_by_ex_GEFS(unet_files, black, week_,obs_source)\n",
    "    hybrid_blue_G = filter_files_by_ex_GEFS(unet_files, blue, week_,obs_source)\n",
    "    obs_red_G = filter_files_by_ex_GEFS(unet_files, red, week_,obs_source)\n",
    "\n",
    "    bias_correction_black_E = filter_files_by_ex_ECMWF(unet_files, black, week_,obs_source)\n",
    "    hybrid_blue_E = filter_files_by_ex_ECMWF(unet_files, blue, week_,obs_source)\n",
    "    obs_red_E = filter_files_by_ex_ECMWF(unet_files, red, week_,obs_source)\n",
    "    \n",
    "    return bias_correction_black_G, hybrid_blue_G, obs_red_G, bias_correction_black_E, hybrid_blue_E, obs_red_E\n",
    "\n",
    "\n",
    "def create_empty_array(ecmwf_acc, day_num):\n",
    "    u_acc = ecmwf_acc.sel(lead=day_num).copy(deep=True)\n",
    "    u_crps = ecmwf_acc.sel(lead=day_num).copy(deep=True)\n",
    "    u_acc[putils.xarray_varname(u_acc)][:,:] = 0\n",
    "    u_crps[putils.xarray_varname(u_crps)][:,:] = 0\n",
    "    return u_acc, u_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3048b-7449-43d1-8499-4481118fd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ACC_raw_forecast_all_seasons(obs_original, gefs, ecmwf):\n",
    "\n",
    "    df_acc_full = pd.DataFrame()\n",
    "    df_crps_full = pd.DataFrame()\n",
    "    \n",
    "    gefs_acc = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(gefs), verifications.rename_obs_for_climpred(obs_original))\n",
    "    df_acc_full = add_lineplot_to_dataframe(df_acc_full,gefs_acc,'GEFSv12', 'ACC',10, 'mean') #Just keep the name the same for later\n",
    "\n",
    "    ecmwf_acc = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(ecmwf), verifications.rename_obs_for_climpred(obs_original))\n",
    "    df_acc_full = add_lineplot_to_dataframe(df_acc_full,gefs_acc,'ECMWF', 'ACC',10, 'mean') #Just keep the name the same for later\n",
    "\n",
    "    gefs_crpss = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(gefs), verifications.rename_obs_for_climpred(obs_original))\n",
    "    df_crps_full = add_lineplot_to_dataframe(df_crps_full,gefs_crpss,'GEFSv12', 'CRPSS',10, 'median') #Just keep the name the same for later\n",
    "    \n",
    "    ecmwf_crpss = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(ecmwf), verifications.rename_obs_for_climpred(obs_original))\n",
    "    df_crps_full = add_lineplot_to_dataframe(df_crps_full,gefs_crpss,'ECMWF', 'CRPSS',10, 'median') #Just keep the name the same for later\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return df_acc_full, df_crps_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbade56a-fd71-4bf9-8471-923bdc06620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_ACC_raw_forecast_split_seasons(obs_original, gefs, ecmwf):\n",
    "    df_acc_djf = pd.DataFrame()\n",
    "    df_acc_mam = pd.DataFrame()\n",
    "    df_acc_jja = pd.DataFrame()\n",
    "    df_acc_son = pd.DataFrame()\n",
    "    \n",
    "    df_crps_djf = pd.DataFrame()\n",
    "    df_crps_mam = pd.DataFrame()\n",
    "    df_crps_jja = pd.DataFrame()\n",
    "    df_crps_son = pd.DataFrame()\n",
    "\n",
    "    \n",
    "\n",
    "    seasons = {\n",
    "        \"DJF\": [12, 1, 2],  # Winter\n",
    "        \"MAM\": [3, 4, 5],   # Spring\n",
    "        \"JJA\": [6, 7, 8],   # Summer\n",
    "        \"SON\": [9, 10, 11]  # Fall\n",
    "    }\n",
    "\n",
    "    for season, months in seasons.items():\n",
    "        # break\n",
    "        # Filter datasets for the current season\n",
    "        obs_season = obs_original\n",
    "        gefs_season = gefs.sel(S=gefs['S'].dt.month.isin(months))\n",
    "        ecmwf_season = ecmwf.sel(S=ecmwf['S'].dt.month.isin(months))\n",
    "\n",
    "        # Compute ACC and CRPSS for the season\n",
    "        gefs_acc = verifications.create_climpred_ACC(\n",
    "            verifications.rename_subx_for_climpred(gefs_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "        ecmwf_acc = verifications.create_climpred_ACC(\n",
    "            verifications.rename_subx_for_climpred(ecmwf_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "\n",
    "        gefs_crps = verifications.create_climpred_CRPSS(\n",
    "            verifications.rename_subx_for_climpred(gefs_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "        ecmwf_crps = verifications.create_climpred_CRPSS(\n",
    "            verifications.rename_subx_for_climpred(ecmwf_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "\n",
    "\n",
    "        if season == 'DJF':\n",
    "            # Store results in DataFrame\n",
    "            df_acc_djf = add_lineplot_to_dataframe(df_acc_djf, gefs_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_acc_djf = add_lineplot_to_dataframe(df_acc_djf, ecmwf_acc, 'ECMWF', f'ACC', 10, 'mean')\n",
    "            df_crps_djf = add_lineplot_to_dataframe(df_crps_djf, gefs_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "            df_crps_djf = add_lineplot_to_dataframe(df_crps_djf, ecmwf_crps, 'ECMWF', f'CRPSS', 10, 'median')\n",
    "        elif season == 'MAM':\n",
    "            df_acc_mam = add_lineplot_to_dataframe(df_acc_mam, gefs_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_acc_mam = add_lineplot_to_dataframe(df_acc_mam, ecmwf_acc, 'ECMWF', f'ACC', 10, 'mean')\n",
    "            df_crps_mam = add_lineplot_to_dataframe(df_crps_mam, gefs_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "            df_crps_mam = add_lineplot_to_dataframe(df_crps_mam, ecmwf_crps, 'ECMWF', f'CRPSS', 10, 'median')\n",
    "        elif season == 'JJA':            \n",
    "            df_acc_jja = add_lineplot_to_dataframe(df_acc_jja, gefs_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_acc_jja = add_lineplot_to_dataframe(df_acc_jja, ecmwf_acc, 'ECMWF', f'ACC', 10, 'mean')\n",
    "            df_crps_jja = add_lineplot_to_dataframe(df_crps_jja, gefs_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "            df_crps_jja = add_lineplot_to_dataframe(df_crps_jja, ecmwf_crps, 'ECMWF', f'CRPSS', 10, 'median')\n",
    "        elif season == 'SON':\n",
    "            df_acc_son = add_lineplot_to_dataframe(df_acc_son, gefs_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_acc_son = add_lineplot_to_dataframe(df_acc_son, ecmwf_acc, 'ECMWF', f'ACC', 10, 'mean')\n",
    "            df_crps_son = add_lineplot_to_dataframe(df_crps_son, gefs_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "            df_crps_son = add_lineplot_to_dataframe(df_crps_son, ecmwf_crps, 'ECMWF', f'CRPSS', 10, 'median')\n",
    "               \n",
    "    return df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafc2ea-b26e-4e05-a0ec-31f65e292bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_UNET_combined(region_name, test_start, test_end, obs_original, df_acc_full, df_crps_full, template, df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son, df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son,leads,\n",
    "                         ecm_BC_djf, gef_BC_djf, ecm_BC_mam, gef_BC_mam, ecm_BC_jja, gef_BC_jja, ecm_BC_son, gef_BC_son,obs_source):\n",
    "    \n",
    "    # Define seasons\n",
    "    seasons = {\n",
    "        \"DJF\": [12, 1, 2],  # Winter\n",
    "        \"MAM\": [3, 4, 5],   # Spring\n",
    "        \"JJA\": [6, 7, 8],   # Summer\n",
    "        \"SON\": [9, 10, 11]  # Fall\n",
    "    }\n",
    "    \n",
    "    # Initialize all-season results\n",
    "    e_acc, e_crps = template.copy(deep=True), template.copy(deep=True)\n",
    "    e_crps = e_crps.rename({'acc':'crps'})\n",
    "    e_acc[putils.xarray_varname(e_acc)][:, :, :] = 0\n",
    "    e_crps[putils.xarray_varname(e_crps)][:, :, :] = 0\n",
    "    \n",
    "    # Initialize dictionaries to store seasonal results\n",
    "    seasonal_acc = {season: e_acc.copy(deep=True) for season in seasons}\n",
    "    seasonal_crps = {season: e_crps.copy(deep=True) for season in seasons}\n",
    "    \n",
    "    # Set initial values to zero for each season\n",
    "    for season in seasons:\n",
    "        seasonal_acc[season][putils.xarray_varname(e_acc)][:, :, :] = 0\n",
    "        seasonal_crps[season][putils.xarray_varname(e_crps)][:, :, :] = 0\n",
    "    \n",
    "    \n",
    "    obs_forecast_boolean = np.isnan(obs)\n",
    "    \n",
    "    #Add to a new gefs template for masking\n",
    "    obs_forecast_boolean2 = gefs.copy(deep=True)\n",
    "    obs_forecast_boolean2.RZSM[:,:,:,:,:] = obs_forecast_boolean[putils.xarray_varname(obs)]\n",
    "\n",
    "\n",
    "    lead_improvment_plots = {}\n",
    "    \n",
    "    for idLead, week_ in enumerate([1, 2, 3, 4]):\n",
    "        # break\n",
    "        \n",
    "        bias_correction_black_G, hybrid_blue_G, obs_red_G, bias_correction_black_E, hybrid_blue_E, obs_red_E  = return_file_list_by_category(region_name, week_,obs_source)\n",
    "        day_num = (week_ * 7) - 1  # Lead time in days\n",
    "    \n",
    "        for model, name in zip([bias_correction_black_G, hybrid_blue_G, obs_red_G, bias_correction_black_E, hybrid_blue_E, obs_red_E], ['DM-BC_DL_GEFSv12', 'DL-DM_GEFSv12', 'DL_GEFSv12','DM-BC_DL_ECMWF', 'DL-DM_ECMWF', 'DL_ECMWF']):\n",
    "\n",
    "            if len(model) !=0:\n",
    "                # break\n",
    "                print(f'Processing {name} for WEEK {week_}.')\n",
    "                u_acc, u_crps = e_acc.copy(deep=True).sel(lead=day_num), e_crps.copy(deep=True).sel(lead=day_num)\n",
    "        \n",
    "                new_source = 'ECMWF' if 'ECMWF' in model else 'GEFSv12'\n",
    "                test_name = model[0].split('testing_')[-1].split('.npy')[0]\n",
    "                \n",
    "                # Load forecast file\n",
    "                forecast = verifications.load_UNET_files(\n",
    "                    gefs=gefs, file=model[0], region_name=region_name, day_num=day_num, \n",
    "                    new_source=new_source, test_year=test_year\n",
    "                )\n",
    "                \n",
    "                # Apply land mask\n",
    "                forecast = forecast.where(obs_forecast_boolean2 == 0, np.nan)\n",
    "                \n",
    "                # Compute ACC and CRPS\n",
    "                unet_acc = verifications.create_climpred_ACC(\n",
    "                    verifications.rename_subx_for_climpred(forecast), \n",
    "                    verifications.rename_obs_for_climpred(obs_original)\n",
    "                ).sel(lead=day_num)\n",
    "    \n",
    "                unet_crps = verifications.create_climpred_CRPSS(\n",
    "                    verifications.rename_subx_for_climpred(forecast), \n",
    "                    verifications.rename_obs_for_climpred(obs_original)\n",
    "                ).sel(lead=day_num).mean(dim='init')\n",
    "\n",
    "        \n",
    "                # Reapply mask\n",
    "                mask = ~np.isnan(template[putils.xarray_varname(template)].sel(lead=day_num))\n",
    "                u_acc = xr.where(mask, unet_acc, np.nan)\n",
    "                u_crps = xr.where(mask, unet_crps, np.nan)\n",
    "        \n",
    "                # Add results to all-season DataFrame\n",
    "                df_acc_full = add_lineplot_to_dataframe_average(df_acc_full, u_acc, name, 'ACC', week_, 'mean')\n",
    "                df_crps_full = add_lineplot_to_dataframe_average(df_crps_full, u_crps, name, 'CRPSS', week_, 'median')\n",
    "        \n",
    "                # Load forecast file\n",
    "                forecast = verifications.load_UNET_files(\n",
    "                    gefs=gefs, file=model[0], region_name=region_name, day_num=day_num, \n",
    "                    new_source=new_source, test_year=test_year\n",
    "                )\n",
    "                \n",
    "                # Assign months\n",
    "                forecast['month'] = forecast['S'].dt.month\n",
    "\n",
    "                \n",
    "                # Process seasonal data\n",
    "                for season, months in seasons.items():\n",
    "                    # break\n",
    "                    \n",
    "                    lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = {} \n",
    "                    \n",
    "                    seasonal_forecast = forecast.where(forecast['month'].isin(months), drop=True)\n",
    "                    seasonal_obs = obs_original\n",
    "        \n",
    "                    # Compute seasonal ACC and CRPSS\n",
    "                    season_acc = verifications.create_climpred_ACC(\n",
    "                        verifications.rename_subx_for_climpred(seasonal_forecast),\n",
    "                        verifications.rename_obs_for_climpred(seasonal_obs)\n",
    "                    ).sel(lead=day_num)\n",
    "\n",
    "                    '''Add improvments'''\n",
    "                    if season == 'DJF':\n",
    "                        if 'GEFSv12' in name:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - gef_BC_djf.isel(lead=idLead)\n",
    "                        else:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - ecm_BC_djf.isel(lead=idLead)\n",
    "                            \n",
    "                    elif season == \"MAM\":\n",
    "                        if 'GEFSv12' in name:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - gef_BC_mam.isel(lead=idLead)\n",
    "                        else:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - ecm_BC_mam.isel(lead=idLead)\n",
    "                    elif season == \"JJA\":\n",
    "                        if 'GEFSv12' in name:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - gef_BC_jja.isel(lead=idLead)\n",
    "                        else:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - ecm_BC_jja.isel(lead=idLead)\n",
    "                    elif season == \"SON\":\n",
    "                        if 'GEFSv12' in name:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - gef_BC_son.isel(lead=idLead)\n",
    "                        else:\n",
    "                            lead_improvment_plots[f'{name}_lead{week_}_season{season}'] = season_acc - ecm_BC_son.isel(lead=idLead)            \n",
    "                    \n",
    "                    season_crps = verifications.create_climpred_CRPSS(\n",
    "                        verifications.rename_subx_for_climpred(seasonal_forecast),\n",
    "                        verifications.rename_obs_for_climpred(seasonal_obs)\n",
    "                    ).sel(lead=day_num).mean(dim='init')\n",
    "    \n",
    "                    # Store seasonal results\n",
    "                    seasonal_acc[season][putils.xarray_varname(seasonal_acc[season])][idLead,:,:] = season_acc[putils.xarray_varname(season_acc)]\n",
    "                    seasonal_crps[season][putils.xarray_varname(seasonal_crps[season])][idLead,:,:]  = season_crps[putils.xarray_varname(season_crps)]\n",
    "    \n",
    "\n",
    "    \n",
    "                for season, months in seasons.items(): \n",
    "                    #winter\n",
    "                    if season == 'DJF':\n",
    "                        df_acc_djf = add_lineplot_to_dataframe_average_by_week(df_acc_djf, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                        df_crps_djf = add_lineplot_to_dataframe_average_by_week(df_crps_djf, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "                    elif season == \"MAM\":\n",
    "                        df_acc_mam = add_lineplot_to_dataframe_average_by_week(df_acc_mam, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                        df_crps_mam = add_lineplot_to_dataframe_average_by_week(df_crps_mam, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "                    elif season == \"JJA\":\n",
    "                        df_acc_jja = add_lineplot_to_dataframe_average_by_week(df_acc_jja, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                        df_crps_jja = add_lineplot_to_dataframe_average_by_week(df_crps_jja, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "                    elif season == \"SON\":\n",
    "                        df_acc_son = add_lineplot_to_dataframe_average_by_week(df_acc_son, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                        df_crps_son = add_lineplot_to_dataframe_average_by_week(df_crps_son, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "        \n",
    "    print(\"Processing completed successfully!\")\n",
    "    return df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son,lead_improvment_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c33b4f-fb6c-4a34-9686-c2258a4bc6c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "leads=[6,13,20,27]\n",
    "\n",
    "print(f'Calculating ACC and CRPS on GEFS and ECMWF')\n",
    "obs, gefs, ecmwf = obs_anomaly_SubX_format.sel(L=leads), baseline_gefs.sel(L=leads), baseline_ecmwf.sel(L=leads)\n",
    "\n",
    "template = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(ecmwf), verifications.rename_obs_for_climpred(obs_original))\n",
    "\n",
    "'''All seasons raw forecast metrics'''\n",
    "df_acc_full, df_crps_full = calculate_ACC_raw_forecast_all_seasons(obs_original, gefs, ecmwf)\n",
    "\n",
    "'''Individual seasons raw forecast metrics. ACC and CRPSS. These are already averaged over both raw datasets'''\n",
    "df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son = calculate_ACC_raw_forecast_split_seasons(obs_original, gefs, ecmwf) \n",
    "\n",
    "'''Load bias corrected ACC all seasons (metrics already computed)'''\n",
    "gef_BC, ecm_BC = loadbias.load_additive_bias_corrected_data_ACC(leads,region_name,obs_source)\n",
    "\n",
    "#Add to dataframe\n",
    "df_acc_full = add_lineplot_to_dataframe(df=df_acc_full,fcst_vals=gef_BC,name_of_fcst='GEFSv12-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "df_acc_full = add_lineplot_to_dataframe(df=df_acc_full,fcst_vals=ecm_BC,name_of_fcst='ECMWF-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "\n",
    "\n",
    "'''Load bias corrected ACC individual seasons (metrics already computed)'''\n",
    "ecm_BC_djf, gef_BC_djf, ecm_BC_mam, gef_BC_mam, ecm_BC_jja, gef_BC_jja, ecm_BC_son, gef_BC_son = loadbias.load_additive_bias_corrected_data_by_season(leads,region_name,'acc',obs_source) \n",
    "#winter\n",
    "df_acc_djf = add_lineplot_to_dataframe(df=df_acc_djf,fcst_vals=gef_BC_djf,name_of_fcst='GEFSv12-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "df_acc_djf = add_lineplot_to_dataframe(df=df_acc_djf,fcst_vals=ecm_BC_djf,name_of_fcst='ECMWF-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "\n",
    "#spring\n",
    "df_acc_mam = add_lineplot_to_dataframe(df=df_acc_mam,fcst_vals=gef_BC_mam,name_of_fcst='GEFSv12-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "df_acc_mam = add_lineplot_to_dataframe(df=df_acc_mam,fcst_vals=ecm_BC_mam,name_of_fcst='ECMWF-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "\n",
    "\n",
    "#summer\n",
    "df_acc_jja = add_lineplot_to_dataframe(df=df_acc_jja,fcst_vals=gef_BC_jja,name_of_fcst='GEFSv12-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "df_acc_jja = add_lineplot_to_dataframe(df=df_acc_jja,fcst_vals=ecm_BC_jja,name_of_fcst='ECMWF-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "\n",
    "\n",
    "#fall\n",
    "df_acc_son = add_lineplot_to_dataframe(df=df_acc_son,fcst_vals=gef_BC_son,name_of_fcst='GEFSv12-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later       \n",
    "df_acc_son = add_lineplot_to_dataframe(df=df_acc_son,fcst_vals=ecm_BC_son,name_of_fcst='ECMWF-BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later       \n",
    "\n",
    "'''Load bias corrected reforecast CRPSS all seasons (metrics already computed)'''\n",
    "gef_BC, ecm_BC = loadbias.load_additive_bias_corrected_data_CRPSS(leads,region_name,obs_source)\n",
    "\n",
    "'''Load bias corrected CRPSS individual seasons (metrics already computed)'''\n",
    "ecm_BC_djf, gef_BC_djf, ecm_BC_mam, gef_BC_mam, ecm_BC_jja, gef_BC_jja, ecm_BC_son, gef_BC_son = loadbias.load_additive_bias_corrected_data_by_season(leads,region_name,'crpss',obs_source) \n",
    "#winter\n",
    "\n",
    "df_crps_djf = add_lineplot_to_dataframe(df=df_crps_djf,fcst_vals=gef_BC_djf[putils.xarray_varname(gef_BC_djf)].mean(dim='init').values,name_of_fcst='GEFSv12-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later   \n",
    "df_crps_djf = add_lineplot_to_dataframe(df=df_crps_djf,fcst_vals=ecm_BC_djf[putils.xarray_varname(ecm_BC_djf)].mean(dim='init').values,name_of_fcst='ECMWF-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later   \n",
    "\n",
    "#spring\n",
    "df_crps_mam = add_lineplot_to_dataframe(df=df_crps_mam,fcst_vals=gef_BC_mam[putils.xarray_varname(gef_BC_mam)].mean(dim='init').values,name_of_fcst='GEFSv12-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later     \n",
    "df_crps_mam = add_lineplot_to_dataframe(df=df_crps_mam,fcst_vals=ecm_BC_mam[putils.xarray_varname(ecm_BC_mam)].mean(dim='init').values,name_of_fcst='ECMWF-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later  \n",
    "\n",
    "#summer\n",
    "df_crps_jja = add_lineplot_to_dataframe(df=df_crps_jja,fcst_vals=gef_BC_jja[putils.xarray_varname(gef_BC_jja)].mean(dim='init').values,name_of_fcst='GEFSv12-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later   \n",
    "df_crps_jja = add_lineplot_to_dataframe(df=df_crps_jja,fcst_vals=ecm_BC_jja[putils.xarray_varname(gef_BC_jja)].mean(dim='init').values,name_of_fcst='ECMWF-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later   \n",
    "\n",
    "#fall\n",
    "df_crps_son = add_lineplot_to_dataframe(df=df_crps_son,fcst_vals=gef_BC_son[putils.xarray_varname(gef_BC_son)].mean(dim='init').values,name_of_fcst='GEFSv12-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later    \n",
    "df_crps_son = add_lineplot_to_dataframe(df=df_crps_son,fcst_vals=ecm_BC_son[putils.xarray_varname(ecm_BC_son)].mean(dim='init').values,name_of_fcst='ECMWF-BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later    \n",
    "\n",
    "\n",
    "'''Load bias corrected ACC all seasons (metrics already computed)'''\n",
    "gef_BC, ecm_BC = loadbias.load_additive_bias_corrected_data_ACC(leads,region_name,obs_source)\n",
    "\n",
    "#Reload the ACC\n",
    "ecm_BC_djf, gef_BC_djf, ecm_BC_mam, gef_BC_mam, ecm_BC_jja, gef_BC_jja, ecm_BC_son, gef_BC_son = loadbias.load_additive_bias_corrected_data_by_season(leads,region_name,'acc',obs_source) \n",
    "'''UNET all seasons and each individual season. ACC and CRPSS'''\n",
    "#We are taking the average of all models\n",
    "'''also compute the ACC improvement over each of the seasons'''\n",
    "df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son,lead_improvment_plots = return_UNET_combined(region_name, test_start, test_end, obs_original, df_acc_full, df_crps_full, template, df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son, df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son,leads,\n",
    "                         ecm_BC_djf, gef_BC_djf, ecm_BC_mam, gef_BC_mam, ecm_BC_jja, gef_BC_jja, ecm_BC_son, gef_BC_son,obs_source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb187e3-4a0a-49cc-94ee-2f2c8eb07536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_global_max_min(datasets, metric):\n",
    "    max_, min_ = [], []\n",
    "    for idx,i in enumerate(datasets):\n",
    "        min_.append(i[metric].min())\n",
    "        max_.append(i[metric].max())\n",
    "    return max(max_), min(min_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ed096-0b99-4312-88f4-29b684e53563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_ACC_CRPS_LinePlot(df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son,obs_source):\n",
    "    save_dir = f'Outputs/ACC_CRPS_line_plots/{region_name}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    # Define datasets for ACC (first row) and CRPSS (second row)\n",
    "    acc_datasets = [df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son]\n",
    "    crpss_datasets = [df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son]\n",
    "    season_names = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "    \n",
    "    acc_max, acc_min = find_global_max_min(acc_datasets, 'ACC')\n",
    "    crpss_max, crpss_min = find_global_max_min(crpss_datasets, 'CRPSS')\n",
    "    \n",
    "    #manually change the max acc to 1 and add a small increment to the bottom\n",
    "    acc_max = 0.9\n",
    "    acc_min =-0.1\n",
    "    \n",
    "    crpss_min = crpss_min-0.1\n",
    "    crpss_max = crpss_max+0.1\n",
    "    \n",
    "    #Plot\n",
    "    fig, axs = plt.subplots(2,4,figsize=(20, 7),dpi=300)\n",
    "    plt.style.use('seaborn-v0_8-colorblind')\n",
    "    palette = plt.get_cmap('tab10')\n",
    "    \n",
    "    # fig.suptitle('ACC and CRPSS by Season', fontsize=16)\n",
    "    \n",
    "    for (row,df),metric in zip(enumerate([acc_datasets,crpss_datasets]),['ACC','CRPSS']):\n",
    "        print(metric)\n",
    "        for col,data in enumerate(df):\n",
    "            \n",
    "            grouped = data.groupby('Forecast')\n",
    "            color_tracker = {}\n",
    "            marker_style = ['o', 'v', '^', '<', '>', 's', 'p', '*', '+']\n",
    "            season = season_names[col]\n",
    "            for i, (name, group) in enumerate(grouped):\n",
    "                color = palette(i)\n",
    "                marker = marker_style[i % len(marker_style)]\n",
    "                if color not in color_tracker:\n",
    "                    axs[row, col].plot(group['Week'], group[metric], label=custom_names[name], color=color, marker=marker, linestyle='-', markersize=6)\n",
    "                    color_tracker[color] = custom_names[name]\n",
    "                else:\n",
    "                    axs[row, col].plot(group['Week'], group[metric], label=custom_names[name], color = color, marker=marker, linestyle='-', markersize=6)           \n",
    "                \n",
    "                axs[row, col].set_ylim(acc_min, acc_max)\n",
    "                axs[row, col].set_ylim(acc_min if row == 0 else crpss_min, acc_max if row == 0 else crpss_max)\n",
    "    \n",
    "                # Add a horizontal line at y=0.5\n",
    "                if row == 0:\n",
    "                    axs[row,col].axhline(y=0.5, color='gray', linestyle='--', linewidth=2)\n",
    "                    axs[row, col].set_title(season, fontsize=20)\n",
    "            \n",
    "                # Setting the title and labels with increased font sizes\n",
    "                # plt.title(metric, fontsize=30)\n",
    "                if row==1:\n",
    "                    axs[row, col].set_xlabel('Week Lead', fontsize=14)\n",
    "                if col ==0:\n",
    "                    axs[row, col].set_ylabel(metric, fontsize=22, labelpad=10)\n",
    "\n",
    "                if row == 0 and col == 0:\n",
    "                    axs[row,col].legend(title='Forecast (# models)', fontsize=10, title_fontsize=13, loc='lower left') # Create the legend with a slightly larger font size\n",
    "        \n",
    "                axs[row, col].set_xticks([1,2,3,4])\n",
    "                axs[row, col].tick_params(axis='both', which='major', labelsize=12)\n",
    "                axs[row, col].grid(True, which='both', linestyle='--', linewidth=0.5) # Add a grid for better readability\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for suptitle spacing\n",
    "    plt.savefig(f'{save_dir}/Lineplot_ACC_CRPSS_SEASON_averaged_by_experiments_{obs_source}.png', dpi=300)\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf02ecd-54f2-46ff-850d-a995a8e84d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_ACC_CRPS_LinePlot(df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, \n",
    "                       df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son,obs_source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a40e44-d64a-4cc3-90f8-aefd7b6ae8ba",
   "metadata": {},
   "source": [
    "## Now plot with the improvement data in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758c6e5-12cb-45fc-80d1-03fde54aeb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered dictionary: only keep keys that contain 'GEFsv12'\n",
    "gefs_dict = {k: v for k, v in lead_improvment_plots.items() if 'GEFSv12' in k}\n",
    "ecmwf_dict = {k: v for k, v in lead_improvment_plots.items() if 'ECMWF' in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2423ef-c0db-4e47-b716-631ec0c454e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "def plot_combined_ACC_CRPS_map_grid(df_acc_list, df_crps_list, forecast_dict, forecast_name, variable_name, cmap,obs_source):\n",
    "    seasons = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "    leads = [1, 2, 3, 4]\n",
    "    marker_style = ['o', 'v', '^', '<', '>', 's', 'p', '*', '+']\n",
    "    palette = plt.get_cmap('tab10')\n",
    "    \n",
    "    fig, axs = plt.subplots(6, 4, figsize=(22, 20), dpi=300,)  # We'll override projection for maps later\n",
    "    acc_max, acc_min = find_global_max_min(df_acc_list, 'ACC')\n",
    "    crpss_max, crpss_min = find_global_max_min(df_crps_list, 'CRPSS')\n",
    "    \n",
    "    #manually change the max acc to 1 and add a small increment to the bottom\n",
    "    acc_max = 0.9\n",
    "    acc_min =-0.1\n",
    "    \n",
    "    crpss_min = crpss_min-0.1\n",
    "    crpss_max = crpss_max+0.1\n",
    "\n",
    "    #  Inject Cartopy projection only in bottom 4 rows\n",
    "    for row in range(2, 6):\n",
    "        for col in range(4):\n",
    "            axs[row, col].remove()\n",
    "            axs[row, col] = fig.add_subplot(6, 4, row * 4 + col + 1, projection=ccrs.PlateCarree())\n",
    "    \n",
    "    # ------------------ Line Plots (Top 2 Rows) ------------------\n",
    "    for row_idx, (df_list, metric) in enumerate(zip([df_acc_list, df_crps_list], ['ACC', 'CRPSS'])):\n",
    "        for col_idx, df in enumerate(df_list):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            grouped = df.groupby('Forecast')\n",
    "    \n",
    "            for i, (name, group) in enumerate(grouped):\n",
    "                color = palette(i)\n",
    "                marker = marker_style[i % len(marker_style)]\n",
    "                ax.plot(group['Week'], group[metric], label=name, color=color,\n",
    "                        marker=marker, linestyle='-', markersize=6)\n",
    "    \n",
    "            ax.set_xlim(0.5, 4.5)\n",
    "            ax.set_xticks([1, 2, 3, 4])\n",
    "            ax.set_xticklabels(['1', '2', '3', '4'])\n",
    "            ax.xaxis.set_major_locator(ticker.FixedLocator([1, 2, 3, 4]))\n",
    "    \n",
    "            ax.grid(True, linestyle='--', linewidth=0.5)\n",
    "            ax.tick_params(labelsize=10)\n",
    "            ax.set_ylim(acc_min if row_idx == 0 else crpss_min, acc_max if row_idx == 0 else crpss_max)\n",
    "    \n",
    "            if row_idx == 0:\n",
    "                ax.axhline(0.5, linestyle='--', color='gray', linewidth=1.5)\n",
    "                ax.set_title(seasons[col_idx], fontsize=20)\n",
    "                # ax.set_title(seasons[col_idx], fontsize=20, fontweight='bold')\n",
    "            if row_idx == 1:\n",
    "                ax.set_xlabel('Lead Week', fontsize=12)\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(metric, fontsize=14)\n",
    "    \n",
    "            if row_idx == 0 and col_idx == 0:\n",
    "                ax.legend(title='Forecast', fontsize=9, title_fontsize=10)\n",
    "    \n",
    "    # ------------------ Compute global color scale for maps ------------------\n",
    "    vmin_map = np.inf\n",
    "    vmax_map = -np.inf\n",
    "    for key in forecast_dict:\n",
    "        if variable_name in forecast_dict[key].data_vars:\n",
    "            data = forecast_dict[key][variable_name].values\n",
    "            vmin_map = min(vmin_map, np.nanmin(data))\n",
    "            vmax_map = max(vmax_map, np.nanmax(data))\n",
    "    \n",
    "    vmin_map = np.floor(vmin_map * 10) / 10\n",
    "    vmax_map = np.ceil(vmax_map * 10) / 10\n",
    "    cmap = get_cmap(cmap)\n",
    "    norm = TwoSlopeNorm(vmin=vmin_map, vcenter=0, vmax=vmax_map)\n",
    "    levels = np.arange(vmin_map, vmax_map + 0.2, 0.2)\n",
    "    \n",
    "    \n",
    "    # ------------------ Map Plots (Bottom 4 Rows) ------------------\n",
    "    for row_idx, lead in enumerate(leads, start=2):\n",
    "        for col_idx, season in enumerate(seasons):\n",
    "            key = f'DL-DM_{forecast_name}_lead{lead}_season{season}'\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.set_aspect('auto')\n",
    "    \n",
    "            if key not in forecast_dict or variable_name not in forecast_dict[key].data_vars:\n",
    "                ax.set_title(f'{key}\\n(No data)', fontsize=10)\n",
    "                ax.coastlines()\n",
    "                continue\n",
    "    \n",
    "            ds = forecast_dict[key]\n",
    "            data = ds[variable_name]\n",
    "            lon = ds.lon.values\n",
    "            lat = ds.lat.values\n",
    "            mesh_lon, mesh_lat = np.meshgrid(lon, lat)\n",
    "    \n",
    "            im = ax.contourf(mesh_lon, mesh_lat, data.values,\n",
    "                             levels=levels,\n",
    "                             transform=ccrs.PlateCarree(), cmap=cmap, norm=norm, extend='both')\n",
    "    \n",
    "    \n",
    "            ax.coastlines()\n",
    "            ax.add_feature(cfeature.BORDERS, linewidth=0.5)\n",
    "            ax.set_title(f'Season: {season}, Week: {lead}', fontsize=14)\n",
    "            # ax.set_title(f'Season: {season}, Week: {lead}', fontsize=12, fontweight='bold')\n",
    "\n",
    "    \n",
    "            gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', linestyle='--')\n",
    "            gl.top_labels = gl.right_labels = False\n",
    "            gl.xformatter = LongitudeFormatter()\n",
    "            gl.yformatter = LatitudeFormatter()\n",
    "            gl.xlabel_style = {'size': 8}\n",
    "            gl.ylabel_style = {'size': 8}\n",
    "    \n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.93, 1])  # Adjust for suptitle spacing\n",
    "    # Update ScalarMappable (same as before)\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    # Colorbar axis\n",
    "    cbar_ax = fig.add_axes([0.945, 0.12, 0.015, 0.50])\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax, orientation='vertical', extend='both',\n",
    "                        boundaries=levels, ticks=levels)\n",
    "    # 0.92, 0.08, 0.015, 0.40\n",
    "    # Labels and appearance\n",
    "    cbar.set_label(f'ACC Improvement diff(EX29-{forecast_name}[BC])', fontsize=14, rotation=90, labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=14, pad=2)\n",
    "\n",
    "    row_labels = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "    # row_labels = ['(A)', '(B)', '(C)', '(D)', '(E)', '(F)']\n",
    "    for row_idx, label in enumerate(row_labels):\n",
    "        axs[row_idx, 0].text(\n",
    "            -0.15, 1.05,  #  coordinates (x, y) relative to that subplot\n",
    "            label, \n",
    "            transform=axs[row_idx, 0].transAxes,  #  place text in subplot's coordinate system\n",
    "            fontsize=20, fontweight='bold', va='top', ha='right'\n",
    "        )\n",
    "\n",
    "    \n",
    "    plt.savefig(f'Outputs/ACC_CRPS_line_plots/{region_name}/Combined_6x4_ACC_CRPS_{forecast_name}_{obs_source}_Map.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc46fc0-6a63-41a3-aff4-2a986659508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combined_ACC_CRPS_map_grid(\n",
    "    df_acc_list=[df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son],\n",
    "    df_crps_list=[df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son],\n",
    "    forecast_dict=gefs_dict,\n",
    "    forecast_name='GEFSv12',\n",
    "    variable_name='acc',\n",
    "    cmap='bwr',\n",
    "    obs_source=obs_source\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d2980-bd06-47aa-9b4a-e4cf39d0280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_combined_ACC_CRPS_map_grid(\n",
    "#     df_acc_list=[df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son],\n",
    "#     df_crps_list=[df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son],\n",
    "#     forecast_dict=ecmwf_dict,\n",
    "#     forecast_name='ECMWF',\n",
    "#     variable_name='acc',\n",
    "#     cmap='bwr',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e1690-317c-4268-9b5b-ddccdf32fa90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu]",
   "language": "python",
   "name": "conda-env-tf212gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
