{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302f239-5aba-4164-8125-86df134c9bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mt\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from numpy import meshgrid\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter, LatitudeLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, TwoSlopeNorm\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from ridgeplot import ridgeplot\n",
    "import joypy\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import climpred\n",
    "from xclim import sdba\n",
    "from climpred.options import OPTIONS\n",
    "import json\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from matplotlib.lines import Line2D  # For custom legend entries\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.gridspec as gridspec\n",
    "import hydroeval as he\n",
    "import re\n",
    "\n",
    "from function import preprocessUtils as putils\n",
    "from function import masks\n",
    "from function import verifications\n",
    "from function import funs as f\n",
    "from function import conf\n",
    "from function import loadbias\n",
    "from function import dataLoad\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "global dim_order, region_name, test_year, leads_\n",
    "dim_order = conf.dim_order\n",
    "region_name = 'CONUS'\n",
    "test_year = 2019\n",
    "leads_ = [6,13,20,27]\n",
    "\n",
    "dir = '/glade/work/klesinger/FD_RZSM_deep_learning'\n",
    "assert test_year == 2019, 'This is only the script for when the testing years are 2018-2019. Test year must = 2019.'\n",
    "assert region_name == 'CONUS', 'This is only the script for CONUS, do not select any other region.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3c50b-ae23-42d5-83d7-fb6d15d55902",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, mask_anom = masks.load_mask_vals(region_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65c869-d7c7-447c-9c3a-5919924a46f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_source = 'GLEAM' #['GLEAM','ERA5']\n",
    "\n",
    "if obs_source == 'GLEAM':\n",
    "    soil_dir = conf.gleam_data\n",
    "elif obs_source == 'ERA5':\n",
    "    soil_dir = conf.era_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f38e61-2f06-4ffc-baf6-999766e5d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global custom_names\n",
    "'''This is for the final plot for ACC and CRPS'''\n",
    "custom_names = {\n",
    "    'GEFSv12': 'NWP (2)', 'EMOS': 'DM-BC_EMOS (4)', \n",
    "    'DM-BC_DL': 'DM-BC-DL (2)', 'DL': 'DL (16)',\n",
    "    'DL-DM': 'DL-DM (20)', 'ML_NWP_OBS': 'ML_NWP_OBS (2)',\n",
    "    'ECMWF':'NWP (2)', 'NWP_BC': 'NWP-BC (2)',\n",
    "}\n",
    "\n",
    "        \n",
    "def return_name(name):\n",
    "    if 'XGBOOST' in name:\n",
    "        name_out = 'ML_NWP_OBS'\n",
    "    else:\n",
    "        name_out = name\n",
    "    custom_names = {name: name_out}\n",
    "\n",
    "    return(custom_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46ab7f-c07d-4455-a5f4-608adcf2b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing and validation dates only for the year 2019'''\n",
    "\n",
    "test_start = '2018-01-01'\n",
    "test_end = '2019-12-31'\n",
    "val_start = '2016-01-01'\n",
    "val_end = '2017-12-31'\n",
    "train_start  = '2000-01-01'\n",
    "\n",
    "\n",
    "'''Test subsets of obs, ecmwf raw, gefsv12 raw '''\n",
    "global obs_anomaly_SubX_format, baseline_gefs, baseline_ecmwf, var_OUT, template_testing_only\n",
    "obs_anomaly_SubX_format, baseline_gefs, baseline_ecmwf, var_OUT, template_testing_only = verifications.open_obs_and_baseline_files_multiple_leads(region_name, leads_, test_start, test_end, mask_anom, soil_dir)\n",
    "\n",
    "#Open the gleam percentile/anom files\n",
    "init_dates,dt_dates,only_testing_dates = dataLoad.return_init_and_testing_dates(region_name,test_start,test_end)\n",
    "\n",
    "obs_anom_percentile = xr.open_mfdataset(f'{soil_dir}/{region_name}/RZSM_anom_and_percentile_reformat/*').sel(S=slice(test_start,test_end))\n",
    "obs_anom_percentile['S'] = only_testing_dates\n",
    "obs_anom_percentile\n",
    "\n",
    "''' Load EMOS results (only for CONUS). We have not completed EMOS on any other region except CONUS'''\n",
    "if region_name == 'CONUS':\n",
    "    emos_template = xr.open_dataset(f'Data/EMOS/{region_name}/EMOS_11_test_predictions_12_weeks_before.nc')\n",
    "    emos_template = emos_template.rename({'idate':'S', 'model': 'M','vdate': 'L', 'latitude': 'Y', 'longitude': 'X'})\n",
    "    emos_testing = emos_template.sel(S=slice(test_start,test_end))\n",
    "\n",
    "test_dates_subx = only_testing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617588b2-6c1d-433c-9b34-431ef9efe672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Experiment info for plotting\n",
    "# black = ['EX0','EX13'] # bias-correction\n",
    "# red = ['EX14','EX15','EX16','EX17','EX22','EX23','EX24','EX25'] # obs.-driven\n",
    "# blue = ['EX1','EX2','EX3','EX4','EX5','EX6','EX7','EX8','EX9','EX10','EX11','EX12',\n",
    "#        'EX18','EX19','EX20','EX21','EX27','EX28'] # hybrid\n",
    "\n",
    "global obs_original,obs_raw\n",
    "obs_original = xr.open_dataset(f'{soil_dir}/{region_name}/RZSM_anomaly.nc').rename({'SMsurf':'RZSM'}).drop('season').load()\n",
    "obs_raw = xr.open_dataset(f'{soil_dir}/{region_name}/RZSM_weighted_mean_0_100cm.nc4').rename({'SMsurf':'RZSM'}).load()\n",
    "\n",
    "init_dates = putils.get_init_date_list(f'{conf.gefsv12_data}/{region_name}/soilw_bgrnd')\n",
    "dt_dates = [pd.to_datetime(i) for i in init_dates]\n",
    "\n",
    "#Load previously created data (percentiles of the anomaly)\n",
    "# global emcwf_perc, gefs_perc\n",
    "# ecmwf_perc = verifications.load_ECMWF_percentile_anomaly(region_name).sel(S=slice(test_start,test_end)).load()\n",
    "# gefs_perc = verifications.load_GEFSv12_percentile_anomaly(region_name).sel(S=slice(test_start,test_end)).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a20f0-8be7-48d9-9ad8-f6ea300f6ff8",
   "metadata": {},
   "source": [
    "# Lineplot ACC and CRPS all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698a07f-8836-4613-bd8f-465faae51593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_lineplot_to_dataframe(df,fcst_vals,name_of_fcst, metric,week, mean_or_median):\n",
    "    # df = pd.DataFrame()\n",
    "    def return_color(name_of_fcst):\n",
    "        black = ['EX0','EX13'] # bias-corrected DL\n",
    "        red = ['EX14','EX15','EX16','EX17','EX22','EX23','EX24','EX25'] #Observation driven\n",
    "        blue = ['EX1','EX2','EX3','EX4','EX5','EX6','EX7','EX8','EX9','EX10','EX11','EX12',\n",
    "               'EX18','EX19','EX20','EX21','EX27','EX28','EX29'] #Hybrid\n",
    "\n",
    "        black2 = ['DM-BC_DL']\n",
    "        red2 = ['DL']\n",
    "        blue2 = ['DL-DM']\n",
    "        \n",
    "        green = ['ECMWF','GEFSv12']\n",
    "        \n",
    "        purple = 'NWP_BC'\n",
    "\n",
    "        yellow = 'EMOS'\n",
    "\n",
    "        if (name_of_fcst in black) or (name_of_fcst in black2):\n",
    "            color = 'black'\n",
    "        elif (name_of_fcst in red) or (name_of_fcst in red2):\n",
    "            color = 'red'\n",
    "        elif (name_of_fcst in blue) or (name_of_fcst in blue2):\n",
    "            color = 'blue'\n",
    "        elif name_of_fcst in green:\n",
    "            color = 'green'\n",
    "        elif purple in name_of_fcst:\n",
    "            color = 'purple'\n",
    "        elif yellow in name_of_fcst:\n",
    "            color = 'yellow'\n",
    "        return(color)\n",
    "\n",
    "    if week==10:\n",
    "        for idx,lead in enumerate([6,13,20,27]):\n",
    "            if mean_or_median == 'mean':\n",
    "                try:\n",
    "                    data = fcst_vals.sel(lead=lead).mean()[putils.xarray_varname(fcst_vals)].values\n",
    "                except KeyError:\n",
    "                    data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "            if mean_or_median == 'median':\n",
    "                try:\n",
    "                    data = fcst_vals.sel(lead=lead).median()[putils.xarray_varname(fcst_vals)].values\n",
    "                except KeyError:\n",
    "                    data = fcst_vals.median()[putils.xarray_varname(fcst_vals)].values\n",
    "            dict_ = {'Forecast':[name_of_fcst], 'Week':[idx+1], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "            df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    else:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.median()[putils.xarray_varname(fcst_vals)].values\n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[week], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "'''Only the single value for all the experiments'''\n",
    "\n",
    "def add_lineplot_to_dataframe_average(df,fcst_vals,name_of_fcst, metric,week, mean_or_median):\n",
    "    # df = pd.DataFrame()\n",
    "\n",
    "    def return_color(name_of_fcst):\n",
    "        black = ['DM-BC_DL']\n",
    "        red = ['DL']\n",
    "        blue = ['DL-DM']\n",
    "        \n",
    "        green = ['ECMWF','GEFSv12']\n",
    "        \n",
    "        purple = 'XGBOOST'\n",
    "\n",
    "        yellow = 'EMOS'\n",
    "\n",
    "        if name_of_fcst in black:\n",
    "            color = 'black'\n",
    "        elif name_of_fcst in red:\n",
    "            color = 'red'\n",
    "        elif name_of_fcst in blue:\n",
    "            color = 'blue'\n",
    "        elif name_of_fcst in green:\n",
    "            color = 'green'\n",
    "        elif purple in name_of_fcst:\n",
    "            color = 'purple'\n",
    "        elif yellow in name_of_fcst:\n",
    "            color = 'yellow'\n",
    "            \n",
    "        return(color)\n",
    "\n",
    "    if week==10:\n",
    "        for idx,lead in enumerate([6,13,20,27]):\n",
    "            if mean_or_median == 'mean':\n",
    "                data = fcst_vals.sel(lead=lead).mean()[putils.xarray_varname(fcst_vals)].values\n",
    "            elif mean_or_median == 'median':\n",
    "                data = fcst_vals.sel(lead=lead).median()[putils.xarray_varname(fcst_vals)].values\n",
    "            dict_ = {'Forecast':[name_of_fcst], 'Week':[idx+1], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "            df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    else:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.median()[putils.xarray_varname(fcst_vals)].values\n",
    "            \n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[week], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def add_lineplot_to_dataframe_average_by_week(df,fcst_vals,name_of_fcst, metric,week, mean_or_median, lead, idLead):\n",
    "    # df = pd.DataFrame()\n",
    "\n",
    "    def return_color(name_of_fcst):\n",
    "        black = ['DM-BC_DL']\n",
    "        red = ['DL']\n",
    "        blue = ['DL-DM']\n",
    "        \n",
    "        green = ['ECMWF','GEFSv12']\n",
    "        \n",
    "        purple = 'XGBOOST'\n",
    "\n",
    "        yellow = 'EMOS'\n",
    "\n",
    "        if name_of_fcst in black:\n",
    "            color = 'black'\n",
    "        elif name_of_fcst in red:\n",
    "            color = 'red'\n",
    "        elif name_of_fcst in blue:\n",
    "            color = 'blue'\n",
    "        elif name_of_fcst in green:\n",
    "            color = 'green'\n",
    "        elif purple in name_of_fcst:\n",
    "            color = 'purple'\n",
    "        elif yellow in name_of_fcst:\n",
    "            color = 'yellow'\n",
    "            \n",
    "        return(color)\n",
    "\n",
    "    if week==10:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.sel(lead=lead).mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.sel(lead=lead).median()[putils.xarray_varname(fcst_vals)].values\n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[idLead+1], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    else:\n",
    "        if mean_or_median == 'mean':\n",
    "            data = fcst_vals.mean()[putils.xarray_varname(fcst_vals)].values\n",
    "        elif mean_or_median == 'median':\n",
    "            data = fcst_vals.median()[putils.xarray_varname(fcst_vals)].values\n",
    "            \n",
    "        dict_ = {'Forecast':[name_of_fcst], 'Week':[week], f'{metric}': [data], 'Color':return_color(name_of_fcst)}\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(dict_)])\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fa9e0-a53c-4795-b982-17ed6d4ee491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_UNET_experiments(correct_experiments,obs_source):\n",
    "    only_RZSM = [j for j in correct_experiments if 'RZSM' in j] \n",
    "    only_ensemble= [j for j in only_RZSM if 'final' not in j]\n",
    "    only_ensemble = [j for j in only_ensemble if 'Residual' not in j]\n",
    "    only_2019 = [j for j in only_ensemble if '2012' not in j]\n",
    "    if obs_source == 'GLEAM':\n",
    "        only_2019 = [j for j in only_ensemble if 'ERA5' not in j]\n",
    "    print(f'Found files {only_2019} for UNET experiments')\n",
    "    return(only_2019)\n",
    "\n",
    "def common_UNET_no_regular_experiments(correct_experiments):\n",
    "    only_RZSM = [j for j in correct_experiments if 'RZSM' in j] \n",
    "    only_ensemble= [j for j in only_RZSM if 'final' not in j]\n",
    "    only_ensemble = [j for j in only_ensemble if 'Residual' not in j]\n",
    "    only_ensemble = [j for j in only_ensemble if 'regular' not in j]\n",
    "    only_2019 = [j for j in only_ensemble if '2012' not in j]\n",
    "    return(only_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f77e0-35eb-46ef-ac02-54abfb09bb37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def return_EMOS_average(region_name,test_start,test_end,obs_original,df_acc, df_crps,ecmwf_acc):\n",
    "#     print('Adding EMOS results')\n",
    "#     '''This is for adding all 4 EMOS experiments, but for some ready it is breaking right now and I'm not sure why (it kills the kernel)'''\n",
    "#     emos_files_full = sorted(glob(f'Data/EMOS/{region_name}/EMOS_11*test_predictions*.nc'))\n",
    "    \n",
    "#     # Loop through all the EMOS file experiments\n",
    "#     e_acc, e_crps = ecmwf_acc.copy(deep=True), ecmwf_acc.copy(deep=True)\n",
    "\n",
    "#     e_acc[putils.xarray_varname(e_acc)][:,:,:],  e_crps[putils.xarray_varname(e_crps)][:,:,:] = 0, 0\n",
    "\n",
    "#     # Loop through all the EMOS file experiments\n",
    "#     for idx,file in enumerate(emos_files_full):\n",
    "#         with xr.open_dataset(file) as emos_:\n",
    "#             # break\n",
    "#             emos_ = xr.open_dataset(file).rename({'idate':'S', 'model': 'M','vdate': 'L', 'latitude': 'Y', 'longitude': 'X'}).sel(S=slice(test_start,test_end))\n",
    "#             #First get the ACC values of GEFS and ECMWF relative to observations\n",
    "#             emos_acc = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(emos_), verifications.rename_obs_for_climpred(obs_original))\n",
    "#             add_  = (e_acc[putils.xarray_varname(e_acc)].values + emos_acc[putils.xarray_varname(emos_acc)].sel(lead=[6,13,20,27]).values)\n",
    "#             e_acc[putils.xarray_varname(e_acc)][:,:,:] = add_\n",
    "    \n",
    "#             emos_crps = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(emos_), verifications.rename_obs_for_climpred(obs_original))\n",
    "#             emos_crps = emos_crps.mean(dim='init')\n",
    "#             add_  = (e_crps[putils.xarray_varname(e_crps)].values + emos_crps[putils.xarray_varname(emos_crps)].sel(lead=[6,13,20,27]).values)\n",
    "#             e_crps[putils.xarray_varname(e_crps)][:,:,:] = add_\n",
    "\n",
    "#     #Divide\n",
    "#     e_acc = e_acc /len(emos_files_full)\n",
    "#     e_crps = e_crps /len(emos_files_full)\n",
    "#     #RE ADD MASK\n",
    "#     mm = ~np.isnan(emos_.isel(M=0,S=0).sel(L=[6,13,20,27]))[putils.xarray_varname(emos_)].values\n",
    "#     e_acc = xr.where(mm==True,e_acc,np.nan)\n",
    "#     e_crps = xr.where(mm==True,e_crps,np.nan)\n",
    "    \n",
    "#     df_acc = add_lineplot_to_dataframe(df_acc,e_acc,'EMOS', 'ACC',10,'mean')\n",
    "#     df_crps = add_lineplot_to_dataframe(df_crps,e_crps,'EMOS', 'CRPSS',10,'median')\n",
    "#     return df_acc, df_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1664c-1c27-4cc5-829c-4741bfceaf9e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def return_EMOS_average_by_season(region_name,test_start,test_end,obs_original,df_acc, df_crps,template):\n",
    "#     print('Adding EMOS results')\n",
    "#     '''This is for adding all 4 EMOS experiments, but for some ready it is breaking right now and I'm not sure why (it kills the kernel)'''\n",
    "#     emos_files_full = sorted(glob(f'Data/EMOS/{region_name}/EMOS_11*test_predictions*.nc'))\n",
    "        \n",
    "#     seasons = {\n",
    "#         \"DJF\": [12, 1, 2],  # Winter\n",
    "#         \"MAM\": [3, 4, 5],   # Spring\n",
    "#         \"JJA\": [6, 7, 8],   # Summer\n",
    "#         \"SON\": [9, 10, 11]  # Fall\n",
    "#     }\n",
    "\n",
    "#     # Initialize dictionaries to store seasonal results\n",
    "#     seasonal_acc = {season: template.copy(deep=True) for season in seasons}\n",
    "#     seasonal_crps = {season: template.copy(deep=True) for season in seasons}\n",
    "    \n",
    "#     # Set initial values to zero\n",
    "#     for season in seasons:\n",
    "#         seasonal_acc[season][putils.xarray_varname(template)][:, :, :] = 0\n",
    "#         seasonal_crps[season][putils.xarray_varname(template)][:, :, :] = 0\n",
    "\n",
    "#      # Loop through all the EMOS experiments\n",
    "#     for idx, file in enumerate(emos_files_full):\n",
    "#         with xr.open_dataset(file) as emos_:\n",
    "#             emos_ = xr.open_dataset(file).rename({'idate': 'S', 'model': 'M', 'vdate': 'L', 'latitude': 'Y', 'longitude': 'X'}).sel(S=slice(test_start, test_end))\n",
    "#             emos_.close()\n",
    "#             # Assign season to each data point based on the month\n",
    "#             emos_['month'] = emos_['S'].dt.month\n",
    "    \n",
    "#             for season, months in seasons.items():\n",
    "#                 # Select seasonal data\n",
    "#                 seasonal_emos = emos_.where(emos_['month'].isin(months), drop=True)\n",
    "#                 seasonal_obs = obs_original\n",
    "    \n",
    "#                 # Compute ACC\n",
    "#                 emos_acc = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(seasonal_emos), verifications.rename_obs_for_climpred(seasonal_obs))\n",
    "#                 add_acc = seasonal_acc[season][putils.xarray_varname(seasonal_acc[season])].values + emos_acc[putils.xarray_varname(emos_acc)].sel(lead=[6, 13, 20, 27]).values\n",
    "#                 seasonal_acc[season][putils.xarray_varname(seasonal_acc[season])][:, :, :] = add_acc\n",
    "    \n",
    "#                 # Compute CRPS\n",
    "#                 emos_crps = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(seasonal_emos), verifications.rename_obs_for_climpred(seasonal_obs))\n",
    "#                 emos_crps = emos_crps.mean(dim='init')\n",
    "#                 add_crps = seasonal_crps[season][putils.xarray_varname(seasonal_crps[season])].values + emos_crps[putils.xarray_varname(emos_crps)].sel(lead=[6, 13, 20, 27]).values\n",
    "#                 seasonal_crps[season][putils.xarray_varname(seasonal_crps[season])][:, :, :] = add_crps\n",
    "\n",
    "\n",
    "\n",
    "#     #Divide\n",
    "#     e_acc = e_acc /len(emos_files_full)\n",
    "#     e_crps = e_crps /len(emos_files_full)\n",
    "#     #RE ADD MASK\n",
    "#     mm = ~np.isnan(emos_.isel(M=0,S=0).sel(L=[6,13,20,27]))[putils.xarray_varname(emos_)].values\n",
    "#     e_acc = xr.where(mm==True,e_acc,np.nan)\n",
    "#     e_crps = xr.where(mm==True,e_crps,np.nan)\n",
    "    \n",
    "#     df_acc = add_lineplot_to_dataframe(df_acc,e_acc,'EMOS', 'ACC',10,'mean')\n",
    "#     df_crps = add_lineplot_to_dataframe(df_crps,e_crps,'EMOS', 'CRPSS',10,'median')\n",
    "#     return df_acc, df_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d132f85-aaf4-45da-b083-4a79dfd8ef43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_files_by_ex(file_list, color_list, week_):\n",
    "    filtered_files = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        match = re.search(rf'Wk{week_}_testing_EX(\\d+)_RZSM', file)\n",
    "        if match:\n",
    "            ex_value = f\"EX{match.group(1)}\"\n",
    "            if ex_value in color_list:\n",
    "                filtered_files.append(file)\n",
    "    \n",
    "    return filtered_files\n",
    "\n",
    "def return_file_list_by_category(region_name, week_):\n",
    "    black = ['EX0','EX13']\n",
    "    red = ['EX14','EX15','EX16','EX17','EX22','EX23','EX24','EX25']\n",
    "    blue = ['EX1','EX2','EX3','EX4','EX5','EX6','EX7','EX8','EX9','EX10','EX11','EX12',\n",
    "           'EX18','EX19','EX20','EX21','EX27','EX28','EX29']\n",
    "    \n",
    "    unet_files = sorted(glob(f'predictions/{region_name}/Wk{week_}_testing/*')) #With a specific subset of data\n",
    "    #First find the correct experiments\n",
    "    bias_correction_black = filter_files_by_ex(unet_files, black, week_)\n",
    "    hybrid_blue = filter_files_by_ex(unet_files, blue, week_)\n",
    "    obs_red = filter_files_by_ex(unet_files, red, week_)\n",
    "    return bias_correction_black, hybrid_blue, obs_red\n",
    "\n",
    "\n",
    "def create_empty_array(ecmwf_acc, day_num):\n",
    "    u_acc = ecmwf_acc.sel(lead=day_num).copy(deep=True)\n",
    "    u_crps = ecmwf_acc.sel(lead=day_num).copy(deep=True)\n",
    "    u_acc[putils.xarray_varname(u_acc)][:,:] = 0\n",
    "    u_crps[putils.xarray_varname(u_crps)][:,:] = 0\n",
    "    return u_acc, u_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3048b-7449-43d1-8499-4481118fd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ACC_raw_forecast_all_seasons(obs_original, gefs, ecmwf):\n",
    "\n",
    "    df_acc_full = pd.DataFrame()\n",
    "    df_crps_full = pd.DataFrame()\n",
    "    \n",
    "    gefs_acc = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(gefs), verifications.rename_obs_for_climpred(obs_original))\n",
    "    ecmwf_acc = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(ecmwf), verifications.rename_obs_for_climpred(obs_original))\n",
    "\n",
    "    gefs_crps = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(gefs), verifications.rename_obs_for_climpred(obs_original))\n",
    "    ecmwf_crps = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(ecmwf), verifications.rename_obs_for_climpred(obs_original))\n",
    "\n",
    "    diff_nwp = (gefs_acc + ecmwf_acc)/2\n",
    "    df_acc_full = add_lineplot_to_dataframe(df_acc_full,diff_nwp,'GEFSv12', 'ACC',10, 'mean') #Just keep the name the same for later\n",
    "\n",
    "    diff_nwp = (gefs_crps + ecmwf_crps)/2\n",
    "    df_crps_full = add_lineplot_to_dataframe(df_crps_full,diff_nwp,'GEFSv12', 'CRPSS',10, 'median') #Just keep the name the same for later\n",
    "    return df_acc_full, df_crps_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbade56a-fd71-4bf9-8471-923bdc06620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_ACC_raw_forecast_split_seasons(obs_original, gefs, ecmwf):\n",
    "    df_acc_djf = pd.DataFrame()\n",
    "    df_acc_mam = pd.DataFrame()\n",
    "    df_acc_jja = pd.DataFrame()\n",
    "    df_acc_son = pd.DataFrame()\n",
    "    \n",
    "    df_crps_djf = pd.DataFrame()\n",
    "    df_crps_mam = pd.DataFrame()\n",
    "    df_crps_jja = pd.DataFrame()\n",
    "    df_crps_son = pd.DataFrame()\n",
    "\n",
    "    seasons = {\n",
    "        \"DJF\": [12, 1, 2],  # Winter\n",
    "        \"MAM\": [3, 4, 5],   # Spring\n",
    "        \"JJA\": [6, 7, 8],   # Summer\n",
    "        \"SON\": [9, 10, 11]  # Fall\n",
    "    }\n",
    "\n",
    "    for season, months in seasons.items():\n",
    "        # break\n",
    "        # Filter datasets for the current season\n",
    "        obs_season = obs_original.sel(time=obs_original['time'].dt.month.isin(months))\n",
    "        gefs_season = gefs.sel(S=gefs['S'].dt.month.isin(months))\n",
    "        ecmwf_season = ecmwf.sel(S=ecmwf['S'].dt.month.isin(months))\n",
    "\n",
    "        # Compute ACC and CRPSS for the season\n",
    "        gefs_acc = verifications.create_climpred_ACC(\n",
    "            verifications.rename_subx_for_climpred(gefs_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "        ecmwf_acc = verifications.create_climpred_ACC(\n",
    "            verifications.rename_subx_for_climpred(ecmwf_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "\n",
    "        gefs_crps = verifications.create_climpred_CRPSS(\n",
    "            verifications.rename_subx_for_climpred(gefs_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "        ecmwf_crps = verifications.create_climpred_CRPSS(\n",
    "            verifications.rename_subx_for_climpred(ecmwf_season), \n",
    "            verifications.rename_obs_for_climpred(obs_season)\n",
    "        )\n",
    "\n",
    "        # Compute the mean ACC and CRPSS for GEFS and ECMWF\n",
    "        diff_nwp_acc = (gefs_acc + ecmwf_acc) / 2\n",
    "        diff_nwp_crps = (gefs_crps + ecmwf_crps) / 2\n",
    "\n",
    "        if season == 'DJF':\n",
    "            # Store results in DataFrame\n",
    "            df_acc_djf = add_lineplot_to_dataframe(df_acc_djf, diff_nwp_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_crps_djf = add_lineplot_to_dataframe(df_crps_djf, diff_nwp_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "        elif season == 'MAM':\n",
    "            df_acc_mam = add_lineplot_to_dataframe(df_acc_mam, diff_nwp_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_crps_mam = add_lineplot_to_dataframe(df_crps_mam, diff_nwp_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "        elif season == 'JJA':            \n",
    "            df_acc_jja = add_lineplot_to_dataframe(df_acc_jja, diff_nwp_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_crps_jja = add_lineplot_to_dataframe(df_crps_jja, diff_nwp_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "        elif season == 'SON':\n",
    "            df_acc_son = add_lineplot_to_dataframe(df_acc_son, diff_nwp_acc, 'GEFSv12', f'ACC', 10, 'mean')\n",
    "            df_crps_son = add_lineplot_to_dataframe(df_crps_son, diff_nwp_crps, 'GEFSv12', f'CRPSS', 10, 'median')\n",
    "               \n",
    "    return df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bdbc5-5db6-46db-af79-cafd6a805fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_EMOS_combined(region_name, test_start, test_end, obs_original, df_acc_full, df_crps_full, template, df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son, df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son,leads):\n",
    "    print('Adding EMOS results (all seasons and seasonal)')\n",
    "\n",
    "    emos_files_full = sorted(glob(f'Data/EMOS/{region_name}/EMOS_11*test_predictions*.nc'))\n",
    "\n",
    "    # Define seasons\n",
    "    seasons = {\n",
    "        \"DJF\": [12, 1, 2],  # Winter\n",
    "        \"MAM\": [3, 4, 5],   # Spring\n",
    "        \"JJA\": [6, 7, 8],   # Summer\n",
    "        \"SON\": [9, 10, 11]  # Fall\n",
    "    }\n",
    "\n",
    "    # Initialize all-season results\n",
    "    e_acc, e_crps = template.copy(deep=True), template.copy(deep=True)\n",
    "    e_acc[putils.xarray_varname(e_acc)][:, :, :] = 0\n",
    "    e_crps[putils.xarray_varname(e_crps)][:, :, :] = 0\n",
    "\n",
    "    # Initialize dictionaries to store seasonal results\n",
    "    seasonal_acc = {season: e_acc.copy(deep=True) for season in seasons}\n",
    "    seasonal_crps = {season: e_crps.copy(deep=True) for season in seasons}\n",
    "\n",
    "    # Set initial values to zero for each season\n",
    "    for season in seasons:\n",
    "        seasonal_acc[season][putils.xarray_varname(e_acc)][:, :, :] = 0\n",
    "        seasonal_crps[season][putils.xarray_varname(e_crps)][:, :, :] = 0\n",
    "\n",
    "    # Loop through all the EMOS experiments\n",
    "    for idx, file in enumerate(emos_files_full):\n",
    "        # break\n",
    "        with xr.open_dataset(file) as emos_:\n",
    "            emos_ = emos_.rename({'idate': 'S', 'model': 'M', 'vdate': 'L', 'latitude': 'Y', 'longitude': 'X'}).sel(S=slice(test_start, test_end))\n",
    "        \n",
    "            # Compute ACC for all seasons\n",
    "            emos_acc = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(emos_), verifications.rename_obs_for_climpred(obs_original))\n",
    "            e_acc[putils.xarray_varname(e_acc)][:, :, :] += emos_acc[putils.xarray_varname(emos_acc)].sel(lead=leads).values\n",
    "\n",
    "            # Compute CRPS for all seasons\n",
    "            emos_crps = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(emos_), verifications.rename_obs_for_climpred(obs_original))\n",
    "            emos_crps = emos_crps.mean(dim='init')\n",
    "            e_crps[putils.xarray_varname(e_crps)][:, :, :] += emos_crps[putils.xarray_varname(emos_crps)].sel(lead=leads).values\n",
    "\n",
    "            # Assign season to each data point based on the month\n",
    "            emos_['month'] = emos_['S'].dt.month\n",
    "\n",
    "            for season, months in seasons.items():\n",
    "                # Select seasonal data\n",
    "                seasonal_emos = emos_.where(emos_['month'].isin(months), drop=True)\n",
    "                seasonal_obs = obs_original.sel(time=obs_original['time'].dt.month.isin(months))\n",
    "\n",
    "                # Compute ACC for season\n",
    "                emos_acc_season = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(seasonal_emos), verifications.rename_obs_for_climpred(seasonal_obs))\n",
    "                seasonal_acc[season][putils.xarray_varname(seasonal_acc[season])][:, :, :] += emos_acc_season[putils.xarray_varname(emos_acc_season)].sel(lead=[6, 13, 20, 27]).values\n",
    "\n",
    "                # Compute CRPS for season\n",
    "                emos_crps_season = verifications.create_climpred_CRPSS(verifications.rename_subx_for_climpred(seasonal_emos), verifications.rename_obs_for_climpred(seasonal_obs))\n",
    "                emos_crps_season = emos_crps_season.mean(dim='init')\n",
    "                seasonal_crps[season][putils.xarray_varname(seasonal_crps[season])][:, :, :] += emos_crps_season[putils.xarray_varname(emos_crps_season)].sel(lead=[6, 13, 20, 27]).values\n",
    "\n",
    "    # Normalize and apply mask for all-season results\n",
    "    e_acc /= len(emos_files_full)\n",
    "    e_crps /= len(emos_files_full)\n",
    "    \n",
    "    mm = ~np.isnan(emos_.isel(M=0, S=0).sel(L=leads))[putils.xarray_varname(emos_)].values\n",
    "    e_acc = xr.where(mm, e_acc, np.nan)\n",
    "    e_crps = xr.where(mm, e_crps, np.nan)\n",
    "\n",
    "    # Add all-season results to DataFrame\n",
    "    df_acc_full = add_lineplot_to_dataframe(df_acc_full, e_acc, 'EMOS', 'ACC', 10, 'mean')\n",
    "    df_crps_full = add_lineplot_to_dataframe(df_crps_full, e_crps, 'EMOS', 'CRPSS', 10, 'median')\n",
    "\n",
    "    # Normalize and apply mask for seasonal results\n",
    "    for season in seasons:\n",
    "        # break\n",
    "        seasonal_acc[season] /= len(emos_files_full)\n",
    "        seasonal_crps[season] /= len(emos_files_full)\n",
    "        \n",
    "        seasonal_acc[season] = xr.where(mm, seasonal_acc[season], np.nan)\n",
    "        seasonal_crps[season] = xr.where(mm, seasonal_crps[season], np.nan)\n",
    "        \n",
    "        # Add seasonal results to DataFrame\n",
    "        #winter\n",
    "        if season == 'DJF':\n",
    "            df_acc_djf = add_lineplot_to_dataframe(df_acc_djf, seasonal_acc[season], f'EMOS', 'ACC', 10, 'mean')\n",
    "            df_crps_djf = add_lineplot_to_dataframe(df_crps_djf, seasonal_crps[season], f'EMOS', 'CRPSS', 10, 'median')\n",
    "        elif season == \"MAM\":\n",
    "            df_acc_mam = add_lineplot_to_dataframe(df_acc_mam, seasonal_acc[season], f'EMOS', 'ACC', 10, 'mean')\n",
    "            df_crps_mam = add_lineplot_to_dataframe(df_crps_mam, seasonal_crps[season], f'EMOS', 'CRPSS', 10, 'median')\n",
    "        elif season == \"JJA\":\n",
    "            df_acc_jja = add_lineplot_to_dataframe(df_acc_jja, seasonal_acc[season], f'EMOS', 'ACC', 10, 'mean')\n",
    "            df_crps_jja = add_lineplot_to_dataframe(df_crps_jja, seasonal_crps[season], f'EMOS', 'CRPSS', 10, 'median')\n",
    "        elif season == \"SON\":\n",
    "            df_acc_son = add_lineplot_to_dataframe(df_acc_son, seasonal_acc[season], f'EMOS', 'ACC', 10, 'mean')\n",
    "            df_crps_son = add_lineplot_to_dataframe(df_crps_son, seasonal_crps[season], f'EMOS', 'CRPSS', 10, 'median')\n",
    "\n",
    "    return df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafc2ea-b26e-4e05-a0ec-31f65e292bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_UNET_combined(region_name, test_start, test_end, obs_original, df_acc_full, df_crps_full, template, df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son, df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son,leads):\n",
    "    \n",
    "    # Define seasons\n",
    "    seasons = {\n",
    "        \"DJF\": [12, 1, 2],  # Winter\n",
    "        \"MAM\": [3, 4, 5],   # Spring\n",
    "        \"JJA\": [6, 7, 8],   # Summer\n",
    "        \"SON\": [9, 10, 11]  # Fall\n",
    "    }\n",
    "    \n",
    "    # Initialize all-season results\n",
    "    e_acc, e_crps = template.copy(deep=True), template.copy(deep=True)\n",
    "    e_acc[putils.xarray_varname(e_acc)][:, :, :] = 0\n",
    "    e_crps[putils.xarray_varname(e_crps)][:, :, :] = 0\n",
    "    \n",
    "    # Initialize dictionaries to store seasonal results\n",
    "    seasonal_acc = {season: e_acc.copy(deep=True) for season in seasons}\n",
    "    seasonal_crps = {season: e_crps.copy(deep=True) for season in seasons}\n",
    "    \n",
    "    # Set initial values to zero for each season\n",
    "    for season in seasons:\n",
    "        seasonal_acc[season][putils.xarray_varname(e_acc)][:, :, :] = 0\n",
    "        seasonal_crps[season][putils.xarray_varname(e_crps)][:, :, :] = 0\n",
    "    \n",
    "    \n",
    "    obs_forecast_boolean = np.isnan(obs)\n",
    "    \n",
    "    #Add to a new gefs template for masking\n",
    "    obs_forecast_boolean2 = gefs.copy(deep=True)\n",
    "    obs_forecast_boolean2.RZSM[:,:,:,:,:] = obs_forecast_boolean['var']\n",
    "    \n",
    "    for idLead, week_ in enumerate([1, 2, 3, 4]):\n",
    "        # break\n",
    "        \n",
    "        bias_correction_black, hybrid_blue, obs_red = return_file_list_by_category(region_name, week_)\n",
    "        day_num = (week_ * 7) - 1  # Lead time in days\n",
    "    \n",
    "        for model, name in zip([bias_correction_black, hybrid_blue, obs_red], ['DM-BC_DL', 'DL-DM', 'DL']):\n",
    "            # break\n",
    "            print(f'Processing {name} for WEEK {week_}.')\n",
    "            u_acc, u_crps = e_acc.copy(deep=True).sel(lead=day_num), e_crps.copy(deep=True).sel(lead=day_num)\n",
    "    \n",
    "            for i in model:\n",
    "                new_source = 'ECMWF' if 'ECMWF' in i else 'GEFSv12'\n",
    "                test_name = i.split('testing_')[-1].split('.npy')[0]\n",
    "                \n",
    "                # Load forecast file\n",
    "                forecast = verifications.load_UNET_files(\n",
    "                    gefs=gefs, file=i, region_name=region_name, day_num=day_num, \n",
    "                    new_source=new_source, test_year=test_year\n",
    "                )\n",
    "                \n",
    "                # Apply land mask\n",
    "                forecast = forecast.where(obs_forecast_boolean2 == 0, np.nan)\n",
    "                \n",
    "                # Compute ACC and CRPS\n",
    "                unet_acc = verifications.create_climpred_ACC(\n",
    "                    verifications.rename_subx_for_climpred(forecast), \n",
    "                    verifications.rename_obs_for_climpred(obs_original)\n",
    "                ).sel(lead=day_num)\n",
    "    \n",
    "                unet_crps = verifications.create_climpred_CRPSS(\n",
    "                    verifications.rename_subx_for_climpred(forecast), \n",
    "                    verifications.rename_obs_for_climpred(obs_original)\n",
    "                ).sel(lead=day_num).mean(dim='init')\n",
    "    \n",
    "                # Accumulate values\n",
    "                u_acc[putils.xarray_varname(u_acc)] += unet_acc[putils.xarray_varname(unet_acc)]\n",
    "                u_crps[putils.xarray_varname(u_crps)] += unet_crps[putils.xarray_varname(unet_crps)]\n",
    "    \n",
    "            # Average over model members\n",
    "            u_acc /= len(model)\n",
    "            u_crps /= len(model)\n",
    "    \n",
    "            # Reapply mask\n",
    "            mask = ~np.isnan(template[putils.xarray_varname(template)].sel(lead=day_num))\n",
    "            u_acc = xr.where(mask, u_acc, np.nan)\n",
    "            u_crps = xr.where(mask, u_crps, np.nan)\n",
    "    \n",
    "            # Add results to all-season DataFrame\n",
    "            df_acc_full = add_lineplot_to_dataframe_average(df_acc_full, u_acc, name, 'ACC', week_, 'mean')\n",
    "            df_crps_full = add_lineplot_to_dataframe_average(df_crps_full, u_crps, name, 'CRPSS', week_, 'median')\n",
    "    \n",
    "            for i in model:\n",
    "                new_source = 'ECMWF' if 'ECMWF' in i else 'GEFSv12'\n",
    "                test_name = i.split('testing_')[-1].split('.npy')[0]\n",
    "                \n",
    "                # Load forecast file\n",
    "                forecast = verifications.load_UNET_files(\n",
    "                    gefs=gefs, file=i, region_name=region_name, day_num=day_num, \n",
    "                    new_source=new_source, test_year=test_year\n",
    "                )\n",
    "                \n",
    "                # Assign months\n",
    "                forecast['month'] = forecast['S'].dt.month\n",
    "    \n",
    "                # Process seasonal data\n",
    "                for season, months in seasons.items():\n",
    "                    seasonal_forecast = forecast.where(forecast['month'].isin(months), drop=True)\n",
    "                    seasonal_obs = obs_original.sel(time=obs_original['time'].dt.month.isin(months))\n",
    "        \n",
    "                    # Compute seasonal ACC and CRPSS\n",
    "                    season_acc = verifications.create_climpred_ACC(\n",
    "                        verifications.rename_subx_for_climpred(seasonal_forecast),\n",
    "                        verifications.rename_obs_for_climpred(seasonal_obs)\n",
    "                    ).sel(lead=day_num)\n",
    "    \n",
    "                    season_crps = verifications.create_climpred_CRPSS(\n",
    "                        verifications.rename_subx_for_climpred(seasonal_forecast),\n",
    "                        verifications.rename_obs_for_climpred(seasonal_obs)\n",
    "                    ).sel(lead=day_num).mean(dim='init')\n",
    "    \n",
    "                    # Store seasonal results\n",
    "                    seasonal_acc[season][putils.xarray_varname(seasonal_acc[season])][idLead,:,:] += season_acc[putils.xarray_varname(season_acc)]\n",
    "                    seasonal_crps[season][putils.xarray_varname(seasonal_crps[season])][idLead,:,:]  += season_crps[putils.xarray_varname(season_crps)]\n",
    "    \n",
    "\n",
    "\n",
    "            for season, months in seasons.items(): \n",
    "                seasonal_acc[season] /= len(model)  \n",
    "                seasonal_crps[season] /= len(model)\n",
    "                #winter\n",
    "                if season == 'DJF':\n",
    "                    df_acc_djf = add_lineplot_to_dataframe_average_by_week(df_acc_djf, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                    df_crps_djf = add_lineplot_to_dataframe_average_by_week(df_crps_djf, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "                elif season == \"MAM\":\n",
    "                    df_acc_mam = add_lineplot_to_dataframe_average_by_week(df_acc_mam, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                    df_crps_mam = add_lineplot_to_dataframe_average_by_week(df_crps_mam, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "                elif season == \"JJA\":\n",
    "                    df_acc_jja = add_lineplot_to_dataframe_average_by_week(df_acc_jja, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                    df_crps_jja = add_lineplot_to_dataframe_average_by_week(df_crps_jja, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "                elif season == \"SON\":\n",
    "                    df_acc_son = add_lineplot_to_dataframe_average_by_week(df_acc_son, seasonal_acc[season], name, 'ACC', 10, 'mean',day_num, idLead)\n",
    "                    df_crps_son = add_lineplot_to_dataframe_average_by_week(df_crps_son, seasonal_crps[season], name, 'CRPSS', 10, 'median',day_num, idLead)\n",
    "    \n",
    "    print(\"Processing completed successfully!\")\n",
    "    return df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66b474-e682-4a56-b414-c9f99f8c26b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leads=[6,13,20,27]\n",
    "\n",
    "print(f'Calculating ACC and CRPS on GEFS and ECMWF')\n",
    "obs, gefs, ecmwf = obs_anomaly_SubX_format.sel(L=leads), baseline_gefs.sel(L=leads), baseline_ecmwf.sel(L=leads)\n",
    "\n",
    "template = verifications.create_climpred_ACC(verifications.rename_subx_for_climpred(ecmwf), verifications.rename_obs_for_climpred(obs_original))\n",
    "\n",
    "'''All seasons raw forecast metrics'''\n",
    "df_acc_full, df_crps_full = calculate_ACC_raw_forecast_all_seasons(obs_original, gefs, ecmwf)\n",
    "\n",
    "'''Individual seasons raw forecast metrics. ACC and CRPSS. These are already averaged over both raw datasets'''\n",
    "df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son = calculate_ACC_raw_forecast_split_seasons(obs_original, gefs, ecmwf) \n",
    "\n",
    "'''Load bias corrected ACC all seasons (metrics already computed)'''\n",
    "gef_BC, ecm_BC = loadbias.load_additive_bias_corrected_data_ACC(leads,region_name,obs_source)\n",
    "diff_nwp_BC = (gef_BC + ecm_BC)/2 #take the average\n",
    "#Add to dataframe\n",
    "df_acc_full = add_lineplot_to_dataframe(df=df_acc_full,fcst_vals=diff_nwp_BC,name_of_fcst='NWP_BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "\n",
    "'''Load bias corrected ACC individual seasons (metrics already computed)'''\n",
    "ecm_BC_djf, gef_BC_djf, ecm_BC_mam, gef_BC_mam, ecm_BC_jja, gef_BC_jja, ecm_BC_son, gef_BC_son = loadbias.load_additive_bias_corrected_data_by_season(leads,region_name,'acc',obs_source) \n",
    "#winter\n",
    "diff_nwp_BC = (ecm_BC_djf + gef_BC_djf)/2 #take the average\n",
    "df_acc_djf = add_lineplot_to_dataframe(df=df_acc_djf,fcst_vals=diff_nwp_BC,name_of_fcst='NWP_BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "#spring\n",
    "diff_nwp_BC = (ecm_BC_mam + gef_BC_mam)/2 #take the average\n",
    "df_acc_mam = add_lineplot_to_dataframe(df=df_acc_mam,fcst_vals=diff_nwp_BC,name_of_fcst='NWP_BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "#summer\n",
    "diff_nwp_BC = (ecm_BC_jja + gef_BC_jja)/2 #take the average\n",
    "df_acc_jja = add_lineplot_to_dataframe(df=df_acc_jja,fcst_vals=diff_nwp_BC,name_of_fcst='NWP_BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later   \n",
    "#fall\n",
    "diff_nwp_BC = (ecm_BC_son + gef_BC_son)/2 #take the average\n",
    "df_acc_son = add_lineplot_to_dataframe(df=df_acc_son,fcst_vals=diff_nwp_BC,name_of_fcst='NWP_BC', metric='ACC',week=10, mean_or_median = 'mean') #Just keep the name the same for later       \n",
    "\n",
    "'''Load bias corrected reforecast CRPSS all seasons (metrics already computed)'''\n",
    "gef_BC, ecm_BC = loadbias.load_additive_bias_corrected_data_CRPSS(leads,region_name,obs_source)\n",
    "\n",
    "\n",
    "'''Load bias corrected CRPSS individual seasons (metrics already computed)'''\n",
    "ecm_BC_djf, gef_BC_djf, ecm_BC_mam, gef_BC_mam, ecm_BC_jja, gef_BC_jja, ecm_BC_son, gef_BC_son = loadbias.load_additive_bias_corrected_data_by_season(leads,region_name,'crpss',obs_source) \n",
    "#winter\n",
    "t1=template.copy(deep=True)\n",
    "diff_nwp_BC = (ecm_BC_djf[putils.xarray_varname(ecm_BC_djf)].mean(dim='init').values + gef_BC_djf[putils.xarray_varname(gef_BC_djf)].mean(dim='init').values)/2 #take the average\n",
    "t1[putils.xarray_varname(t1)][:,:,:]=diff_nwp_BC\n",
    "df_crps_djf = add_lineplot_to_dataframe(df=df_crps_djf,fcst_vals=t1,name_of_fcst='NWP_BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later   \n",
    "\n",
    "#spring\n",
    "t1=template.copy(deep=True)\n",
    "diff_nwp_BC = (ecm_BC_mam[putils.xarray_varname(ecm_BC_mam)].mean(dim='init').values + gef_BC_mam[putils.xarray_varname(gef_BC_mam)].mean(dim='init').values)/2 #take the average\n",
    "t1[putils.xarray_varname(t1)][:,:,:]=diff_nwp_BC\n",
    "df_crps_mam = add_lineplot_to_dataframe(df=df_crps_mam,fcst_vals=t1,name_of_fcst='NWP_BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later     \n",
    "#summer\n",
    "t1=template.copy(deep=True)\n",
    "diff_nwp_BC = (ecm_BC_jja[putils.xarray_varname(ecm_BC_jja)].mean(dim='init').values + gef_BC_jja[putils.xarray_varname(gef_BC_jja)].mean(dim='init').values)/2 #take the average\n",
    "t1[putils.xarray_varname(t1)][:,:,:]=diff_nwp_BC\n",
    "df_crps_jja = add_lineplot_to_dataframe(df=df_crps_jja,fcst_vals=t1,name_of_fcst='NWP_BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later   \n",
    "#fall\n",
    "t1=template.copy(deep=True)\n",
    "diff_nwp_BC = (ecm_BC_son[putils.xarray_varname(ecm_BC_son)].mean(dim='init').values + gef_BC_son[putils.xarray_varname(gef_BC_son)].mean(dim='init').values)/2 #take the average\n",
    "t1[putils.xarray_varname(t1)][:,:,:]=diff_nwp_BC\n",
    "df_crps_son = add_lineplot_to_dataframe(df=df_crps_son,fcst_vals=t1,name_of_fcst='NWP_BC', metric='CRPSS',week=10, mean_or_median = 'median') #Just keep the name the same for later    \n",
    "\n",
    "'''EMOS all seasons and each individual season. ACC and CRPSS'''\n",
    "df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son = return_EMOS_combined(region_name, test_start, test_end, obs_original, df_acc_full, df_crps_full, template,df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son, df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son,leads)\n",
    "\n",
    "'''UNET all seasons and each individual season. ACC and CRPSS'''\n",
    "#We are taking the average of all models\n",
    "df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son = return_UNET_combined(region_name, test_start, test_end, obs_original, df_acc_full, df_crps_full, template,df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son, df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son,leads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798fa66-57ef-446e-9f3d-60cb0bb3e9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb187e3-4a0a-49cc-94ee-2f2c8eb07536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_global_max_min(datasets, metric):\n",
    "    max_, min_ = [], []\n",
    "    for idx,i in enumerate(datasets):\n",
    "        min_.append(i[metric].min())\n",
    "        max_.append(i[metric].max())\n",
    "    return max(max_), min(min_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ed096-0b99-4312-88f4-29b684e53563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_ACC_CRPS_LinePlot(df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son):\n",
    "    save_dir = f'Outputs/ACC_CRPS_line_plots/{region_name}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    # Define datasets for ACC (first row) and CRPSS (second row)\n",
    "    acc_datasets = [df_acc_djf, df_acc_mam, df_acc_jja, df_acc_son]\n",
    "    crpss_datasets = [df_crps_djf, df_crps_mam, df_crps_jja, df_crps_son]\n",
    "    season_names = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "    \n",
    "    acc_max, acc_min = find_global_max_min(acc_datasets, 'ACC')\n",
    "    crpss_max, crpss_min = find_global_max_min(crpss_datasets, 'CRPSS')\n",
    "    \n",
    "    #manually change the max acc to 1 and add a small increment to the bottom\n",
    "    acc_max = 1\n",
    "    acc_min =0\n",
    "    \n",
    "    crpss_min = crpss_min-0.1\n",
    "    crpss_max = crpss_max+0.1\n",
    "    \n",
    "    #Plot\n",
    "    fig, axs = plt.subplots(2,4,figsize=(20, 7),dpi=300)\n",
    "    plt.style.use('seaborn-v0_8-colorblind')\n",
    "    palette = plt.get_cmap('tab10')\n",
    "    \n",
    "    # fig.suptitle('ACC and CRPSS by Season', fontsize=16)\n",
    "    \n",
    "    for (row,df),metric in zip(enumerate([acc_datasets,crpss_datasets]),['ACC','CRPSS']):\n",
    "        print(metric)\n",
    "        for col,data in enumerate(df):\n",
    "            \n",
    "            grouped = data.groupby('Forecast')\n",
    "            color_tracker = {}\n",
    "            marker_style = ['o', 'v', '^', '<', '>', 's', 'p', '*', '+']\n",
    "            season = season_names[col]\n",
    "            for i, (name, group) in enumerate(grouped):\n",
    "                color = palette(i)\n",
    "                marker = marker_style[i % len(marker_style)]\n",
    "                if color not in color_tracker:\n",
    "                    axs[row, col].plot(group['Week'], group[metric], label=custom_names[name], color=color, marker=marker, linestyle='-', markersize=6)\n",
    "                    color_tracker[color] = custom_names[name]\n",
    "                else:\n",
    "                    axs[row, col].plot(group['Week'], group[metric], label=custom_names[name], color = color, marker=marker, linestyle='-', markersize=6)           \n",
    "                \n",
    "                axs[row, col].set_ylim(acc_min, acc_max)\n",
    "                axs[row, col].set_ylim(acc_min if row == 0 else crpss_min, acc_max if row == 0 else crpss_max)\n",
    "    \n",
    "                # Add a horizontal line at y=0.5\n",
    "                if row == 0:\n",
    "                    axs[row,col].axhline(y=0.5, color='gray', linestyle='--', linewidth=2)\n",
    "                    axs[row, col].set_title(season, fontsize=20)\n",
    "            \n",
    "                # Setting the title and labels with increased font sizes\n",
    "                # plt.title(metric, fontsize=30)\n",
    "                if row==1:\n",
    "                    axs[row, col].set_xlabel('Week Lead', fontsize=14)\n",
    "                if col ==0:\n",
    "                    axs[row, col].set_ylabel(metric, fontsize=22, labelpad=10)\n",
    "\n",
    "                if row == 0 and col == 0:\n",
    "                    axs[row,col].legend(title='Forecast (# models)', fontsize=10, title_fontsize=13, loc='lower left') # Create the legend with a slightly larger font size\n",
    "        \n",
    "                axs[row, col].set_xticks([1,2,3,4])\n",
    "                axs[row, col].tick_params(axis='both', which='major', labelsize=12)\n",
    "                axs[row, col].grid(True, which='both', linestyle='--', linewidth=0.5) # Add a grid for better readability\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for suptitle spacing\n",
    "    plt.savefig(f'{save_dir}/Lineplot_ACC_CRPSS_SEASON_averaged_by_experiments.png', dpi=300)\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf02ecd-54f2-46ff-850d-a995a8e84d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ACC_CRPS_LinePlot(df_acc_full, df_crps_full, df_acc_djf, df_crps_djf, df_acc_mam, df_crps_mam, df_acc_jja, df_crps_jja, df_acc_son, df_crps_son)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90f433-af25-4117-8ecb-d0c09b513cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu]",
   "language": "python",
   "name": "conda-env-tf212gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
