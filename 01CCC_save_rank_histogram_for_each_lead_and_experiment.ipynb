{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302f239-5aba-4164-8125-86df134c9bd5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "# import pandas as pd\n",
    "from glob import glob\n",
    "#import climpredNEW.climpred \n",
    "#from climpredNEW.climpred.options import OPTIONS\n",
    "from climpred.options import OPTIONS\n",
    "import climpred\n",
    "import pickle\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from numpy import meshgrid\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.feature as cfeature\n",
    "import itertools\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter, LatitudeLocator\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, TwoSlopeNorm\n",
    "from scipy.stats import rankdata\n",
    "import bottleneck as bn\n",
    "import scipy.stats as stats\n",
    "\n",
    "from function import preprocessUtils as putils\n",
    "from function import masks\n",
    "from function import verifications\n",
    "from function import funs as f\n",
    "from function import conf\n",
    "from function import loadbias\n",
    "from function import dataLoad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9f743-2b10-4ed6-8037-d2ff7bcfd9b0",
   "metadata": {},
   "source": [
    "# Make ACC values for the later plots for permutation tests. \n",
    "## These are a bit further down in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2151bb10-b78b-472d-9a60-e062e22bbc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_52175/3923103670.py:4: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  obs_original = xr.open_dataset(f'{conf.gleam_data}/{region_name}/RZSM_anomaly.nc').rename({'SMsurf':'RZSM'}).drop('season').load()\n"
     ]
    }
   ],
   "source": [
    "region_name = 'CONUS' #or ['australia', 'CONUS', 'china']\n",
    "\n",
    "global obs_original\n",
    "obs_original = xr.open_dataset(f'{conf.gleam_data}/{region_name}/RZSM_anomaly.nc').rename({'SMsurf':'RZSM'}).drop('season').load()\n",
    "obs_anom_climp = verifications.rename_obs_for_climpred(obs_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612950b1-1fcf-4522-b79c-7d85f090e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set script parameters\n",
    "\n",
    "\n",
    "\n",
    "mask=masks.load_mask(region_name)\n",
    "mask_anom = mask[putils.xarray_varname(mask)][:,:].values\n",
    "\n",
    "start_obs = '2000-01-01' #Beginning of observation period for analysis. We actually have data starting from 1999 so that we could have a 7-day rolling mean applied to the data and have up to 12 weeks lags for RZSM\n",
    "end_obs = '2020-12-31' #end of observations for ERA5 and GLEAM. We actually needed data through 2020-02-15 since we have an initialization on 2019-12-25\n",
    "start_testing = '2018-01-01' #Beginning of testing period\n",
    "train_end_string = '2015-12-31' #last string date for training\n",
    "train_end = 2015 #last year of training dates\n",
    "\n",
    "\n",
    "global RZSM_or_Tmax_or_both\n",
    "RZSM_or_Tmax_or_both = 'RZSM' # for getting the predictor from either RZSM and Tmax ('both') or only RZSM ('RZSM')\n",
    "\n",
    "lead_select = [6,13,20,27,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898fb0e0-f8ee-4f17-bc53-1398e00403b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_min_max(file,name):\n",
    "    print(name)\n",
    "    print(f'Maximum value in file is {np.nanmax(file[putils.xarray_varname(file)])}')\n",
    "    print(f'Minimum value in file is {np.nanmin(file[putils.xarray_varname(file)])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33006b80-df8e-4d6a-93ca-4ab7fb432eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "global verification_var\n",
    "verification_var = 'soilw_bgrnd_GLEAM' #this is for what we are verifying with DL outputs\n",
    "\n",
    "#Gleam observations\n",
    "gleam_dir = f'{conf.gleam_data}/{region_name}'\n",
    "\n",
    "#Forecast predictions\n",
    "gefsv12_fcst_dir = f'{conf.gefsv12_data}/{region_name}'\n",
    "\n",
    "#ERA5 observations\n",
    "era5_dir = f'{conf.era_data}/{region_name}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e288d7ab-6c7c-47b5-b251-6a5067c7512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original observations and reforecasts (no anomalies). Selecting dates for observations between 2000-01-01 and 2020-12-31. Applying a 7-day rolling mean to be consistent.\n",
      "Loading GLEAM baseline anomaly files\n",
      "Loading ECMWF baseline anomaly files\n",
      "Loading GEFSv12 baseline anomaly files\n"
     ]
    }
   ],
   "source": [
    "#Load observation anomaly\n",
    "print(f'Loading original observations and reforecasts (no anomalies). Selecting dates for observations between {start_obs} and {end_obs}. Applying a 7-day rolling mean to be consistent.')\n",
    "\n",
    "gleam_anom = verifications.load_RZSM_anomaly_obs(region_name).load()\n",
    "ecmwf_anom = verifications.load_ECMWF_baseline_anomaly(region_name).load()\n",
    "gefs_anom = verifications.load_GEFSv12_baseline_anomaly(region_name).load()\n",
    "\n",
    "'''Load a base file to serve as the xarray template to add our predictions from UNET into.'''\n",
    "base_file_testing = gefs_anom.copy(deep=True).sel(S=slice(start_testing, None)).load()\n",
    "\n",
    "global lat, lon\n",
    "lat = base_file_testing.Y.values  # for plotting later\n",
    "lon = base_file_testing.X.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969c264e-626d-4153-b516-05b88f7b3445",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "manager must be a string or instance of ChunkManagerEntrypoint, but received type <class 'xarray.core.daskmanager.DaskManager'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Load the percentile files from \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ecmwf_perc \u001b[38;5;241m=\u001b[39m \u001b[43mverifications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_ECMWF_percentile_anomaly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      3\u001b[0m gefs_perc \u001b[38;5;241m=\u001b[39m verifications\u001b[38;5;241m.\u001b[39mload_GEFSv12_percentile_anomaly(region_name)\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[0;32m/glade/work/klesinger/FD_RZSM_deep_learning/function/verifications.py:115\u001b[0m, in \u001b[0;36mload_ECMWF_percentile_anomaly\u001b[0;34m(region_name)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_ECMWF_percentile_anomaly\u001b[39m(region_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mecmwf_data\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mregion_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/soilw_bgrnd/percentiles_MEM/*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnested\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/xarray/backends/api.py:1054\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1051\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1052\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1054\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [open_(p, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m   1055\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/xarray/backends/api.py:1054\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1051\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1052\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1054\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[43mopen_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m   1055\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/xarray/backends/api.py:577\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    571\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[1;32m    572\u001b[0m     filename_or_obj,\n\u001b[1;32m    573\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    576\u001b[0m )\n\u001b[0;32m--> 577\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43m_dataset_from_backend_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/xarray/backends/api.py:370\u001b[0m, in \u001b[0;36m_dataset_from_backend_dataset\u001b[0;34m(backend_ds, filename_or_obj, engine, chunks, cache, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs, **extra_tokens)\u001b[0m\n\u001b[1;32m    368\u001b[0m     ds \u001b[38;5;241m=\u001b[39m backend_ds\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43m_chunk_ds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43minline_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m ds\u001b[38;5;241m.\u001b[39mset_close(backend_ds\u001b[38;5;241m.\u001b[39m_close)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Ensure source filename always stored in dataset object\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/xarray/backends/api.py:335\u001b[0m, in \u001b[0;36m_chunk_ds\u001b[0;34m(backend_ds, filename_or_obj, engine, chunks, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs, **extra_tokens)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, var \u001b[38;5;129;01min\u001b[39;00m backend_ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    334\u001b[0m     var_chunks \u001b[38;5;241m=\u001b[39m _get_chunk(var, chunks, chunkmanager)\n\u001b[0;32m--> 335\u001b[0m     variables[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43minline_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunkmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend_ds\u001b[38;5;241m.\u001b[39m_replace(variables)\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/xarray/core/dataset.py:301\u001b[0m, in \u001b[0;36m_maybe_chunk\u001b[0;34m(name, var, chunks, token, lock, name_prefix, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m {dim: chunks[dim] \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m var\u001b[38;5;241m.\u001b[39mdims \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m chunks}\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 301\u001b[0m     chunked_array_type \u001b[38;5;241m=\u001b[39m \u001b[43mguess_chunkmanager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked_array_type\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# coerce string to ChunkManagerEntrypoint type\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunked_array_type, DaskManager):\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenize\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/xarray/namedarray/parallelcompat.py:126\u001b[0m, in \u001b[0;36mguess_chunkmanager\u001b[0;34m(manager)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m manager\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanager must be a string or instance of ChunkManagerEntrypoint, but received type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(manager)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: manager must be a string or instance of ChunkManagerEntrypoint, but received type <class 'xarray.core.daskmanager.DaskManager'>"
     ]
    }
   ],
   "source": [
    "#Load the percentile files from \n",
    "ecmwf_perc = verifications.load_ECMWF_percentile_anomaly(region_name).load()\n",
    "gefs_perc = verifications.load_GEFSv12_percentile_anomaly(region_name).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b733db-dc18-4c90-b0d0-2e458932e706",
   "metadata": {},
   "source": [
    "# Now create baseline anomalies of files to not have to re-compute later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0897f7c3-e10a-44a6-a5b6-a8936bc7ca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the seasonal anomalies for observational data and then subsetting for everything after 2018-01-01 date.\n"
     ]
    }
   ],
   "source": [
    "#First\n",
    "#Create seasonal anomaly from observations\n",
    "print(f'Creating the seasonal anomalies for observational data and then subsetting for everything after {start_testing} date.')\n",
    "save_anomaly_dir = f'Data/anomaly/{region_name}'\n",
    "os.system(f'mkdir -p {save_anomaly_dir}')\n",
    "\n",
    "obs_RZSM_save = f'{save_anomaly_dir}/obs_RZSM_anomaly_testing.nc'\n",
    "ref_RZSM_save = f'{save_anomaly_dir}/reforecast_RZSM_anomaly_testing.nc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b7147-7a28-41ab-a5a3-14b80173dfa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bias correction (additive). Climpred won't work despite my data being in the exact same format. Let's just make our own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ffaf3c95-e085-40ff-96f6-4edc71b69559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_create_seasonal_anomaly(path,train_end):\n",
    "    #Must subset by lead first (because we actually have data previously from past lag weeks)\n",
    "    return(create_seasonal_anomaly(xr.open_mfdataset(path).sel(L=slice(0,34)).rolling(L=7, min_periods=7,center=False).mean(),train_end=train_end,source='reforecast'))\n",
    "\n",
    "def check_values_in_file(file,lead):\n",
    "    '''Just print some values to verify the files aren't identical when comparing with other results'''\n",
    "    name_file = list(file.keys())[0]\n",
    "    return(print(file[name_file].isel(L=lead).isel(M=10).isel(S=0).values))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aa259c4d-646c-4c4a-9901-21cc495dde82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_experiment_predictions_and_observations(lead,experiment,region_name):\n",
    "    # #Test\n",
    "    # experiment='EX0'\n",
    "    day_num = (lead*7)-1\n",
    "    min_max_dir = f'Data/min_max_values/{region_name}'\n",
    "    verification_directory = f'Data/model_npy_input_data/{region_name}/Verification_data' #For observation verification\n",
    "    bias_correction_dir = f'Data/bias_mean_values/Wk_{lead}'\n",
    "\n",
    "    ex_name = experiment\n",
    "\n",
    "\n",
    "    #Load the actual observations (used for the Mean Absolute Error calculation)\n",
    "    obs_final_train,obs_final_validation,obs_final_testing = f.load_verification_observations_updated(lead,verification_directory)\n",
    "    obs_RZSM = np.array(obs_final_testing) #anomaly\n",
    "\n",
    "    #Convert observations 0 values to nan (only for the RZSM observations). These values had a zero where there is no land soil moisture\n",
    "    obs_RZSM = np.where(obs_RZSM == 0,np.nan,obs_RZSM)\n",
    "    \n",
    "    obs_RZSM =verifications.reverse_min_max_scaling(obs_RZSM,region_name,day_num,'GLEAM',2019)\n",
    "\n",
    "        \n",
    "    predictions_directory = f'predictions/{region_name}/Wk{lead}_testing'\n",
    "    try:\n",
    "        prediction_ = np.load(f'{predictions_directory}/Wk{lead}_testing_{ex_name}_regular_RZSM.npy')\n",
    "        cont = True\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            prediction_ = np.load(f'{predictions_directory}/Wk{lead}_testing_{ex_name}_RZSM.npy')\n",
    "            cont = True\n",
    "        except FileNotFoundError:\n",
    "            cont = False\n",
    "\n",
    "    if cont:\n",
    "        print(f'Test prediction shape: {prediction_.shape}')\n",
    "        prediction_RZSM = verifications.reverse_min_max_scaling(prediction_[-1,:,:,:],region_name, day_num, 'GEFSv12',2019)\n",
    "        print(f'Shape of prediction RZSM: {prediction_RZSM.shape}')\n",
    "    \n",
    "        #Convert back to np.nan values for the ocean and other water bodies\n",
    "        prediction_RZSM = np.where(np.isnan(obs_RZSM),np.nan,prediction_RZSM.squeeze())\n",
    "    \n",
    "        return(prediction_RZSM, obs_RZSM)\n",
    "    else:\n",
    "        return(np.zeros(shape=obs_RZSM.shape), obs_RZSM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "93a4033f-958d-4bc3-b0e7-29f9e98e0a3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def setup_binary_for_hit_rate_with_ensemble_mean(week_lead, region_name, test_start, test_end, unet_file):\n",
    "\n",
    "    #Test \n",
    "    # week_lead=1\n",
    "    # percentile_eval = 20\n",
    "\n",
    "    #Save dir\n",
    "    save_dir = f'Data/correct_anomaly_percentile_statistics/{region_name}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "\n",
    "    save_ecmwf = f'{save_dir}/Wk{week_lead}_ecmwf_stats_TP_FP_ensemble_mean.npy'\n",
    "    save_gefs = f'{save_dir}/Wk{week_lead}_gefs_stats_TP_FP_ensemble_mean.npy'\n",
    "    save_xg = f'{save_dir}/Wk{week_lead}_xgboost_stats_TP_FP_ensemble_mean.npy'\n",
    "    save_obs_binary = f'{save_dir}/Wk{week_lead}_obs_stats_TP_FP_ensemble_mean.npy'\n",
    "\n",
    "    day_num = (week_lead*7) -1\n",
    "        \n",
    "    print('Loading observation and baseline anomaly files')\n",
    "    obs, gefs, ecmwf, var_OUT_overwrite, template_testing_only_by_lead= select_data_by_lead(obs_anomaly_SubX_format, baseline_anomaly, baseline_ecmwf, var_OUT, template_testing_only, day_num)\n",
    "    \n",
    "    obs_percent = obs_anom_percentile.sel(L=day_num).sel(M=0)\n",
    "    obs_percent['95th_percentile'].shape #(104, 48, 96)\n",
    "\n",
    "\n",
    "    file = baseline_anomaly\n",
    "    file.RZSM.shape\n",
    "    out_check_gefs_base = np.zeros(shape=(104,11,48,96,8)) #Adding 8 channels for the different anomaly spreads\n",
    "    \n",
    "    out_check_gefs_base[:,:,:,:] = np.nan\n",
    "    out_check_ecmwf_base = out_check_gefs_base.copy()\n",
    "    out_check_unet = out_check_gefs_base.copy()\n",
    "    \n",
    "    \n",
    "    obs_binary_out =np.zeros(shape=(104,48,96,8)) #Adding 8 channels for the different anomaly spreads\n",
    "\n",
    "    final_perc_gefs = np.zeros(shape=(104,48,96,8)) #Adding 8 channels for the different anomaly spreads\n",
    "    final_perc_gefs[:,:,:] = np.nan\n",
    "    final_perc_ecmwf = final_perc_gefs.copy()\n",
    "    final_perc_unet = final_perc_gefs.copy()\n",
    "    \n",
    "    \n",
    "\n",
    "    test_name = unet_file.split('testing_')[-1].split('.npy')[0].split('ensemble_')[-1]\n",
    "    save_unet = f'{save_dir}/Wk{week_lead}_unet_stats_{test_name}_TP_FP_ensemble_mean.npy'\n",
    "    \n",
    "    test =  verifications.reverse_min_max_scaling(np.load(unet_file), region_name, day_num)[2,:,:,:,0] #We only want the last channel\n",
    "    test = np.reshape(test,(test.shape[0]//11,11,test.shape[1],test.shape[2]))\n",
    "    test.shape\n",
    "\n",
    "    #Now mask the input\n",
    "    test_unet = np.where(mask_anom == 1,test,np.nan)\n",
    "\n",
    "    #XGBoost\n",
    "    #Load the XGBoost data\n",
    "    if region_name == 'CONUS':\n",
    "        out_check_xg = out_check_gefs_base.copy()\n",
    "        final_perc_xg = final_perc_gefs.copy()\n",
    "        \n",
    "        xgboost_files = sorted(glob(f'predictions_XGBOOST/{region_name}/Wk{week_lead}_testing/*EX28*'))[0]\n",
    "    \n",
    "        # break\n",
    "        #Still working here\n",
    "        test_name = xgboost_files.split('testing_')[-1].split('.npy')[0]\n",
    "        load_ = np.expand_dims(np.load(xgboost_files),-1)\n",
    "        load_.shape\n",
    "        load_ = np.where(load_ == 0,np.nan,load_)\n",
    "        load_ =  verifications.reverse_min_max_scaling(load_, region_name, day_num)#We only want the last channel\n",
    "        \n",
    "        xg = np.empty(shape=(load_.shape[0],11,load_.shape[1],load_.shape[2],load_.shape[3])) #This will help with climpred functions\n",
    "        for j in range(11):\n",
    "            xg[:,j,:,:,:] = load_\n",
    "    \n",
    "        xg = xg.squeeze()\n",
    "        xg.shape\n",
    "        x_vals = np.nanmean(xg,axis=1)\n",
    "    else:\n",
    "        x_vals = out_check_gefs_base.copy()\n",
    "    #Check if the predicted anomaly is below each threshold\n",
    "\n",
    "\n",
    "    \n",
    "    #Test\n",
    "    # idx = 0\n",
    "    # mx = 0\n",
    "    # ix = 10\n",
    "    # iy =10 #NEGATIVE ANOMALY VALUE\n",
    "    # iy =5 #POSITIVE ANOMALY VALUE\n",
    "\n",
    "    #Use np.where to find the values of the percentile\n",
    "\n",
    "    #Take ensemble mean\n",
    "    o_vals = np.nanmean(obs.RZSM[:,:,0,:,:].values,axis=1)\n",
    "    g_vals =  np.nanmean(gefs.RZSM[:,:,0,:,:].values,axis=1)\n",
    "    e_vals =  np.nanmean(ecmwf.RZSM[:,:,0,:,:].values,axis=1)\n",
    "    u_vals = np.nanmean(test_unet,axis=1)\n",
    "    \n",
    "\n",
    "    #Keep all models the same\n",
    "    # o_vals = obs.RZSM[:,:,0,:,:].values\n",
    "    # g_vals =  gefs.RZSM[:,:,0,:,:].values\n",
    "    # e_vals =  ecmwf.RZSM[:,:,0,:,:].values\n",
    "    # u_vals = test_unet\n",
    "    # x_vals = xg\n",
    "\n",
    "    u_vals.shape\n",
    "    x_vals.shape\n",
    "\n",
    "    def check_if_below_percentile(obs_percent, percentile_num, o_vals, g_vals, e_vals, u_vals, x_vals):\n",
    "        perc_= obs_percent[f'{percentile_num}th_percentile'].values\n",
    "        \n",
    "        def find_percentage(perc_,o_vals,fcst):\n",
    "            fcst =  np.where(fcst<perc_,1,0)\n",
    "            obs_binary = np.where((o_vals<perc_),1,0)\n",
    "            '''Take the mean to find the probability of correct'''\n",
    "            fcst.shape #(104, 48, 96)\n",
    "            #Now mask the input of CONUS/region\n",
    "            fcst = np.where(mask_anom == 1,fcst,np.nan)\n",
    "            obs_binary = np.where(mask_anom == 1,obs_binary,np.nan)\n",
    "\n",
    "            return(fcst,obs_binary)\n",
    "\n",
    "        g_perc,obs_binary = find_percentage(perc_,o_vals,g_vals)\n",
    "        g_perc.shape\n",
    "        e_perc,obs_binary = find_percentage(perc_,o_vals,e_vals)\n",
    "        u_perc,obs_binary  = find_percentage(perc_,o_vals,u_vals)\n",
    "        x_perc,obs_binary  = find_percentage(perc_,o_vals,x_vals)\n",
    "        return(g_perc,e_perc,u_perc,x_perc,obs_binary )\n",
    "\n",
    "    for idx,percentile_num in enumerate([5,10,20,33]):\n",
    "        final_perc_gefs[:,:,:,idx], final_perc_ecmwf[:,:,:,idx], final_perc_unet[:,:,:,idx],final_perc_xg[:,:,:,idx],obs_binary_out[:,:,:,idx] = check_if_below_percentile(obs_percent, percentile_num, o_vals, g_vals, e_vals, u_vals, x_vals)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def check_if_above_percentile(obs_percent, percentile_num, o_vals, g_vals, e_vals, u_vals, x_vals):\n",
    "        perc_= obs_percent[f'{percentile_num}th_percentile'].values\n",
    "       \n",
    "        def find_percentage(perc_,o_vals,fcst):\n",
    "            fcst =  np.where(fcst>perc_,1,0)\n",
    "            obs_binary = np.where((o_vals>perc_),1,0)\n",
    "            '''Take the mean to find the probability of correct'''\n",
    "            fcst.shape #(104, 48, 96)\n",
    "            #Now mask the input of CONUS/region\n",
    "            fcst = np.where(mask_anom == 1,fcst,np.nan)\n",
    "            obs_binary = np.where(mask_anom == 1,obs_binary,np.nan)\n",
    "\n",
    "            return(fcst,obs_binary)\n",
    "\n",
    "        g_perc,obs_binary  = find_percentage(perc_,o_vals,g_vals)\n",
    "        g_perc.shape\n",
    "        e_perc,obs_binary  = find_percentage(perc_,o_vals,e_vals)\n",
    "        u_perc,obs_binary  = find_percentage(perc_,o_vals,u_vals)\n",
    "        x_perc,obs_binary  = find_percentage(perc_,o_vals,x_vals)\n",
    "        \n",
    "        return(g_perc,e_perc,u_perc,x_perc,obs_binary )\n",
    "    \n",
    "    for idx,percentile_num in enumerate([66,80,90,95]):\n",
    "        '''We are adding 4 to make sure that we get the indices correct, we already added data from below percentiles'''\n",
    "        final_perc_gefs[:,:,:,idx+4], final_perc_ecmwf[:,:,:,idx+4], final_perc_unet[:,:,:,idx+4], final_perc_xg[:,:,:,idx+4],obs_binary_out[:,:,:,idx+4] = check_if_above_percentile(obs_percent, percentile_num, o_vals, g_vals, e_vals, u_vals, x_vals)\n",
    "\n",
    "    \n",
    "    #Save files for later use\n",
    "    np.save(save_ecmwf,final_perc_ecmwf)\n",
    "    np.save(save_gefs, final_perc_gefs)\n",
    "    np.save(save_unet, final_perc_unet)\n",
    "    np.save(save_xg, final_perc_xg)\n",
    "    np.save(save_obs_binary, obs_binary_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6b8e5a97-0b49-444a-9a23-f6cff79d12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_anomaly_correlation_coefficient_compute(output_dictionary,fcst_RZSM,obs_RZSM,base_RZSM_climpred,\n",
    "                                                    out_name,bias_correction,experiment,dim_order,many_testing_predictions):\n",
    "    #Now create the anomaly correlation coefficient\n",
    "    \n",
    "    if many_testing_predictions == True:\n",
    "        out_name = f'{out_name}_many_predictions'\n",
    "    else:\n",
    "        out_name = f'{out_name}_single_prediction'\n",
    "    \n",
    "    ACC_RZSM_prediction = anomaly_correlation_coefficient_function(var_OUT = np.empty(shape=(fcst_RZSM.RZSM.squeeze().shape)), forecast_converted=fcst_RZSM.RZSM.values.squeeze(), obs_converted = obs_RZSM.squeeze().reshape((104,11,48,96)))\n",
    "    ACC_RZSM_baseline = anomaly_correlation_coefficient_function(np.empty(shape=(fcst_RZSM.RZSM.squeeze().shape)), base_RZSM_climpred.RZSM.values.squeeze(), obs_RZSM.squeeze().reshape((104,11,48,96)))\n",
    "\n",
    "    output_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC{out_name}'] =  ACC_RZSM_prediction  \n",
    "    output_dictionary[f'Wk{lead}_MEM_baseline_RZSM_ACC_no_BC'] =  ACC_RZSM_baseline \n",
    "    output_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_MEM_RZSM_ACC{out_name}'] =  ACC_RZSM_prediction - ACC_RZSM_baseline \n",
    "\n",
    "    \n",
    "    #Additive bias correction\n",
    "#     ACC_RZSM_additive_BC = anomaly_correlation_coefficient_function(var_OUT=np.empty(shape=(corrected_RZSM_additive.sel(L=(lead*7)-1).expand_dims({'L': 1}).transpose(*dim_order).squeeze().RZSM.shape)), forecast_converted=corrected_RZSM_additive.isel(L=lead).RZSM.values, obs_converted=obs_RZSM.squeeze().reshape((104,11,48,96)))\n",
    "#     ACC_RZSM_additive_BC = np.where(np.isnan(obs_RZSM[0,:,:]),np.nan,ACC_RZSM_additive_BC)\n",
    "#     ACC_tmax_additive_BC = anomaly_correlation_coefficient_function(np.empty(shape=(corrected_tmax_additive.sel(L=(lead*7)-1).expand_dims({'L': 1}).transpose(*dim_order).squeeze().tmax.shape)), corrected_tmax_additive.isel(L=lead).tmax.values, obs_tmax.squeeze().reshape((104,11,48,96)))\n",
    "    \n",
    "#     output_dictionary[f'Wk{lead}_baseline_improvement_MEM_RZSM_ACC_additive_BC'] =  ACC_RZSM_additive_BC - ACC_RZSM_baseline\n",
    "#     output_dictionary[f'Wk{lead}_MEM_RZSM_ACC_additive_BC'] = ACC_RZSM_additive_BC\n",
    "    \n",
    "#     output_dictionary[f'Wk{lead}_baseline_improvement_MEM_Tmax_ACC_additive_BC'] =  ACC_tmax_additive_BC - ACC_Tmax_baseline\n",
    "#     output_dictionary[f'Wk{lead}_MEM_Tmax_ACC_additive_BC'] = ACC_tmax_additive_BC\n",
    "    \n",
    "    return(output_dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3d9adef1-6c22-4222-aee4-b9e7e99ba4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_non_post_processed_forecasts(lead,dim_order):\n",
    "    '''We are selecting a single lead time, so use this code'''\n",
    "    if lead == 0:\n",
    "        index_sel = 0\n",
    "    else:\n",
    "        index_sel = (lead*7)-1\n",
    "    \n",
    "    if lead ==0:\n",
    "        RZSM_base_reforecast_climpred = f.restrict_to_CONUS_bounding_box(RZSM_baseline_reforecast_climpred_day0,CONUS_mask).isel(L=index_sel).expand_dims({'L': 1}).transpose(*dim_order)\n",
    "        print_min_max(RZSM_base_reforecast_climpred,'RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)')\n",
    "    elif lead !=0:\n",
    "        RZSM_base_reforecast_climpred = f.restrict_to_CONUS_bounding_box(gefs_anom,mask).sel(L=(lead*7)-1).expand_dims({'L': 1}).transpose(*dim_order)\n",
    "        print_min_max(RZSM_base_reforecast_climpred,'RZSM baseline value from reforecast (training, validation, testing) (no pre-processing other than anomaly computed.)')\n",
    "\n",
    "    if RZSM_or_Tmax_or_both == 'both':\n",
    "        return(RZSM_base_reforecast_climpred,tmax_base_reforecast_climpred)\n",
    "    else:\n",
    "        return(RZSM_base_reforecast_climpred)\n",
    "\n",
    "    '''Then load the actual UNET predictions and keep the observations that are already in a good format for comparison\n",
    "    This data has been loaded, converted back to anomalies, and masked for RZSM for non-land regions'''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d739bf45-b227-47ea-84a8-0bfd172673b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def anomaly_correlation_coefficient(lead,experiment,ACC_dictionary,obs_anom_climp,gef_bc_acc,ecm_bc_acc):\n",
    "    output_dictionary = {}\n",
    "    out_name = ''\n",
    "    \n",
    "    #Must re-add back L as a date\n",
    "    dim_order = ['S','M','Y','X','L']\n",
    "\n",
    "    RZSM_base_reforecast_climpred = return_non_post_processed_forecasts(lead,dim_order) #Returns the original reforecasts\n",
    "    prediction_RZSM,obs_RZSM = load_experiment_predictions_and_observations(lead,experiment,region_name) #Returns the UNET prediction and observations\n",
    "    \n",
    "    #Change name for climpred processing\n",
    "    #Reforecast prediction\n",
    "    prediction_RZSM_climpred = verifications.rename_subx_for_climpred(convert_prediction_to_SubX_format(file=prediction_RZSM,lead=lead,dim_order = dim_order))\n",
    "    prediction_RZSM_climpred  = prediction_RZSM_climpred.rename({'file_name':'RZSM'})\n",
    "    print_min_max(prediction_RZSM_climpred,'RZSM anomaly prediction value from UNET')\n",
    "\n",
    "    \n",
    "    unet_acc = verifications.create_climpred_ACC_no_chunk(prediction_RZSM_climpred, obs_anom_climp)\n",
    "    ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n",
    "\n",
    "    #Base reforecast (before post-processing)\n",
    "    base_RZSM_climpred  = verifications.rename_subx_for_climpred(RZSM_base_reforecast_climpred)\n",
    "    base_RZSM_climpred = base_RZSM_climpred.sel(init=slice(start_testing, None))\n",
    "    print_min_max(base_RZSM_climpred,'RZSM baseline anomaly from reforecast. No post-processing.')\n",
    "\n",
    "    gefs_acc = verifications.create_climpred_ACC_no_chunk(base_RZSM_climpred, obs_anom_climp)\n",
    "\n",
    "    ACC_dictionary[f'Wk{lead}_MEM_baseline_RZSM_ACC'] = np.nanmean(gefs_acc.acc.values)\n",
    "    ACC_dictionary[f'Wk{lead}_GEFS_MEM_BC_baseline_RZSM_ACC'] = np.nanmean(gef_bc_acc.acc.values[lead-1,:,:])\n",
    "    ACC_dictionary[f'Wk{lead}_ECMWF_MEM_BC_baseline_RZSM_ACC'] = np.nanmean(ecm_bc_acc.acc.values[lead-1,:,:])\n",
    "    \n",
    "\n",
    "    return(ACC_dictionary)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6ecc019d-e460-4016-8bd0-75b040172514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ACC(lead,region_name):\n",
    "    print(f'Working on lead {lead}')\n",
    "    # lead=1\n",
    "\n",
    "    save_dict_dir = f'Outputs/crps_mae/{region_name}/Wk_{lead}'\n",
    "    os.system(f'mkdir -p {save_dict_dir}')\n",
    "    \n",
    "    if lead ==0:\n",
    "        experiment_list = [f'EX{i}' for i in range(0,13)]\n",
    "    elif lead <=4:\n",
    "        experiment_list = [f'EX{i}' for i in range(0,30)]\n",
    "    elif lead ==5:\n",
    "        experiment_list = ['EX26']\n",
    "    else:\n",
    "        experiment_list = [f'EX{i}' for i in range(0,27)]\n",
    "    \n",
    "    ACC_dictionary = {}\n",
    "    for experiment in experiment_list:\n",
    "        ACC_dictionary.update(anomaly_correlation_coefficient(lead=lead,experiment=experiment,ACC_dictionary=ACC_dictionary, obs_anom_climp=obs_anom_climp,gef_bc_acc=gef_bc_acc))\n",
    "        \n",
    "    return(ACC_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cca117d1-ce0c-43cc-89a7-7d53c514738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ACC_dictionary.keys())\n",
    "\n",
    "def save_acc_tests(var, ACC_dictionary):\n",
    "\n",
    "    t1 = grab_ACC_from_dict(dict_ = ACC_dictionary, var = var)\n",
    "    # print(acc.keys())\n",
    "\n",
    "    ############################### SINGLE PREDICTION, NO BIAS CORRECTION ##################################################################\n",
    "    # acc = grab_ACC_from_dict(dict_ = ACC_dictionary, var = var)\n",
    "    # t1 = subset_delete(dict_ = acc, subset = 'bias_corrected')\n",
    "    # print(t1.keys())\n",
    "\n",
    "    #Save the average ACC values to a dictionary for later plotting\n",
    "    # t_base = subset_keep(dict_ = t1, subset = 'baseline')\n",
    "    # t_unet= subset_delete(dict_ = t1, subset = 'baseline')\n",
    "    # print(t_base.keys())\n",
    "    # print(t_unet.keys())\n",
    "    \n",
    "    file_path = f'Outputs/permutation_tests/Wk_{lead}'\n",
    "    file_save = f'{file_path}/ACC_vals.pkl'\n",
    "    \n",
    "    os.system(f'mkdir -p {file_path}')\n",
    "    \n",
    "    with open(file_save, 'wb') as file:\n",
    "        pickle.dump(t1, file)\n",
    "\n",
    "    # plot_files_ACC(test_file = t1, var = var, name_of_test = f'{var} Single prediction ACC - No bias correction')\n",
    "\n",
    " \n",
    "    return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b04232d7-ea4f-4380-9d3b-6a6492f70cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_ACC_from_dict(dict_,var):\n",
    "    acc = {key: value for key, value in dict_.items() if f'{var}_ACC' in key}\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "45fd061e-5ef2-4d32-9e01-2ddb19daad0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on lead 1\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.15982161462306976\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.18186791241168976\n",
      "Minimum value in file is -0.1761283278465271\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19063960015773773\n",
      "Minimum value in file is -0.1767590045928955\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.24138320982456207\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2004750818014145\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19575713574886322\n",
      "Minimum value in file is -0.1711311936378479\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21364320814609528\n",
      "Minimum value in file is -0.18573899567127228\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20842571556568146\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.12714390456676483\n",
      "Minimum value in file is -0.20013552904129028\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2724548578262329\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21087075769901276\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19553156197071075\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.24719692766666412\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.17284594476222992\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20098347961902618\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2292362004518509\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20193462073802948\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2193152755498886\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.299274206161499\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.1279548555612564\n",
      "Minimum value in file is -0.20508520305156708\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.12340544164180756\n",
      "Minimum value in file is -0.19970235228538513\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.12591974437236786\n",
      "Minimum value in file is -0.20267271995544434\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2001328021287918\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21780486404895782\n",
      "Minimum value in file is -0.2024918645620346\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.9952380657196045\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.25310784578323364\n",
      "Minimum value in file is -0.2299593836069107\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2466011941432953\n",
      "Minimum value in file is -0.18918319046497345\n",
      "Working on lead 2\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21269601583480835\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.22096821665763855\n",
      "Minimum value in file is -0.19838304817676544\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21908867359161377\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2174537479877472\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2338065207004547\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.31601864099502563\n",
      "Minimum value in file is -0.15944144129753113\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.5762695670127869\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19525614380836487\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.1241493821144104\n",
      "Minimum value in file is -0.20802932977676392\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20887798070907593\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.22749537229537964\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.219393789768219\n",
      "Minimum value in file is -0.22627376019954681\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.27110666036605835\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.16490954160690308\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20930415391921997\n",
      "Minimum value in file is -0.15550486743450165\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21547064185142517\n",
      "Minimum value in file is -0.18361324071884155\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.22040197253227234\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.26021450757980347\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21975621581077576\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19916221499443054\n",
      "Minimum value in file is -0.2154523730278015\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21332937479019165\n",
      "Minimum value in file is -0.2291397750377655\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.1932872235774994\n",
      "Minimum value in file is -0.2222335785627365\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2807915210723877\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.11506399512290955\n",
      "Minimum value in file is -0.21299336850643158\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13184180855751038\n",
      "Minimum value in file is -0.19969968497753143\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13372361660003662\n",
      "Minimum value in file is -0.20663368701934814\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.22191721200942993\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20181116461753845\n",
      "Minimum value in file is -0.1849433183670044\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.24183440208435059\n",
      "Minimum value in file is -0.4620744585990906\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2215965986251831\n",
      "Minimum value in file is -0.24183440208435059\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2385759800672531\n",
      "Minimum value in file is -0.1945461928844452\n",
      "Working on lead 3\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.15248671174049377\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20652511715888977\n",
      "Minimum value in file is -0.13920968770980835\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.22781288623809814\n",
      "Minimum value in file is -0.16482120752334595\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2508757412433624\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.24984455108642578\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.24475592374801636\n",
      "Minimum value in file is -0.1813642680644989\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.22001010179519653\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2077268660068512\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13860785961151123\n",
      "Minimum value in file is -0.19986557960510254\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2484641671180725\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.22463127970695496\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21148914098739624\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.23763030767440796\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.11304321885108948\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2529950737953186\n",
      "Minimum value in file is -0.1227804645895958\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.224217027425766\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21360257267951965\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2515900135040283\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2197757363319397\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20368167757987976\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.223829448223114\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19268137216567993\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2507614493370056\n",
      "Minimum value in file is -0.13937999308109283\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.32990315556526184\n",
      "Minimum value in file is -0.15539243817329407\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13249540328979492\n",
      "Minimum value in file is -0.19188764691352844\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13630801439285278\n",
      "Minimum value in file is -0.18532107770442963\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20139294862747192\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20482099056243896\n",
      "Minimum value in file is -0.1717126965522766\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.21719999611377716\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.17964860796928406\n",
      "Minimum value in file is -0.2142491638660431\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2493806928396225\n",
      "Minimum value in file is -0.1958891600370407\n",
      "Working on lead 4\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2784121036529541\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.1938541680574417\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20146866142749786\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2528459429740906\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.24393294751644135\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13573838770389557\n",
      "Minimum value in file is -0.215907484292984\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13533227145671844\n",
      "Minimum value in file is -0.20772384107112885\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19405578076839447\n",
      "Minimum value in file is -0.18504418432712555\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.14204539358615875\n",
      "Minimum value in file is -0.20560945570468903\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.20955424010753632\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2224252074956894\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21993570029735565\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.2046576589345932\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.06860916316509247\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.12762020528316498\n",
      "Minimum value in file is -0.20963776111602783\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.1389092653989792\n",
      "Minimum value in file is -0.19735828042030334\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.21288524568080902\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.1984323114156723\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19075192511081696\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.3000035285949707\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.16120798885822296\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.19505591690540314\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13781817257404327\n",
      "Minimum value in file is -0.21093912422657013\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13372109830379486\n",
      "Minimum value in file is -0.19896551966667175\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.14391793310642242\n",
      "Minimum value in file is -0.18674950301647186\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.13577251136302948\n",
      "Minimum value in file is -0.18953467905521393\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.0\n",
      "Minimum value in file is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_5310/3797334969.py:19: RuntimeWarning: Mean of empty slice\n",
      "  ACC_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_ACC'] = np.nanmean(unet_acc.acc.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.1914394348859787\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.18363715708255768\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n",
      "RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)\n",
      "Maximum value in file is 0.26432961225509644\n",
      "Minimum value in file is -0.22833965718746185\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Test prediction shape: (3, 1144, 48, 96, 1)\n",
      "Shape of prediction RZSM: (1144, 48, 96, 1)\n",
      "RZSM anomaly prediction value from UNET\n",
      "Maximum value in file is 0.17235352098941803\n",
      "Minimum value in file is -0.22833965718746185\n",
      "RZSM baseline anomaly from reforecast. No post-processing.\n",
      "Maximum value in file is 0.2505298852920532\n",
      "Minimum value in file is -0.19464196264743805\n"
     ]
    }
   ],
   "source": [
    "for lead in [1,2,3,4]:\n",
    "    ACC_dictionary = run_ACC(lead,region_name)\n",
    "    '''As a note, week 1 doesn't ever have any experimental runs for EX18-EX21, also EX26 is not a model that I ran'''\n",
    "    save_acc_tests(var = 'RZSM', ACC_dictionary=ACC_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c64f3b-82d6-49ed-9a07-fd76046bbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "# many_testing_predictions = True\n",
    "# experiment = 'EX0'\n",
    "# lead=1\n",
    "# bias_correction = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c29ea3e1-b12b-4a6b-9633-b526bad79742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_prediction_to_SubX_format(file,lead,dim_order):\n",
    "    if lead == 0:\n",
    "        cp_base = f.restrict_to_CONUS_bounding_box(base_file_testing_day0.copy(deep=True).isel(L=0),mask).expand_dims({'L': 1})\n",
    "    else:                                    \n",
    "        cp_base = f.restrict_to_CONUS_bounding_box(base_file_testing.copy(deep=True).sel(L=(lead*7)-1),mask).expand_dims({'L': 1})\n",
    "\n",
    "    #reshape data back to original format (testing shape)\n",
    "    \n",
    "    cp_base = cp_base.transpose(*dim_order)\n",
    "    \n",
    "    #Reshape prediction file\n",
    "    file = file.reshape((104,11,48,96,1))\n",
    "    \n",
    "    var_OUT = xr.Dataset(\n",
    "            data_vars = dict(\n",
    "                file_name = (['S','M','Y','X','L'],  file[:,:,:,:,:]),\n",
    "            ),\n",
    "            coords = dict(\n",
    "                S = cp_base.S.values,\n",
    "                X = cp_base.X.values,\n",
    "                Y = cp_base.Y.values,\n",
    "                L = cp_base.L.values,\n",
    "                M = cp_base.M.values,\n",
    "\n",
    "            ),\n",
    "            attrs = dict(\n",
    "                Description = 'New data added to file'),\n",
    "        )  \n",
    "\n",
    "\n",
    "    \n",
    "    return(var_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf0d63-3835-4001-9e97-966d7b717694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lead(file,dim_order,lead):\n",
    "    return(file.sel(L=(lead*7)-1).expand_dims({'L': 1}).transpose(*dim_order))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461ab70-6fca-438c-8adf-12bed6e41a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Testing\n",
    "# lead=1\n",
    "# experiment='EX0'\n",
    "# train_end = 2015\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# def run_climpred_for_Experiment(lead,experiment, train_end, \n",
    "#                                 obs_RZSM_file_for_climpred, obs_tmax_file_for_climpred,\n",
    "#                                 RZSM_baseline_reforecast_climpred, tmax_baseline_reforecast_climpred,\n",
    "#                                 base_file_testing,bias_correction,many_testing_predictions=False):\n",
    "#     '''Returns the CRPS and MAE and ACC values for CONUS. Saves into a dictionary'''\n",
    "        \n",
    "#     out_dictionary = {}\n",
    "    \n",
    "#     #Must re-add back L as a date\n",
    "#     dim_order = ['S','M','Y','X','L']\n",
    "#     RZSM_base_reforecast_climpred, tmax_base_reforecast_climpred = return_original_forecasts(lead,dim_order)\n",
    "    \n",
    "#     if bias_correction  == True:\n",
    "#         out_name = '_bias_corrected'\n",
    "#     else:\n",
    "#         out_name = ''\n",
    "        \n",
    "#     print(f'Prediction RZSM shape = {prediction_RZSM.shape}')\n",
    "#     print(f'Prediction Tmax shape = {prediction_tmax.shape}')\n",
    "#     print(f'Obs RZSM shape = {obs_RZSM_for_mae.shape}')\n",
    "#     print(f'Obs Tmax shape = {obs_tmax_for_mae.shape}')\n",
    "    \n",
    "\n",
    "#     #Find the mean absolute error over all predictions from each ensemble member\n",
    "#     # out_dictionary[f'Wk{lead}_{experiment}_RZSM_MAE'] = np.abs(np.nanmean(obs_RZSM_for_mae-prediction_RZSM,axis=0))\n",
    "#     # out_dictionary[f'Wk{lead}_{experiment}_Tmax_MAE'] = np.abs(np.nanmean(obs_tmax_for_mae-prediction_tmax,axis=0))\n",
    "    \n",
    "#     prediction_MAE_RZSM = np.abs(np.nanmean(obs_RZSM_for_mae - prediction_RZSM,axis=0))\n",
    "#     prediction_MAE_Tmax = np.abs(np.nanmean(obs_tmax_for_mae - prediction_tmax,axis=0))\n",
    "    \n",
    "#     convert_obs_to_compare_baseline_rzsm = np.abs(np.nanmean(np.subtract(obs_RZSM_for_mae.reshape((104,11,48,96,1)),RZSM_base_reforecast_climpred.RZSM.values).squeeze(),axis=(0,1)))\n",
    "#     try:\n",
    "#         convert_obs_to_compare_baseline_tmax = np.abs(np.nanmean(np.subtract(obs_tmax_for_mae.reshape((104,11,48,96,1)),tmax_base_reforecast_climpred.tasmax.values).squeeze(),axis=(0,1)))\n",
    "#     except AttributeError:\n",
    "#         convert_obs_to_compare_baseline_tmax = np.abs(np.nanmean(np.subtract(obs_tmax_for_mae.reshape((104,11,48,96,1)),tmax_base_reforecast_climpred.tmax.values).squeeze(),axis=(0,1)))\n",
    "    \n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_RZSM_MAE{out_name}'] = np.subtract(convert_obs_to_compare_baseline_rzsm,prediction_MAE_RZSM)\n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_Tmax_MAE{out_name}'] =  np.subtract(convert_obs_to_compare_baseline_tmax, prediction_MAE_Tmax)\n",
    "    \n",
    "#     #Change name for climpred processing\n",
    "#     #Reforecast prediction\n",
    "#     prediction_RZSM_climpred = f.rename_subx_for_climpred(convert_prediction_to_SubX_format(prediction_RZSM,lead,dim_order))\n",
    "#     print_min_max(prediction_RZSM_climpred,'RZSM anomaly prediction value from UNET')\n",
    "    \n",
    "#     # out_dictionary[f'Wk{lead}_baseline_RZSM_MAE'] = convert_obs_to_compare_baseline\n",
    "\n",
    "    \n",
    "#     prediction_tmax_climpred  = f.rename_subx_for_climpred(convert_prediction_to_SubX_format(prediction_tmax,lead,dim_order))\n",
    "#     prediction_tmax_climpred  = prediction_tmax_climpred .rename({'RZSM':'tmax'})\n",
    "#     print_min_max(prediction_tmax_climpred,'Tmax anomaly prediction value from UNET')\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # out_dictionary[f'Wk{lead}_baseline_Tmax_MAE'] = convert_obs_to_compare_baseline_tmax\n",
    "        \n",
    "#     #Base reforecast (before post-processing)\n",
    "#     base_RZSM_climpred  = f.rename_subx_for_climpred(RZSM_base_reforecast_climpred)\n",
    "#     base_RZSM_climpred = base_RZSM_climpred.sel(init=slice(start_testing, None))\n",
    "#     print_min_max(base_RZSM_climpred,'RZSM baseline anomaly from reforecast. No post-processing.')\n",
    "    \n",
    "#     base_tmax_climpred  = rename_subx_for_climpred(tmax_base_reforecast_climpred)\n",
    "#     try:\n",
    "#         base_tmax_climpred = base_tmax_climpred.rename({'tasmax':'tmax'})\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "#     base_tmax_climpred = base_tmax_climpred.sel(init=slice(start_testing, None))\n",
    "#     print_min_max(base_tmax_climpred,'Tmax baseline anomaly from reforecast. No post-processing.')\n",
    "    \n",
    "#     #Observations\n",
    "#     obs_RZSM_file_climpred = rename_obs_for_climpred(obs_RZSM_file_for_climpred)\n",
    "#     obs_RZSM_file_climpred = obs_RZSM_file_climpred.rename({'SMsurf':'RZSM'})\n",
    "#     print_min_max(obs_RZSM_file_climpred,'RZSM observations anomaly.')\n",
    "\n",
    "#     obs_tmax_file_climpred = rename_obs_for_climpred(obs_tmax_file_for_climpred)\n",
    "#     obs_tmax_file_climpred = obs_tmax_file_climpred.rename({'mx2t':'tmax'})\n",
    "#     print_min_max(obs_tmax_file_climpred,'Tmax observations anomaly.')\n",
    "    \n",
    "#     #Need to set chunks for climpred functions\n",
    "#     fcst_RZSM,fcst_tmax,base_RZSM,base_tmax = prediction_RZSM_climpred.chunk({'init': -1}), prediction_tmax_climpred.chunk({'init': -1}), base_RZSM_climpred.chunk({'init': -1}), base_tmax_climpred.chunk({'init': -1})\n",
    "\n",
    "#     additive_RZSM_bias = rename_subx_for_climpred(corrected_RZSM_additive.isel(L=lead).expand_dims({'L': 1}).transpose(*dim_order)).chunk({'init': -1})\n",
    "#     additive_tmax_bias = rename_subx_for_climpred(corrected_tmax_additive.isel(L=lead).expand_dims({'L': 1}).transpose(*dim_order)).chunk({'init': -1})\n",
    "    \n",
    "#     verif_RZSM,verif_tmax = obs_RZSM_file_climpred.chunk({'time': -1}), obs_tmax_file_climpred.chunk({'time': -1})\n",
    "#     ######################################### ACC #########################################\n",
    "#     output_dictionary,ACC_RZSM_prediction,ACC_RZSM_baseline,ACC_Tmax_prediction,ACC_Tmax_baseline,ACC_RZSM_additive_BC,ACC_tmax_additive_BC =  return_anomaly_correlation_coefficient_compute(output_dictionary,fcst_RZSM,obs_RZSM_for_mae,base_RZSM,fcst_tmax,obs_tmax_for_mae,base_tmax,corrected_RZSM_additive,corrected_tmax_additive,out_name)\n",
    "    \n",
    "#     #Now create climpred classes for CRPS\n",
    "#     hindcast_prediction_RZSM = climpred.HindcastEnsemble(fcst_RZSM).add_observations(verif_RZSM)\n",
    "#     hindcast_prediction_tmax = climpred.HindcastEnsemble(fcst_tmax).add_observations(verif_tmax)\n",
    "\n",
    "#     hindcast_base_RZSM = climpred.HindcastEnsemble(base_RZSM).add_observations(verif_RZSM)\n",
    "#     hindcast_base_tmax = climpred.HindcastEnsemble(base_tmax).add_observations(verif_tmax)\n",
    "    \n",
    "#     hindcast_base_RZSM_additive_BC = climpred.HindcastEnsemble(additive_RZSM_bias).add_observations(verif_RZSM)\n",
    "#     hindcast_base_tmax_additive_BC = climpred.HindcastEnsemble(additive_tmax_bias).add_observations(verif_tmax)\n",
    "    \n",
    "#     ######################################### CRPS #########################################\n",
    "#     crps_baseline_RZSM = hindcast_base_RZSM.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(RZSM='crps').load()\n",
    "#     prediction_RZSM = hindcast_prediction_RZSM.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(RZSM='crps').load() \n",
    "    \n",
    "#     addtive_bias_RZSM = hindcast_base_RZSM_additive_BC.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(RZSM='crps').load() \n",
    "    \n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_RZSM_CRPS{out_name}'] = crps_baseline_RZSM -   prediction_RZSM\n",
    "#     out_dictionary[f'Wk{lead}_baseline_improvement_RZSM_CRPS{out_name}_additive_BC'] = crps_baseline_RZSM -   addtive_bias_RZSM\n",
    "#     # out_dictionary[f'Wk{lead}_{experiment}_Tmax_Baseline_CRPS']= hindcast_base_tmax.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(tmax='crps').load()\n",
    "\n",
    "    \n",
    "#     crps_baseline_tmax = hindcast_base_tmax.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(tmax='crps').load()\n",
    "#     prediction_tmax =  hindcast_prediction_tmax.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(tmax='crps').load()\n",
    "#     addtive_bias_RZSM = hindcast_base_tmax_additive_BC.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(tmax='crps').load() \n",
    "    \n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_Tmax_CRPS{out_name}'] = crps_baseline_tmax - prediction_tmax\n",
    "#     out_dictionary[f'Wk{lead}_baseline_improvement_Tmax_CRPS{out_name}_additive_BC'] = crps_baseline_tmax - addtive_bias_RZSM\n",
    "    \n",
    "#     ######################################### RANK HISTOGRAM #########################################\n",
    "#     #Now plot the rank histogram\n",
    "#     rank_histogram_RZSM_baseline = hindcast_base_RZSM.verify(metric=\"rank_histogram\", comparison=\"m2o\", dim=[\"member\", \"init\", \"lat\", \"lon\"], alignment=\"maximize\").load().rename(RZSM='rank_histogram')\n",
    "#     rank_histogram_RZSM_prediction = hindcast_prediction_RZSM.verify(metric=\"rank_histogram\", comparison=\"m2o\", dim=[\"member\", \"init\", \"lat\", \"lon\"], alignment=\"maximize\").load().rename(RZSM='rank_histogram')\n",
    "    \n",
    "#     rank_histogram_Tmax_baseline = hindcast_base_tmax.verify(metric=\"rank_histogram\", comparison=\"m2o\", dim=[\"member\", \"init\", \"lat\", \"lon\"], alignment=\"maximize\").load().rename(tmax='rank_histogram')\n",
    "#     rank_histogram_Tmax_prediction = hindcast_prediction_tmax.verify(metric=\"rank_histogram\", comparison=\"m2o\", dim=[\"member\", \"init\", \"lat\", \"lon\"], alignment=\"maximize\").load().rename(tmax='rank_histogram')\n",
    "    \n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_RZSM_rank_histogram{out_name}'] = rank_histogram_RZSM_prediction\n",
    "#     out_dictionary[f'Wk{lead}_baseline_RZSM_rank_histogram'] = rank_histogram_RZSM_baseline\n",
    "    \n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_Tmax_rank_histogram{out_name}'] = rank_histogram_Tmax_prediction\n",
    "#     out_dictionary[f'Wk{lead}_baseline_Tmax_rank_histogram'] = rank_histogram_Tmax_baseline\n",
    "    \n",
    "#     return(out_dictionary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b6d592-5d00-4164-a29d-9732336ee864",
   "metadata": {},
   "source": [
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6c342-4a4a-4be3-992f-9916275c8915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_min_max_of_files(file):\n",
    "    min_ =  []\n",
    "    max_ = []\n",
    "    try:\n",
    "        for f in list(file.keys()):\n",
    "            min_.append(np.nanmin(file[f]))\n",
    "            max_.append(np.nanmax(file[f]))\n",
    "    except TypeError:\n",
    "         for f in list(file.keys()):\n",
    "            min_.append(np.nanmin(file[f].crps))\n",
    "            max_.append(np.nanmax(file[f].crps))\n",
    "            \n",
    "    return(min(min_),max(max_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "222496b8-48b2-4b11-9739-fa46f31403af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "# cmap = 'coolwarm'\n",
    "\n",
    "def plot_files_ACC(test_file, var, name_of_test):\n",
    "    cmap = plt.get_cmap('bwr')    \n",
    "    \n",
    "    save_dir = f'Outputs/crps_mae/Wk_{lead}/{var}_ACC'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    if lead == 0:\n",
    "        row=3\n",
    "        column=5\n",
    "        width = 20\n",
    "        height=10\n",
    "        ex_size = 12\n",
    "    else:\n",
    "        row=6\n",
    "        column=5\n",
    "        width = 30\n",
    "        height=25\n",
    "        ex_size = 16\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        row, column, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(width, height))\n",
    "    axs = axs.flatten()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files(test_file)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    \n",
    "    #For the ACC values\n",
    "    if lead == 0:\n",
    "        text_x = -84  # You may need to adjust this value based on your data\n",
    "        text_y = 27  # You may need to adjust this value based on your data\n",
    "        font_size = 12\n",
    "    else:\n",
    "        text_x = -84  # You may need to adjust this value based on your data\n",
    "        text_y = 27  # You may need to adjust this value based on your data\n",
    "        font_size = 16\n",
    "    \n",
    "    for idx,experiment in enumerate(experiment_list):\n",
    "        data = {key: value for key, value in test_file.items() if experiment in key}\n",
    "        data = list(data.values())[0]\n",
    "        \n",
    "        \n",
    "        mean_vals = round(np.nanmean(data),4)\n",
    "        print(f'Mean value: {mean_vals}')\n",
    "        \n",
    "        v = np.linspace(min_, max_, 30, endpoint=True)\n",
    "\n",
    "        map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                      llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "        x, y = map(*np.meshgrid(lon, lat))\n",
    "        # Adjust the text coordinates based on the actual data coordinates\n",
    "\n",
    "\n",
    "        \n",
    "        # ax.drawmeridians()\n",
    "        try:\n",
    "            norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "        except ValueError:\n",
    "            norm = None\n",
    "        \n",
    "        try:\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "        except TypeError:\n",
    "            data = np.nanmean(data.crps.values,axis=0)\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                      transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "            \n",
    "    \n",
    "        # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "        gl = axs[idx].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                   linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlabels_top = False\n",
    "        gl.ylabels_right = False\n",
    "        if lead != 1:\n",
    "            gl.ylabels_left = False\n",
    "        gl.xformatter = LongitudeFormatter()\n",
    "        gl.yformatter = LatitudeFormatter()\n",
    "        axs[idx].coastlines()\n",
    "        # plt.colorbar(im)\n",
    "        # axs[idx].set_aspect('auto', adjustable=None)\n",
    "        axs[idx].set_aspect('equal')  # this makes the plots better\n",
    "        axs[idx].set_title(experiment,fontsize=ex_size)\n",
    "        axs[idx].text(text_x, text_y, mean_vals, ha='right', va='bottom', fontsize=font_size, color='blue', weight = 'bold')\n",
    "\n",
    "        # Add a colorbar axis at the bottom of the graph\n",
    "        # left, bottom, width, height\n",
    "    \n",
    "    data_non_EX = {key: value for key, value in test_file.items() if 'EX' not in key}\n",
    "    #Don't worry about additive bias right now. I can't figure out why it doesn't work\n",
    "    data_non_EX = {key: value for key, value in data_non_EX.items() if 'no_BC' in key}\n",
    "    \n",
    "    for non_used,data_key in enumerate(data_non_EX):\n",
    "        idx+=1\n",
    "        # break\n",
    "        data = {key: value for key, value in test_file.items() if data_key in key}\n",
    "        data = list(data.values())[0]\n",
    "        mean_vals = round(np.nanmean(data),4)\n",
    "        \n",
    "        v = np.linspace(min_, max_, 30, endpoint=True)\n",
    "\n",
    "        map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                      llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "        x, y = map(*np.meshgrid(lon, lat))\n",
    "\n",
    "\n",
    "        # ax.drawmeridians()\n",
    "        try:\n",
    "            norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "        except ValueError:\n",
    "            norm = None\n",
    "        \n",
    "        try:\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "        except TypeError:\n",
    "            data = np.nanmean(data.crps.values,axis=0)\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                      transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "        # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "        gl = axs[idx].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                   linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlabels_top = False\n",
    "        gl.ylabels_right = False\n",
    "        if lead != 1:\n",
    "            gl.ylabels_left = False\n",
    "        gl.xformatter = LongitudeFormatter()\n",
    "        gl.yformatter = LatitudeFormatter()\n",
    "        axs[idx].coastlines()\n",
    "        # plt.colorbar(im)\n",
    "        # axs[idx].set_aspect('auto', adjustable=None)\n",
    "        axs[idx].set_aspect('equal')  # this makes the plots better\n",
    "        axs[idx].set_title(data_key)\n",
    "        axs[idx].text(text_x, text_y, mean_vals, ha='right', va='bottom', fontsize=font_size, color='blue', weight = 'bold')\n",
    "        \n",
    "        # Add a colorbar axis at the bottom of the graph\n",
    "        # left, bottom, width, height\n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "\n",
    "\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(name_of_test, fontsize=30)\n",
    "    plt.savefig(f'{save_dir}/{name_of_test}.png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c5b561-37c3-4948-94f7-0008e8034b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_rank_histogram(baseline_file,prediction_file, name_of_file):\n",
    "    # prediction_file = rzsm_Rank_histogram_predictions\n",
    "    # baseline_file = rzsm_Rank_histogram_baseline\n",
    "    \n",
    "    # baseline_file = baseline_file.values()\n",
    "    baseline_file = list(baseline_file.values())[0]\n",
    "    \n",
    "    fig, axs = plt.subplots(3,5, figsize=(20, 7))\n",
    "\n",
    "#     fig, axs = plt.subplots(\n",
    "#         3, 5, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(20, 7), gridspec_kw={'height_ratios': [2,2,2]})\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "\n",
    "    # rank_file=rank_histogram_unet\n",
    "    to_df = baseline_file.rank_histogram[:].to_dataframe()\n",
    "    to_df['rank_histogram'] = to_df['rank_histogram'] / \\\n",
    "        to_df['rank_histogram'].sum()\n",
    "    to_df['rank'] = to_df.index\n",
    "    to_df['rank'] = to_df['rank'].astype(int)\n",
    "    to_df.index = to_df['rank']\n",
    "    del to_df['lead']\n",
    "    del to_df['skill']\n",
    "    del to_df['rank']\n",
    "    \n",
    "    print(f'Shape of to_df : {to_df.rank().shape[0]}')\n",
    "    # axs[ax].plot(to_df)\n",
    "    axs[0].bar(np.arange(1,to_df.rank().shape[0]+1),to_df.rank_histogram)\n",
    "    axs[0].set_xlim(1, 12)\n",
    "\n",
    "    # Optionally, adjust tick marks\n",
    "    axs[0].set_xticks(np.arange(1, 13))\n",
    "    # to_df.bar(ax=axs[0], kind='bar', width=1.4)\n",
    "    axs[0].set_title(f'Baseline Rank Histogram')\n",
    "    axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=0)\n",
    "    axs[0].set_ylabel('Relative Frequency', rotation=90)\n",
    "\n",
    "    \n",
    "    for ax,experiment in enumerate(experiment_list):\n",
    "        ax+=1\n",
    "        data = {key: value for key, value in prediction_file.items() if experiment in key}\n",
    "        data = list(data.values())[0]\n",
    "\n",
    "        # rank_file=rank_histogram_unet\n",
    "        to_df = data.rank_histogram[:].to_dataframe()\n",
    "        to_df['rank_histogram'] = to_df['rank_histogram'] / \\\n",
    "            to_df['rank_histogram'].sum()\n",
    "        to_df['rank'] = to_df.index\n",
    "        to_df['rank'] = to_df['rank'].astype(int)\n",
    "        to_df.index = to_df['rank']\n",
    "        del to_df['lead']\n",
    "        del to_df['skill']\n",
    "        del to_df['rank']\n",
    "        \n",
    "        print(f'Shape of to_df : {to_df.rank().shape[0]}')\n",
    "        # axs[ax].plot(to_df)\n",
    "        axs[ax].bar(np.arange(1,to_df.rank().shape[0]+1),to_df.rank_histogram)\n",
    "        axs[ax].set_xlim(1, 12)\n",
    "\n",
    "        # Optionally, adjust tick marks\n",
    "        axs[ax].set_xticks(np.arange(1, 13))\n",
    "        axs[ax].set_title(experiment)\n",
    "        axs[ax].set_xticklabels(axs[ax].get_xticklabels(), rotation=0)\n",
    "        axs[ax].set_ylabel('Relative Frequency', rotation=90)\n",
    "    plt.suptitle(f'{name_of_file} Rank Histogram', fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    out_dir_save = f'{save_dir}/{name_of_file}.png'\n",
    "    plt.savefig(out_dir_save, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a31f6c-cda6-4d37-95a3-cbd962f52aa3",
   "metadata": {},
   "source": [
    "# Plot ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4e029-72a6-464d-b26f-fd5dc95a4942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "# experiment='EX0'\n",
    "# bias_correction=True\n",
    "# many_testing_predictions=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3470674-f336-452c-93e5-70b197283ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def subset_delete(dict_,subset):\n",
    "    keys_to_delete = [key for key in dict_.keys() if subset in key]\n",
    "    for key in keys_to_delete:\n",
    "        del dict_[key]\n",
    "    return(dict_)\n",
    "\n",
    "def subset_keep(dict_,subset):\n",
    "    keys_to_keep = [key for key in dict_.keys() if subset in key]\n",
    "    new_dict = {key: dict_[key] for key in keys_to_keep}\n",
    "    return(new_dict)\n",
    "\n",
    "def subset_update(dict_in, background_dict, subset):\n",
    "    keys_to_keep = [key for key in background_dict.keys() if subset in key]\n",
    "    new_dict = {key: background_dict[key] for key in keys_to_keep}\n",
    "    dict_in.update(new_dict)\n",
    "    return(dict_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe28330-dbb2-4215-b7d4-a548d24ab004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is for all different tests\n",
    "# experiment_list = [f'EX{i}' for i in range(0,13)]\n",
    "\n",
    "# ACC_dictionary = {}\n",
    "# for experiment in experiment_list:\n",
    "#     for many_testing_predictions in [True,False]:\n",
    "#         for bias_correction in [True,False]:\n",
    "#             ACC_dictionary.update(anomaly_correlation_coefficient(lead,corrected_RZSM_additive,corrected_tmax_additive,bias_correction,many_testing_predictions,experiment))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d9fc897-4fc2-4d98-bd7e-3c3c82006114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505bb01-1daf-4510-b649-f5dc86ac16c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade55559-26e3-4909-a2d9-620106d722eb",
   "metadata": {},
   "source": [
    "# Plot CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfbf226-e75e-41fc-84e9-31bc9e6e0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_analysis(lead,bias_correction,many_testing_predictions,experiment):\n",
    "    print(f'Working on Experiment: {experiment}. For bias_correction: {bias_correction}. For many_testing_predictions: {many_testing_predictions}')\n",
    "    \n",
    "    def create_climpred_CRPS(fcst,obs):\n",
    "        fcst_name = list(fcst.keys())[0]\n",
    "        object_ =  climpred.HindcastEnsemble(fcst).add_observations(obs)\n",
    "        return(object_.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"same_inits\").rename({fcst_name:'crps'}).load())\n",
    "\n",
    "        \n",
    "    dim_order = ['S','M','Y','X','L']\n",
    "    \n",
    "    out_dictionary = {}\n",
    "    \n",
    "    if bias_correction  == True:\n",
    "        if many_testing_predictions == True:\n",
    "            out_name = '_bias_corrected_many_predictions'\n",
    "        else:\n",
    "            out_name = '_bias_corrected_single_prediction'\n",
    "    else:\n",
    "        if many_testing_predictions == True:\n",
    "            out_name = '_many_predictions'\n",
    "        else:\n",
    "            out_name = '_single_prediction'\n",
    "    \n",
    "    #Must re-add back L as a date\n",
    "    dim_order = ['S','M','Y','X','L']\n",
    "    \n",
    "    if RZSM_or_Tmax_or_both == 'both':\n",
    "        RZSM_base_reforecast_climpred, tmax_base_reforecast_climpred = return_non_post_processed_forecasts(lead,dim_order) #Returns the original reforecasts\n",
    "        prediction_RZSM,prediction_tmax,obs_RZSM,obs_tmax = load_experiment_predictions_and_observations(lead,experiment,many_testing_predictions,bias_correction) #Returns the UNET prediction and observations\n",
    "    else:\n",
    "        RZSM_base_reforecast_climpred = return_non_post_processed_forecasts(lead,dim_order) #Returns the original reforecasts\n",
    "        prediction_RZSM,obs_RZSM = load_experiment_predictions_and_observations(lead,experiment,many_testing_predictions,bias_correction) #Returns the UNET prediction and observations\n",
    "    ######################################### OBSERVATIONS #########################################\n",
    "    obs_RZSM_climpred = f.rename_obs_for_climpred(obs_RZSM_file_for_climpred).chunk({'time': -1}).rename({'SMsurf':'RZSM'})\n",
    "    print_min_max(obs_RZSM_climpred,'RZSM observations anomaly.')\n",
    "\n",
    "        \n",
    "    ######################################### Reforecast (No post-processing) raw forecasts BASELINE #########################################\n",
    "    #Base reforecast (before post-processing)\n",
    "    if lead ==0:\n",
    "        RZSM_base_reforecast_climpred = f.restrict_to_CONUS_bounding_box(RZSM_baseline_reforecast_climpred_day0,CONUS_mask).isel(L=0).expand_dims({'L': 1}).transpose(*dim_order)\n",
    "        print_min_max(RZSM_base_reforecast_climpred,'RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)')\n",
    "    elif lead !=0:\n",
    "        RZSM_base_reforecast_climpred = f.restrict_to_CONUS_bounding_box(RZSM_baseline_reforecast_climpred,CONUS_mask).sel(L=(lead*7)-1).expand_dims({'L': 1}).transpose(*dim_order)\n",
    "        print_min_max(RZSM_base_reforecast_climpred,'RZSM baseline value from reforecast (no pre-processing other than anomaly computed.)')\n",
    "    \n",
    "\n",
    "\n",
    "    #Reforecast prediction\n",
    "    prediction_RZSM_climpred = f.rename_subx_for_climpred(convert_prediction_to_SubX_format(file=prediction_RZSM,lead=lead,dim_order = dim_order))\n",
    "    prediction_RZSM_climpred  = prediction_RZSM_climpred.rename({'file_name':'RZSM'})\n",
    "    print_min_max(prediction_RZSM_climpred,'RZSM anomaly prediction value from UNET')\n",
    "    \n",
    "    if RZSM_or_Tmax_or_both == 'both':\n",
    "        prediction_tmax_climpred  = f.rename_subx_for_climpred(convert_prediction_to_SubX_format(prediction_tmax,lead,dim_order))\n",
    "        prediction_tmax_climpred  = prediction_tmax_climpred.rename({'file_name':'tmax'})\n",
    "        print_min_max(prediction_tmax_climpred,'Tmax anomaly prediction value from UNET')\n",
    "\n",
    "    #Base reforecast (before post-processing)\n",
    "    RZSM_base_reforecast_climpred = f.rename_subx_for_climpred(RZSM_base_reforecast_climpred)\n",
    "    crps_baseline_RZSM = create_climpred_CRPS(RZSM_base_reforecast_climpred,obs_RZSM_climpred)\n",
    "    print_min_max(crps_baseline_RZSM,'RZSM baseline anomaly from reforecast. No post-processing.')\n",
    "\n",
    "    ######################################### Reforecast prediction #########################################\n",
    "    fcst_RZSM = f.rename_subx_for_climpred(convert_prediction_to_SubX_format(prediction_RZSM,lead,dim_order)).chunk({'init': -1}).rename({'file_name':'RZSM'})\n",
    "    print_min_max(fcst_RZSM,'RZSM anomaly prediction value from UNET')\n",
    "    prediction_RZSM = create_climpred_CRPS(fcst_RZSM,obs_RZSM_climpred)\n",
    "    out_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_RZSM_CRPS{out_name}'] = crps_baseline_RZSM -   prediction_RZSM\n",
    "    out_dictionary[f'Wk{lead}_{experiment}_MEM_RZSM_CRPS{out_name}'] =  prediction_RZSM  \n",
    "    out_dictionary[f'Wk{lead}_MEM_baseline_RZSM_CRPS_no_BC'] =  crps_baseline_RZSM \n",
    "    \n",
    "    \n",
    "    ######################################### Reforecast Additive Bias #########################################\n",
    "    # additive_BC_fcst_RZSM = f.rename_subx_for_climpred(select_lead(corrected_RZSM_additive,dim_order,lead)).chunk({'init': -1})\n",
    "    # print_min_max(additive_BC_fcst_RZSM,'RZSM additive bias from raw forecasts (no post-processing with UNET).')\n",
    "    # addtive_bias_RZSM = create_climpred_CRPS(additive_BC_fcst_RZSM,obs_RZSM_climpred)\n",
    "    # out_dictionary[f'Wk{lead}_baseline_improvement_RZSM_CRPS{out_name}_additive_BC'] = crps_baseline_RZSM -   addtive_bias_RZSM\n",
    "\n",
    "    \n",
    "    \n",
    "    ######################################### CRPS #########################################\n",
    "\n",
    "\n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_RZSM_CRPS{out_name}'] = crps_baseline_RZSM -   prediction_RZSM\n",
    "#     out_dictionary[f'Wk{lead}_baseline_improvement_RZSM_CRPS{out_name}_additive_BC'] = crps_baseline_RZSM -   addtive_bias_RZSM\n",
    "#     # out_dictionary[f'Wk{lead}_{experiment}_Tmax_Baseline_CRPS']= hindcast_base_tmax.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(tmax='crps').load()\n",
    "\n",
    "\n",
    "    \n",
    "#     addtive_bias_RZSM = hindcast_base_tmax_additive_BC.verify(metric=\"crps\", comparison=\"m2o\", dim=\"member\", alignment=\"maximize\").rename(tmax='crps').load() \n",
    "    \n",
    "#     out_dictionary[f'Wk{lead}_{experiment}_baseline_improvement_Tmax_CRPS{out_name}'] = crps_baseline_tmax - prediction_tmax\n",
    "#     out_dictionary[f'Wk{lead}_baseline_improvement_Tmax_CRPS{out_name}_additive_BC'] = crps_baseline_tmax - addtive_bias_RZSM\n",
    "    \n",
    "    \n",
    "    return(out_dictionary)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9ecc1-ad86-4afe-97f8-1a11e8afee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead=4\n",
    "\n",
    "save_dict_dir = f'Outputs/crps_mae/Wk_{lead}'\n",
    "os.system(f'mkdir -p {save_dict_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95917e-eaab-490a-a630-ddfe1dee3a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if lead ==0:\n",
    "    experiment_list = [f'EX{i}' for i in range(0,13)]\n",
    "elif lead ==4:\n",
    "    experiment_list = [f'EX{i}' for i in range(0,12)]\n",
    "    experiment_list2 = [f'EX{i}' for i in range(13,27)] #Couldn't run EX12 due to memory issues\n",
    "    experiment_list = experiment_list + experiment_list2\n",
    "elif lead ==5:\n",
    "    experiment_list = ['EX26']\n",
    "else:\n",
    "    experiment_list = [f'EX{i}' for i in range(0,27)]\n",
    "\n",
    "crps_dictionary = {}\n",
    "for experiment in experiment_list:\n",
    "    # if lead < 3:\n",
    "    #     for many_testing_predictions in [True,False]:\n",
    "    #         for bias_correction in [True,False]:\n",
    "    #             crps_dictionary.update(crps_analysis(lead,bias_correction,many_testing_predictions,experiment))\n",
    "    # else:\n",
    "    for many_testing_predictions in [False]:\n",
    "        for bias_correction in [False]:\n",
    "            crps_dictionary.update(crps_analysis(lead,bias_correction,many_testing_predictions,experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f362ded-7692-4267-9805-0b204a0caf62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_files_CRPS(test_file, var, name_of_test):\n",
    "    # cmap = plt.get_cmap('bwr')    \n",
    "    cmap = 'coolwarm'\n",
    "    save_dir = f'Outputs/crps_mae/Wk_{lead}/{var}_CRPS'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    if lead == 0:\n",
    "        row=3\n",
    "        column=5\n",
    "        width = 20\n",
    "        height=10\n",
    "        ex_size=12\n",
    "    else:\n",
    "        row=6\n",
    "        column=5\n",
    "        width = 30\n",
    "        height=25\n",
    "        ex_size=16\n",
    "    fig, axs = plt.subplots(\n",
    "        row, column, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(width, height))\n",
    "    axs = axs.flatten()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files(test_file)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    \n",
    "    #For the ACC values\n",
    "    if lead == 0:\n",
    "        text_x = -84  # You may need to adjust this value based on your data\n",
    "        text_y = 27  # You may need to adjust this value based on your data\n",
    "        font_size = 12\n",
    "    else:\n",
    "        text_x = -84  # You may need to adjust this value based on your data\n",
    "        text_y = 27  # You may need to adjust this value based on your data\n",
    "        font_size = 16\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files(test_file)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    for idx,experiment in enumerate(experiment_list):\n",
    "        data = {key: value for key, value in test_file.items() if experiment in key}\n",
    "        data = list(data.values())[0]\n",
    "        data = data.mean(dim='init').crps.values\n",
    "        \n",
    "        mean_vals = round(np.nanmean(data),4)\n",
    "        print(f'Mean value: {mean_vals}')\n",
    "        \n",
    "        v = np.linspace(min_, max_, 30, endpoint=True)\n",
    "\n",
    "        map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                      llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "        x, y = map(*np.meshgrid(lon, lat))\n",
    "\n",
    "        \n",
    "        # ax.drawmeridians()\n",
    "\n",
    "        norm = None\n",
    "        \n",
    "        try:\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "        except TypeError:\n",
    "            data = np.nanmean(data.crps.values,axis=0)\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                      transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "            \n",
    "    \n",
    "        # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "        gl = axs[idx].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                   linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlabels_top = False\n",
    "        gl.ylabels_right = False\n",
    "        if lead != 1:\n",
    "            gl.ylabels_left = False\n",
    "        gl.xformatter = LongitudeFormatter()\n",
    "        gl.yformatter = LatitudeFormatter()\n",
    "        axs[idx].coastlines()\n",
    "        # plt.colorbar(im)\n",
    "        # axs[idx].set_aspect('auto', adjustable=None)\n",
    "        axs[idx].set_aspect('equal')  # this makes the plots better\n",
    "        axs[idx].set_title(experiment,fontsize=ex_size)\n",
    "        axs[idx].text(text_x, text_y, mean_vals, ha='right', va='bottom', fontsize=font_size, color='blue', weight = 'bold')\n",
    "\n",
    "        # Add a colorbar axis at the bottom of the graph\n",
    "        # left, bottom, width, height\n",
    "    \n",
    "    data_non_EX = {key: value for key, value in test_file.items() if 'EX' not in key}\n",
    "    #Don't worry about additive bias right now. I can't figure out why it doesn't work\n",
    "    data_non_EX = {key: value for key, value in data_non_EX.items() if 'no_BC' in key}\n",
    "    \n",
    "    for non_used,data_key in enumerate(data_non_EX):\n",
    "        idx+=1\n",
    "        # break\n",
    "        data = {key: value for key, value in test_file.items() if data_key in key}\n",
    "        data = list(data.values())[0]\n",
    "        data = data.mean(dim='init').crps.values\n",
    "        mean_vals = round(np.nanmean(data),4)\n",
    "        \n",
    "        v = np.linspace(min_, max_, 30, endpoint=True)\n",
    "\n",
    "        map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                      llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "        x, y = map(*np.meshgrid(lon, lat))\n",
    "        # Adjust the text coordinates based on the actual data coordinates\n",
    "        text_x = -84  # You may need to adjust this value based on your data\n",
    "        text_y = 27  # You may need to adjust this value based on your data\n",
    "\n",
    "        # ax.drawmeridians()\n",
    "        norm = None\n",
    "        \n",
    "        try:\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "        except TypeError:\n",
    "            data = np.nanmean(data.crps.values,axis=0)\n",
    "            im = axs[idx].contourf(x, y, data, levels=v, extend='both',\n",
    "                      transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "        # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "        gl = axs[idx].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                   linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlabels_top = False\n",
    "        gl.ylabels_right = False\n",
    "        if lead != 1:\n",
    "            gl.ylabels_left = False\n",
    "        gl.xformatter = LongitudeFormatter()\n",
    "        gl.yformatter = LatitudeFormatter()\n",
    "        axs[idx].coastlines()\n",
    "        # plt.colorbar(im)\n",
    "        # axs[idx].set_aspect('auto', adjustable=None)\n",
    "        axs[idx].set_aspect('equal')  # this makes the plots better\n",
    "        axs[idx].set_title(data_key)\n",
    "        axs[idx].text(text_x, text_y, mean_vals, ha='right', va='bottom', fontsize=font_size, color='blue', weight = 'bold')\n",
    "        \n",
    "        # Add a colorbar axis at the bottom of the graph\n",
    "        # left, bottom, width, height\n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "\n",
    "\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(name_of_test, fontsize=30)\n",
    "    plt.savefig(f'{save_dir}/{name_of_test}.png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ad1ad-477c-4674-88d0-e6a74af578b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_crps_from_dict(dict_,var):\n",
    "    acc = {key: value for key, value in dict_.items() if f'{var}_CRPS' in key}\n",
    "    return(acc)\n",
    "\n",
    "def subset_delete(dict_,subset):\n",
    "    keys_to_delete = [key for key in dict_.keys() if subset in key]\n",
    "    for key in keys_to_delete:\n",
    "        del dict_[key]\n",
    "    return(dict_)\n",
    "\n",
    "def subset_keep(dict_,subset):\n",
    "    keys_to_keep = [key for key in dict_.keys() if subset in key]\n",
    "    new_dict = {key: dict_[key] for key in keys_to_keep}\n",
    "    return(new_dict)\n",
    "\n",
    "def subset_update(dict_in, background_dict, subset):\n",
    "    keys_to_keep = [key for key in background_dict.keys() if subset in key]\n",
    "    new_dict = {key: background_dict[key] for key in keys_to_keep}\n",
    "    dict_in.update(new_dict)\n",
    "    return(dict_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2694c-7c91-426b-960e-67bb73a1c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ACC_dictionary.keys())\n",
    "\n",
    "def plot_crps_tests(var):\n",
    "    \n",
    "    acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "    # print(acc.keys())\n",
    "\n",
    "    ############################### SINGLE PREDICTION, NO BIAS CORRECTION ##################################################################\n",
    "    acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "    t1 = subset_delete(dict_ = acc, subset = 'bias_corrected')\n",
    "    # print(t1.keys())\n",
    "\n",
    "    t1 = subset_delete(subset_update(subset_update(subset_delete(subset_keep(dict_ = t1, subset = 'single_prediction'), subset='baseline_improvement'),acc,'no_BC'),acc,'additive_BC'),'baseline_improvement')\n",
    "    # print(t1.keys())\n",
    "    # print(len(list(t1.keys())))\n",
    "\n",
    "    #Save the average ACC values to a dictionary for later plotting\n",
    "    tsave2 = subset_keep(dict_ = t1, subset = 'MEM_RZSM_CRPS_single_prediction')\n",
    "    #save as a numpy array instead of xarray object\n",
    "    tsave = {}\n",
    "    \n",
    "    for k,v in tsave2.items():\n",
    "        # break\n",
    "        tsave[k] = v.crps.mean(dim='init').values\n",
    "    \n",
    "    \n",
    "    t_base2 = subset_keep(dict_ = t1, subset = 'MEM_baseline_RZSM_CRPS_no_BC')\n",
    "    t_base = {}\n",
    "    \n",
    "    for k,v in t_base2.items():\n",
    "        # break\n",
    "        t_base[k] = v.crps.mean(dim='init').values\n",
    "    \n",
    "    tsave[list(t_base.keys())[0]] = t_base[list(t_base.keys())[0]]\n",
    "    \n",
    "    #Also include the baseline reforecast ACC value\n",
    "    \n",
    "    \n",
    "    file_path = f'Outputs/permutation_tests/Wk_{lead}'\n",
    "    file_save = f'{file_path}/CRPS_vals.pkl'\n",
    "    \n",
    "    os.system(f'mkdir -p {file_path}')\n",
    "    \n",
    "    with open(file_save, 'wb') as file:\n",
    "        pickle.dump(tsave, file)\n",
    "\n",
    "    plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Single prediction CRPS - No bias correction')\n",
    "    \n",
    "    \n",
    "    ############################### SINGLE PREDICTION, NO BIAS CORRECTION --  IMPROVEMENT ##################################################################\n",
    "    acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "    t1 = subset_delete(dict_ = acc, subset = 'bias_corrected')\n",
    "    # print(t1.keys())\n",
    "\n",
    "    t1 = subset_keep(subset_update(subset_keep(subset_keep(dict_ = t1, subset = 'single_prediction'), subset='baseline_improvement'),acc,'additive_BC'),'baseline_improvement')\n",
    "    # print(t1.keys())\n",
    "    # print(len(list(t1.keys())))\n",
    "\n",
    "    plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Single prediction CRPS Improvement - No bias correction')\n",
    "    \n",
    "    if lead < 3:\n",
    "        \n",
    "        ############################### MANY PREDICTION, NO BIAS CORRECTION ##################################################################\n",
    "        acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "        t1 = subset_delete(dict_ = acc, subset = 'bias_corrected')\n",
    "        # print(t1.keys())\n",
    "\n",
    "        t1 = subset_delete(subset_update(subset_update(subset_delete(subset_keep(dict_ = t1, subset = 'many_predictions'), subset='baseline_improvement'),acc,'no_BC'),acc,'additive_BC'),'baseline_improvement')\n",
    "        # print(t1.keys())\n",
    "        # print(len(list(t1.keys())))\n",
    "\n",
    "        plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Many prediction CRPS - No bias correction')\n",
    "\n",
    "        ############################### MANY PREDICTION, BIAS CORRECTION ##################################################################\n",
    "        acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "        t1 = subset_keep(dict_ = acc, subset = 'bias_corrected')\n",
    "        # print(t1.keys())\n",
    "\n",
    "        t1 = subset_delete(subset_update(subset_update(subset_delete(subset_keep(dict_ = t1, subset = 'many_predictions'), subset='baseline_improvement'),acc,'no_BC'),acc,'additive_BC'),'baseline_improvement')\n",
    "        # print(t1.keys())\n",
    "        # print(len(list(t1.keys())))\n",
    "\n",
    "        plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Many prediction CRPS - Bias correction')\n",
    "\n",
    "        ############################### SINGLE PREDICTION, BIAS CORRECTION ##################################################################\n",
    "        acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "        t1 = subset_keep(dict_ = acc, subset = 'bias_corrected')\n",
    "        # print(t1.keys())\n",
    "\n",
    "        t1 = subset_delete(subset_update(subset_update(subset_delete(subset_keep(dict_ = t1, subset = 'single_prediction'), subset='baseline_improvement'),acc,'no_BC'),acc,'additive_BC'),'baseline_improvement')\n",
    "        # print(t1.keys())\n",
    "        # print(len(list(t1.keys())))\n",
    "\n",
    "        plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Single prediction CRPS - Bias correction')\n",
    "\n",
    "\n",
    "\n",
    "        ############################### MANY PREDICTION, NO BIAS CORRECTION --  IMPROVEMENT ##################################################################\n",
    "        acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "        t1 = subset_delete(dict_ = acc, subset = 'bias_corrected')\n",
    "        # print(t1.keys())\n",
    "\n",
    "        t1 = subset_keep(subset_update(subset_keep(subset_keep(dict_ = t1, subset = 'many_predictions'), subset='baseline_improvement'),acc,'additive_BC'),'baseline_improvement')\n",
    "        # print(t1.keys())\n",
    "        # print(len(list(t1.keys())))\n",
    "\n",
    "        plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Many prediction CRPS Improvement - No bias correction')\n",
    "\n",
    "        ############################### MANY PREDICTION, BIAS CORRECTION -- Improvement ##################################################################\n",
    "        acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "        t1 = subset_keep(dict_ = acc, subset = 'bias_corrected')\n",
    "        print(t1.keys())\n",
    "\n",
    "        t1 = subset_keep(subset_update(subset_keep(subset_keep(dict_ = t1, subset = 'many_predictions'), subset='baseline_improvement'),acc,'additive_BC'),'baseline_improvement')\n",
    "        # print(t1.keys())\n",
    "        # print(len(list(t1.keys())))\n",
    "\n",
    "        plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Many prediction CRPS Improvement - Bias correction')\n",
    "\n",
    "        ############################### SINGLE PREDICTION, BIAS CORRECTION -- Improvement ##################################################################\n",
    "        acc = grab_crps_from_dict(dict_ = crps_dictionary, var = var)\n",
    "        t1 = subset_keep(dict_ = acc, subset = 'bias_corrected')\n",
    "        # print(t1.keys())\n",
    "        t1 = subset_keep(subset_update(subset_keep(subset_keep(dict_ = t1, subset = 'single_prediction'), subset='baseline_improvement'),acc,'additive_BC'),'baseline_improvement')\n",
    "        # print(t1.keys())\n",
    "        # print(len(list(t1.keys())))\n",
    "        plot_files_CRPS(test_file = t1, var = var, name_of_test = f'{var} Single prediction CRPS Improvement - Bias correction')\n",
    "\n",
    "    #     ############################### MANY PREDICTION, No BIAS CORRECTION -- Improvement ##################################################################\n",
    "    #     acc = grab_ACC_from_dict(dict_ = ACC_dictionary, var = var)\n",
    "    #     t1 = subset_delete(dict_ = acc, subset = 'bias_corrected')\n",
    "    #     # print(t1.keys())\n",
    "\n",
    "    #     t1 = subset_keep(subset_update(subset_keep(subset_keep(dict_ = t1, subset = 'many_predictions'), subset='baseline_improvement'),acc,'additive_BC'),'baseline_improvement')\n",
    "    #     # print(t1.keys())\n",
    "    #     # print(len(list(t1.keys())))\n",
    "\n",
    "    #     plot_files_ACC(test_file = t1, var = var, name_of_test = f'{var} Many prediction ACC Improvement - No Bias correction')\n",
    "\n",
    "    #     ############################### SINGLE PREDICTION, No BIAS CORRECTION -- Improvement ##################################################################\n",
    "    #     acc = grab_ACC_from_dict(dict_ = ACC_dictionary, var = 'RZSM')\n",
    "    #     t1 = subset_delete(dict_ = acc, subset = 'bias_corrected')\n",
    "    #     # print(t1.keys())\n",
    "    #     t1 = subset_keep(subset_update(subset_keep(subset_keep(dict_ = t1, subset = 'single_prediction'), subset='baseline_improvement'),acc,'additive_BC'),'baseline_improvement')\n",
    "    #     # print(t1.keys())\n",
    "    #     # print(len(list(t1.keys())))\n",
    "\n",
    "    #     plot_files_ACC(test_file = t1, var = var, name_of_test = f'{var} Single prediction ACC Improvement - No Bias correction')\n",
    "\n",
    "    return(0)\n",
    "\n",
    "\n",
    "plot_crps_tests(var = 'RZSM')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6e924-999e-474c-95fb-a842b39caaad",
   "metadata": {},
   "source": [
    "# Now make multiple predictions and see if this increases any of the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb29ca-5e1c-4c09-ae33-bcd537f5871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xarray as xr\n",
    "# import numpy as np\n",
    "# from scipy.stats import rankdata\n",
    "\n",
    "# def empirical_quantile_mapping(obs, ref, dim='dates'):\n",
    "#     # Flatten the data along latitude and longitude dimensions\n",
    "#     obs_flat = obs.stack(points=['latitude', 'longitude'])\n",
    "#     ref_flat = ref.stack(points=['latitude', 'longitude'])\n",
    "\n",
    "#     # Get the ranks of the observations and reforecasts\n",
    "#     ranks_obs = rankdata(obs_flat, axis=0) / (len(obs_flat) + 1)\n",
    "#     ranks_ref = rankdata(ref_flat, axis=0) / (len(ref_flat) + 1)\n",
    "\n",
    "#     # Transform ranks to quantiles\n",
    "#     quantiles_obs = ranks_obs / (len(ranks_obs) + 1)\n",
    "#     quantiles_ref = ranks_ref / (len(ranks_ref) + 1)\n",
    "\n",
    "#     # Compute quantile mapping correction\n",
    "#     correction = np.percentile(quantiles_obs, quantiles_ref * 100, axis=0)\n",
    "\n",
    "#     # Apply correction to the reforecasts\n",
    "#     ref_corrected = xr.apply_ufunc(\n",
    "#         np.interp, ref, quantiles_ref, correction, \n",
    "#         input_core_dims=[dim, dim, dim], \n",
    "#         output_core_dims=[dim],\n",
    "#         dask='parallelized',\n",
    "#         output_dtypes=[float],\n",
    "#     )\n",
    "\n",
    "#     return ref_corrected\n",
    "\n",
    "# # Example usage\n",
    "# # Assuming you have 'obs' and 'ref' as xarray DataArrays with the specified dimensions\n",
    "\n",
    "# # Generate some random data for demonstration\n",
    "# dates = pd.date_range('2022-01-01', periods=10)\n",
    "# latitude = np.linspace(-90, 90, 5)\n",
    "# longitude = np.linspace(-180, 180, 5)\n",
    "# models = ['ModelA', 'ModelB']\n",
    "# leads = [1, 2, 3]\n",
    "\n",
    "# obs_data = np.random.rand(len(dates), len(models), len(leads), len(latitude), len(longitude))\n",
    "# ref_data = np.random.rand(len(dates), len(models), len(leads), len(latitude), len(longitude))\n",
    "\n",
    "# obs = xr.DataArray(obs_data, dims=('dates', 'model', 'lead', 'latitude', 'longitude'),\n",
    "#                    coords={'dates': dates, 'model': models, 'lead': leads, 'latitude': latitude, 'longitude': longitude})\n",
    "\n",
    "# ref = xr.DataArray(ref_data, dims=('dates', 'model', 'lead', 'latitude', 'longitude'),\n",
    "#                    coords={'dates': dates, 'model': models, 'lead': leads, 'latitude': latitude, 'longitude': longitude})\n",
    "\n",
    "# # Apply EQM\n",
    "# ref_corrected = empirical_quantile_mapping(obs, ref)\n",
    "\n",
    "# # Print the corrected reforecasts\n",
    "# print(ref_corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884148e-b9a6-4b64-a809-59115bbf3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_obs_RZSM = rename_obs_for_climpred(obs_RZSM_file_climpred_full).chunk({'time': -1}).rename({'SMsurf':'RZSM'})\n",
    "# bias_obs_RZSM['time'].attrs['units'] = 'days'\n",
    "# bias_obs_RZSM = bias_obs_RZSM.RZSM.fillna(0).to_dataset()\n",
    "\n",
    "# bias_obs_tmax = rename_obs_for_climpred(obs_tmax_file_climpred_full).chunk({'time': -1}).drop('time_bnds').rename({'mx2t':'tasmax'})\n",
    "# bias_obs_tmax['time'] = bias_obs_RZSM.time.values\n",
    "# bias_obs_tmax['time'].attrs['units'] = 'days'\n",
    "\n",
    "# bias_ref_RZSM = rename_subx_for_climpred(base_file_RZSM).chunk({'init': -1})\n",
    "# bias_ref_RZSM['lead'] = bias_ref_RZSM['lead'].values.astype(np.float64)\n",
    "# bias_ref_RZSM['lead'].attrs['units'] = 'days'\n",
    "# bias_ref_RZSM = bias_ref_RZSM.RZSM.fillna(0).to_dataset()\n",
    "\n",
    "# bias_ref_tmax = rename_subx_for_climpred(base_file_tmax).chunk({'init': -1})\n",
    "# bias_ref_tmax['lead'] = bias_ref_tmax['lead'].values.astype(np.float64)\n",
    "# bias_ref_tmax['lead'].attrs['units'] = 'days'\n",
    "# bias_ref_tmax['member'] = bias_ref_tmax['member'].values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afde415-0afc-45b3-a070-72ba01e25467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #subset to only the same days as reforecast\n",
    "# bias_obs_RZSM = bias_obs_RZSM.sel(time=bias_ref_RZSM.init.values)\n",
    "# bias_obs_tmax = bias_obs_tmax.sel(time=bias_ref_RZSM.init.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb4cf4-c0e0-4c05-9a7d-54e2d1082bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_RZSM = climpred.HindcastEnsemble(bias_ref_RZSM).add_observations(bias_obs_RZSM)\n",
    "# bias_tmax = climpred.HindcastEnsemble(bias_ref_tmax).add_observations(bias_obs_tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4abf6-1af6-4894-96c6-31961a995618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias = bias_RZSM.verify(\n",
    "#     metric=\"additive_bias\", comparison=\"e2o\", dim='init', alignment=\"same_inits\"\n",
    "# )\n",
    "\n",
    "# bias[v].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ab88f-0c95-426e-93e7-11cbb8c29669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #With a subset (only 1 lat and 1 lon)\n",
    "# bias_obs_RZSM = rename_obs_for_climpred(obs_RZSM_file_climpred_full).chunk({'time': -1}).rename({'SMsurf':'RZSM'}).sel(lat=50,lon=238)\n",
    "# bias_obs_RZSM['time'].attrs['units'] = 'days'\n",
    "# bias_obs_tmax = rename_obs_for_climpred(obs_tmax_file_climpred_full).chunk({'time': -1}).drop('time_bnds').rename({'mx2t':'tasmax'}).sel(lat=50,lon=238)\n",
    "# bias_obs_tmax['time'].attrs['units'] = 'days'\n",
    "\n",
    "# bias_ref_RZSM = rename_subx_for_climpred(base_file_RZSM).chunk({'init': -1}).sel(lat=50,lon=238)\n",
    "# bias_ref_RZSM['lead'] = bias_ref_RZSM['lead'].values.astype(np.float64)\n",
    "# bias_ref_RZSM['lead'].attrs['units'] = 'days'\n",
    "# bias_ref_RZSM['member'] = bias_ref_RZSM['member'].values.astype(np.float32)\n",
    "\n",
    "\n",
    "# bias_ref_tmax = rename_subx_for_climpred(base_file_tmax).chunk({'init': -1}).sel(lat=50,lon=238)\n",
    "# bias_ref_tmax['lead'] = bias_ref_tmax['lead'].values.astype(np.float64)\n",
    "# bias_ref_tmax['lead'].attrs['units'] = 'days'\n",
    "# bias_ref_tmax['member'] = bias_ref_tmax['member'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788355c-4379-4f96-8d8b-02967196c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init=bias_ref_RZSM.coords[\"init\"].sel(init=slice(\"2000-01-05\", \"2015-12-30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a7cf2-37f7-4f66-a339-c2b3d5fefe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dim = train_init.rename({\"init\": \"time\"})\n",
    "dim = \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5739fa-cfdd-447f-80ef-7221f061c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = convert_cftime_to_datetime_coords(bias_RZSM.get_initialized(), 'init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e31408a-4b4f-4248-bf11-dc7701e3d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_RZSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26428ec9-5bc1-48c0-8daa-3529c27471be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = bias_RZSM.verify(\n",
    "    metric=\"additive_bias\", comparison=\"e2o\", dim=[], alignment=\"same_verifs\"\n",
    ")\n",
    "\n",
    "bias[v].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a96761-fe07-437d-a9ba-d275ed3eb9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bias_obs_RZSM[f'{time_name}'] = pd.to_datetime(file[f'{time_name}'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7a0de-d639-4504-b82e-7cdbdde7583e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4f203-da9b-4efd-b485-872843772342",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_kwargs = dict(\n",
    "    metric=\"rmse\", alignment=\"maximize\", dim=\"init\", comparison=\"e2o\", skipna=True\n",
    ")\n",
    "\n",
    "train_init_data_array = bias_ref_RZSM.coords[\"init\"].sel(init=slice(\"2000-01-05\", \"2015-12-30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31d15d-825d-4e51-a434-1da37357ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fair calculates bias for train_time/train_init and drops these data from hindcast\n",
    "bias_removed_RZSM = bias_RZSM.remove_bias(\n",
    "    how=\"modified_quantile\",\n",
    "    alignment=metric_kwargs[\"alignment\"],\n",
    "    train_test_split=\"fair\",\n",
    "    train_init=train_init_data_array,\n",
    "    train_time=slice('2000-01-05','2015-12-30'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cda1e-97db-4423-9d96-bd27cf74e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fair calculates bias for train_time/train_init and drops these data from hindcast\n",
    "bias_removed_tmax = bias_tmax.remove_bias(\n",
    "    how=\"EmpiricalQuantileMapping\",\n",
    "    alignment=metric_kwargs[\"alignment\"],\n",
    "    train_test_split=\"fair\",\n",
    "    train_time=slice(\"2000\", \"2015\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ed8ec-1edd-4dd1-8c72-cf46092a63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(lead,experiment_name):\n",
    "    model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_{experiment_name}',compile=False) #don't need the custom loss function for predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0dbf4-5b29-4536-b334-e5a4b2e970f2",
   "metadata": {},
   "source": [
    "# Empirical quantile mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12556b0d-f7e8-4d90-859a-fcc07f57c955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def empirical_quantile_mapping(obs, ref):\n",
    "#     #Testing\n",
    "#     # obs = obs_RZSM_bias_correct.to_array()\n",
    "#     # ref =  ref_RZSM_anomaly.to_array()\n",
    "    \n",
    "#     # Subset data\n",
    "#     train_obs = obs.sel(S=slice('2000-01-01', '2015-12-31'))\n",
    "#     test_obs = obs.sel(S=slice('2018-01-01', '2019-12-31'))\n",
    "    \n",
    "#     train_reforecasts = ref.sel(S=slice('2000-01-01', '2015-12-31'))\n",
    "#     test_reforecasts = ref.sel(S=slice('2018-01-01', '2019-12-31'))\n",
    "    \n",
    "#     mean_train = train_reforecasts.mean(dim=['S','M'])\n",
    "#     mean_std = train_reforecasts.std(dim=['S','M'])\n",
    "    \n",
    "#     # Calculate quantiles\n",
    "#     obs_quantiles = (train_obs.compute().rank(dim='S') - 1) / (len(train_obs.S) - 1)\n",
    "#     reforecast_quantiles = (train_reforecasts.compute().rank(dim='S') - 1) / (len(train_reforecasts.S) - 1)\n",
    "    \n",
    "#     # Convert DataArrays to datasets with a common dimension\n",
    "#     obs_quantiles_ds = obs_quantiles.to_dataset(name='quantiles')\n",
    "#     reforecast_quantiles_ds = reforecast_quantiles.to_dataset(name='quantiles')\n",
    "\n",
    "#     # Interpolate using the 'S' dimension\n",
    "#     corrected_test_reforecasts_ds = reforecast_quantiles_ds.interp(S=obs_quantiles_ds['S'])\n",
    "\n",
    "#     # Extract the resulting DataArray\n",
    "#     corrected_test_reforecasts = corrected_test_reforecasts_ds['quantiles']\n",
    "    \n",
    "#     # Ensure that corrected_test_reforecasts is in the range [0, 1]\n",
    "#     corrected_test_reforecasts = np.clip(corrected_test_reforecasts, , 1)\n",
    "\n",
    "#     # Reshape to a 2D array where the first dimension is collapsed\n",
    "#     reshaped_data = corrected_test_reforecasts.stack(points=['S', 'X', 'Y'])\n",
    "\n",
    "#     # Applying the inverse transformation (percent-point function) element-wise\n",
    "#     percentiles = np.percentile(reshaped_data, q=np.arange(0, 100.1, 0.1), axis=0)\n",
    "\n",
    "#     # Transforming percentiles back to the original scale\n",
    "#     corrected_values = percentiles * std_train + mean_train\n",
    "    \n",
    "#     # Ensure that corrected_test_reforecasts is in the range [0, 1]\n",
    "#     # corrected_test_reforecasts = corrected_test_reforecasts.fillna(0)\n",
    "#     # corrected_test_reforecasts = np.clip(corrected_test_reforecasts, 0, 1)\n",
    "    \n",
    "    \n",
    "#     # Applying the inverse transformation (percent-point function) element-wise\n",
    "#     corrected_values = np.percentile(corrected_test_reforecasts, q=100 * corrected_test_reforecasts, axis=0) *  + \n",
    "    \n",
    "#     #Now apply the inverse CDF to obtain anomalies\n",
    "#     corrected_values = np.percentile(corrected_test_reforecasts, q=100 * corrected_test_reforecasts, axis=0) *  + \n",
    "\n",
    "    \n",
    "#     return(corrected_test_reforecasts)\n",
    "\n",
    "\n",
    "# RZSM_eqm_corrected = empirical_quantile_mapping(obs_RZSM_bias_correct.to_array(), ref_RZSM_anomaly.to_array())\n",
    "# tmax_eqm_corrected = empirical_quantile_mapping(obs_tmax_bias_correct.to_array(), ref_tmax_anomaly.to_array())\n",
    "\n",
    "# RZSM_quantile_observations = obs_RZSM_bias_correct.to_array()\n",
    "# RZSM_quantile_reforecast = ref_RZSM_anomaly.to_array()\n",
    "\n",
    "\n",
    "# def empirical_quantile_mapping(obs, ref, dim='dates'):\n",
    "#     # Flatten the data along latitude and longitude dimensions\n",
    "#     obs_flat = obs.stack(points=['Y', 'X'])\n",
    "#     ref_flat = ref.stack(points=['Y', 'X'])\n",
    "\n",
    "#     # Get the ranks of the observations and reforecasts\n",
    "#     ranks_obs = rankdata(obs_flat, axis=0) / (len(obs_flat) + 1)\n",
    "#     ranks_ref = rankdata(ref_flat, axis=0) / (len(ref_flat) + 1)\n",
    "\n",
    "#     # Transform ranks to quantiles\n",
    "#     quantiles_obs = ranks_obs / (len(ranks_obs) + 1)\n",
    "#     quantiles_ref = ranks_ref / (len(ranks_ref) + 1)\n",
    "\n",
    "#     # Compute quantile mapping correction\n",
    "#     correction = np.percentile(quantiles_obs, quantiles_ref * 100, axis=0)\n",
    "\n",
    "#     # Apply correction to the reforecasts\n",
    "#     ref_corrected = xr.apply_ufunc(\n",
    "#         np.interp, ref, quantiles_ref, correction, \n",
    "#         input_core_dims=[dim, dim, dim], \n",
    "#         output_core_dims=[dim],\n",
    "#         dask='parallelized',\n",
    "#         output_dtypes=[float],\n",
    "#     )\n",
    "\n",
    "#     return ref_corrected\n",
    "\n",
    "\n",
    "\n",
    "# # Apply EQM\n",
    "# ref_corrected = empirical_quantile_mapping(obs, ref)\n",
    "\n",
    "# # Print the corrected reforecasts\n",
    "# print(ref_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7f963-e4db-48cb-a42f-338d9a41935b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Data for correcting the bias (observations)\n",
    "# obs_RZSM_bias_correct = create_seasonal_anomaly(xr.open_mfdataset('Data/GLEAM/reformat_to_reforecast_shape/RZSM_weighted/*weighted*').sel(L=slice(0,34)),train_end=train_end,source='reforecast')\n",
    "# #Create the seasonal anomaly for reforecast\n",
    "# ref_RZSM_anomaly = create_seasonal_anomaly(file = base_file_RZSM,train_end=train_end,source='reforecast')\n",
    "\n",
    "# #Find the mean bias over all test years (for additive mean)\n",
    "# RZSM_bias = obs_RZSM_bias_correct.sel(S=slice(None,train_end_string)) - ref_RZSM_anomaly.sel(S=slice(None,train_end_string))\n",
    "\n",
    "# #We are bias correcting the test file (dates after 2018)\n",
    "# #Now correct the data based on the seasonal bias\n",
    "# global corrected_RZSM_additive\n",
    "# corrected_RZSM_additive = additive_bias_correct_by_season(RZSM_bias,RZSM_baseline_reforecast_climpred).isel(L=[0,6,13,20,27,34]).load()\n",
    "\n",
    "\n",
    "# #Data for correcting the bias (observations)\n",
    "# obs_tmax_bias_correct = create_seasonal_anomaly(xr.open_mfdataset('Data/ERA5/reformat_to_reforecast_shape/tmax_2m/*').sel(L=slice(0,34)),train_end=train_end,source='reforecast')\n",
    "# #Create the seasonal anomaly for reforecast\n",
    "# ref_tmax_anomaly = create_seasonal_anomaly(file = base_file_tmax,train_end=train_end,source='reforecast').rename({'tasmax':'tmax'})\n",
    "# tmax_baseline_reforecast_climpred = tmax_baseline_reforecast_climpred.rename({'tasmax':'tmax'})\n",
    "# #Find the mean bias over all test years (for additive mean)\n",
    "# tmax_bias = obs_tmax_bias_correct.sel(S=slice(None,train_end_string)) - ref_tmax_anomaly.sel(S=slice(None,train_end_string))\n",
    "\n",
    "# #We are bias correcting the test file (dates after 2018)\n",
    "# #Now correct the data based on the seasonal bias\n",
    "# global corrected_tmax_additive\n",
    "# corrected_tmax_additive = additive_bias_correct_by_season(bias_file=tmax_bias,test_file=tmax_baseline_reforecast_climpred).isel(L=[0,6,13,20,27,34]).load()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu_new]",
   "language": "python",
   "name": "conda-env-tf212gpu_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
