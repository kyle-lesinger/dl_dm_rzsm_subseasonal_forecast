{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51fd071-9238-4e03-982e-68dafa29e04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 19:10:00.292548: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-17 19:10:00.340736: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-17 19:10:01.143648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "/glade/derecho/scratch/klesinger/FD_RZSM_deep_learning\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image \n",
    "from tensorflow.python.data.ops import dataset_ops\n",
    "import dask\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from io import StringIO\n",
    "from keras.layers import Input\n",
    "import keras as k\n",
    "from contextlib import redirect_stdout\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import bottleneck as bn\n",
    "from tensorflow.keras import mixed_precision\n",
    "import csv\n",
    "\n",
    "from function import addPredictors as pred\n",
    "from function import channelExperiment as CE\n",
    "from function import loadDataWeek0 as loadDataWeek0\n",
    "from function import loadValues as lv\n",
    "from function import masks\n",
    "from function import denseValue\n",
    "from function import conf\n",
    "from function import losses\n",
    "from function import funs as f\n",
    "from function import modelRzsmReluExtraConv as UNETRzsm\n",
    "from function import experimentType\n",
    "from function import loadDataAllWeeks as loadData\n",
    "\n",
    "\n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90f1a63-ee8f-4cea-82d5-4af35f88e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla V100-SXM2-32GB, compute capability 7.0\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow RT things\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338104ca-6ab4-4238-943c-0652b54f5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "global region_name,testing_scenario,save_loss_name\n",
    "region_name = 'china' #['australia','CONUS', 'china']\n",
    "\n",
    "global ref_source,reforecast_input,obs_source\n",
    "ref_source = 'ECMWF' #['GEFSv12','ECMWF']\n",
    "obs_source='GLEAM' #['GLEAM','ERA5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d48ca3e-515b-422c-a912-be608cb190c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global final_testing_year\n",
    "final_testing_year = 2019\n",
    "\n",
    "    \n",
    "'''Make sure to fill in this information depending on what test we are doing'''\n",
    "make_single_prediction_from_model_for_testing=True\n",
    "make_additional_predictions_from_model_for_testing = True\n",
    "permutation_test_graphs_create=True\n",
    "bias_correction_predict = False\n",
    "\n",
    "\n",
    "global RZSM_or_Tmax_or_both, num_predictions_testing, num_train_val_predictions\n",
    "RZSM_or_Tmax_or_both = 'RZSM' # for getting the predictor from either RZSM and Tmax ('both') or only RZSM ('RZSM')\n",
    "num_predictions_testing = 25\n",
    "num_train_val_predictions=10\n",
    "\n",
    "#for permutation plot\n",
    "max_RZSM_value,max_tmax_value = 0.05,5\n",
    "\n",
    "#set for the larger memeory ones\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbac262c-ee29-43de-8bb8-9662fac03668",
   "metadata": {},
   "outputs": [],
   "source": [
    "EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX12,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28,EX29 = experimentType.return_experiment_dictionaries(region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638590c-749d-4c6c-85c4-3af63200d242",
   "metadata": {},
   "source": [
    "# Choose different loss and architecture configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30eb77c-8143-4556-b370-ff75098f35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First just re-save the new density value into a new file (it's convoluted but it works)\n",
    "# denseValue.return_dense_value_file(region_name, 0.5) #can chooose 0.5 or 0.8 as the alpha coefficient\n",
    "\n",
    "testing_scenario = 'regular' #['dense', 'regular', 'transformer', 'super_pixel', 'attention', 'denseLarge']\n",
    "assert testing_scenario =='regular', \"You must put the testing_scenario as 'regular for final manuscript results'\"\n",
    "\n",
    "global save_loss_name, loss_fn\n",
    "if ref_source=='ECMWF':\n",
    "    save_loss_name, loss_fn = losses.return_ECMWF_loss_name_and_function(testing_scenario)\n",
    "else:\n",
    "    save_loss_name, loss_fn = losses.return_GEFSv12_loss_name_and_function(testing_scenario)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa26b2-3d09-43c4-90c2-b3adf94d4126",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This script will load data based on specific lead times that we want to experiment with and what Experiments we choose to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe39e5b-a435-4b47-8272-b0fc8c20c1c8",
   "metadata": {},
   "source": [
    "# Week 1 (lead index 6 of the forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf62daf-7f99-475f-bc39-5eefe7c31436",
   "metadata": {
    "tags": []
   },
   "source": [
    "| Ex. Number/Name | Obs. RZSM Inputs | Obs. Other Inputs                    | UNET predicted Inputs (N>=2)     |Reforecast Inputs| Prediction Lead Week/Variables | Activation function | Loss function | Batch size |\n",
    "| ----------------| -----------------| ------------------------------------ | -------------------      |--------          | -------------------| ---------------------| ------------------------| ------------|\n",
    "| 0 - EX0         | None             | None                                 | None                     | RZSM, Wk 1-N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 1 - EX1         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 2 - EX2         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N          |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 3 - EX3         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N         |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 4 - EX4         | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| RZSM Wk 1-N         |  None |  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 5 - EX5         | Wk. lags 1-3   | None                                   | None                   | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 6 - EX6         | Wk. lags 1-6   | None                                     | None                   |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 7 - EX7         | Wk. lags 1-9    | None                                | None                   |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 8 - EX8         | Wk. lags 1-12    | None                                  | None                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 9 - EX9         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 10 - EX10       | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  |Wk N     -  RZSM   |         Relu             | CRPS experimental| 66\n",
    "| 11 - EX11       | Wk. lags 1-9    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 12 - EX12       | Wk. lags 1-12   |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 13 - EX13       | None             | None                                 | None                     | RZSM week N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 14 - EX14         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 15 - EX15         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | None             |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 16 - EX16         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None            |  None|  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 17 - EX17        | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| None            |  None|  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 18 - EX18         | Wk. lags 1-3   | None                                   | RZSM Wk 1-N                 | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 19 - EX19         | Wk. lags 1-6   | None                                     | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 20 - EX20         | Wk. lags 1-9    | None                                | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 21 - EX21         | Wk. lags 1-12    | None                                  | RZSM Wk 1-N                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 22 - EX22         | Wk. lags 1-3   | None                                   | None                   | None | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 23 - EX23         | Wk. lags 1-6   | None                                     | None                   |None  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 24 - EX24         | Wk. lags 1-9    | None                                | None                   |None  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 25 - EX25         | Wk. lags 1-12    | None                                  | None                   |None  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 26 - EX26         | None    | None                                  | None                   |Wk 1-N (choose best models)  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 27 - EX27         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX9)\n",
    "| 28 - EX28         | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bc1a4-0171-4e83-9601-76c524bbf735",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EX 1-4 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Observation driven but with a prediction.\n",
    "# EX 14-17 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Purely observation driven.\n",
    "# EX 5-8 - Testing if adding other observations (pwat, spfh, etc) has an increase or decrease in skill.\n",
    "# EX 18-21 - Seeing if adding the previous week gains additional skill\n",
    "# EX 22-25 - Purely observation driven. Only soil moisture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1674ec3d-e9f4-415d-84b7-cfcd0a50e0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_directory = f'Data/model_npy_input_data/{region_name}/Model_input_data' #For inputs into the model\n",
    "verification_directory = f'Data/model_npy_input_data/{region_name}/Verification_data' #For observation verification\n",
    "start_of_forecast_init = '2000-01-05'\n",
    "end_of_forecast_init = '2019-12-25'\n",
    "\n",
    "global training_size_shape\n",
    "training_size_shape = np.array((9185,48,96))\n",
    "\n",
    "global validation_testing_size_shape\n",
    "validation_testing_size_shape = np.array((1144,48,96))\n",
    "\n",
    "'''This decides how many lag weeks we have for data such as pwat, z200, tmax, etc'''\n",
    "global observation_lag_list_not_RZSM\n",
    "#This is for observations pwat, z200, spfh, tmax, diff_temp variables used as predictors\n",
    "#These are the day lags which were already computed as the 7-day rolling mean\n",
    "\n",
    "observation_lag_list_not_RZSM = [-1,-7,-14] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf1ffb2-5208-4623-bfa8-abb211b826ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For testing\n",
    "# lead=1\n",
    "# num_lags_obs_RZSM = 6\n",
    "# include_lags_obs_pwat_spfh_tmax = True\n",
    "# include_reforecast_or_not=True\n",
    "# deep_supervision = True\n",
    "# initial_learning_rate = 0.0001\n",
    "# beta_1 = 0.9\n",
    "# batch_size=66\n",
    "# epochs=1\n",
    "# shuffle=False\n",
    "# kernel_norm =  None\n",
    "# patience=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705e8a43-188b-46c5-a45f-02a2637c28c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,\n",
    "                             experiment_test,region_name,experiment_name_out,obs_source,ref_source):\n",
    "    \n",
    "    \n",
    "    #Set restrictions. For EX0, we only want to bias correct the forecasts with week lead 1 RZSM and tmax\n",
    "    if experiment_name == 'EX0' or experiment_name == 'EX13':\n",
    "        \n",
    "        #Step 1 load data \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list =  loadData.load_all_data_EX0(lead=lead, \n",
    "                                                                                                                  num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "                                                                                                                  include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "                                                                                                                  include_reforecast_or_not=include_reforecast_or_not,\n",
    "                                                                                                                  observation_lag_list_not_RZSM=observation_lag_list_not_RZSM,\n",
    "                                                                                                                  lag_integer_list=lag_integer_list, \n",
    "                                                                                                                  input_directory=input_directory,\n",
    "                                                                                                                  training_size_shape=training_size_shape,\n",
    "                                                                                                                  validation_testing_size_shape=validation_testing_size_shape,\n",
    "                                                                                                                  RZSM_or_Tmax_or_both=RZSM_or_Tmax_or_both,\n",
    "                                                                                                                  addtl_experiment=addtl_experiment,\n",
    "                                                                                                                  experiment_test=experiment_test,\n",
    "                                                                                                                  final_testing_year=final_testing_year,\n",
    "                                                                                                                  ref_source=ref_source,obs_source=obs_source)\n",
    "\n",
    "        print(f'\\nInput channels will be only week 1 Tmax and RZSM through the current lead {lead} which are also going to be predicted. There are no observations in this experiment\\n')\n",
    "        \n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 1-4 ####################################################################################\n",
    "    elif experiment_name in ['EX1','EX2','EX3','EX4','EX14','EX15','EX16','EX17']:\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "\n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX1_EX2_EX3_EX4_after_week_0(lead=lead, \n",
    "                                                                                                                  num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "                                                                                                                  include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "                                                                                                                  include_reforecast_or_not=include_reforecast_or_not,\n",
    "                                                                                                                  observation_lag_list_not_RZSM=observation_lag_list_not_RZSM,\n",
    "                                                                                                                  lag_integer_list=lag_integer_list, \n",
    "                                                                                                                  input_directory=input_directory,\n",
    "                                                                                                                  training_size_shape=training_size_shape,\n",
    "                                                                                                                  validation_testing_size_shape=validation_testing_size_shape,\n",
    "                                                                                                                  RZSM_or_Tmax_or_both=RZSM_or_Tmax_or_both,\n",
    "                                                                                                                  addtl_experiment=addtl_experiment,\n",
    "                                                                                                                  experiment_test=experiment_test,\n",
    "                                                                                                                  final_testing_year=final_testing_year,\n",
    "                                                                                                                  ref_source=ref_source,\n",
    "                                                                                                                  obs_source=obs_source,\n",
    "                                                                                                                  experiment_name=experiment_name,\n",
    "                                                                                                                  experiment_name_out=experiment_name_out)\n",
    "    \n",
    "                \n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 5-8 ####################################################################################\n",
    "    elif experiment_name in ['EX5','EX6','EX7','EX8','EX18','EX19','EX20','EX21','EX22','EX23','EX24','EX25']:\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        # #Step 1 load data \n",
    "        # if addtl_experiment == False:\n",
    "        #     final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX5_EX6_EX7_EX8(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "        #                                                                                                    include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list,\n",
    "        #                                                                                                    input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                   # region_name=region_name)\n",
    "        # else:\n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX5_EX6_EX7_EX8_experiments(lead=lead, \n",
    "                                                                                                                  num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "                                                                                                                  include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "                                                                                                                  include_reforecast_or_not=include_reforecast_or_not,\n",
    "                                                                                                                  observation_lag_list_not_RZSM=observation_lag_list_not_RZSM,\n",
    "                                                                                                                  lag_integer_list=lag_integer_list, \n",
    "                                                                                                                  input_directory=input_directory,\n",
    "                                                                                                                  training_size_shape=training_size_shape,\n",
    "                                                                                                                  validation_testing_size_shape=validation_testing_size_shape,\n",
    "                                                                                                                  RZSM_or_Tmax_or_both=RZSM_or_Tmax_or_both,\n",
    "                                                                                                                  addtl_experiment=addtl_experiment,\n",
    "                                                                                                                  experiment_test=experiment_test,\n",
    "                                                                                                                  final_testing_year=final_testing_year,\n",
    "                                                                                                                  ref_source=ref_source,\n",
    "                                                                                                                  obs_source=obs_source,\n",
    "                                                                                                                  experiment_name=experiment_name,\n",
    "                                                                                                                  experiment_name_out=experiment_name_out)\n",
    "\n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 9-12 ####################################################################################\n",
    "    elif (experiment_name == 'EX9') or (experiment_name == 'EX10') or (experiment_name == 'EX11') or (experiment_name == 'EX12') or (experiment_name == 'EX27') or (experiment_name == 'EX28'):\n",
    "        \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX9_EX10_EX11_EX12_after_week_0(lead=lead, \n",
    "                                                                                                                  num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "                                                                                                                  include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "                                                                                                                  include_reforecast_or_not=include_reforecast_or_not,\n",
    "                                                                                                                  observation_lag_list_not_RZSM=observation_lag_list_not_RZSM,\n",
    "                                                                                                                  lag_integer_list=lag_integer_list, \n",
    "                                                                                                                  input_directory=input_directory,\n",
    "                                                                                                                  training_size_shape=training_size_shape,\n",
    "                                                                                                                  validation_testing_size_shape=validation_testing_size_shape,\n",
    "                                                                                                                  RZSM_or_Tmax_or_both=RZSM_or_Tmax_or_both,\n",
    "                                                                                                                  addtl_experiment=addtl_experiment,\n",
    "                                                                                                                  experiment_test=experiment_test,\n",
    "                                                                                                                  final_testing_year=final_testing_year,\n",
    "                                                                                                                  ref_source=ref_source,\n",
    "                                                                                                                  obs_source=obs_source,\n",
    "                                                                                                                  experiment_name=experiment_name,\n",
    "                                                                                                                  experiment_name_out=experiment_name_out)\n",
    "    elif (experiment_name == 'EX26'):\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        final_input_train, final_input_validation, final_input_testing,\n",
    "        channel_list = loadData.load_only_predictions_EX26(lead, input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_name,region_name,\n",
    "                               experiment_name_out)\n",
    "        print('Done')\n",
    "\n",
    "\n",
    "    elif (experiment_name == 'EX29'):\n",
    "        \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX29_after_week_0(lead=lead, \n",
    "                                                                                                                  num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "                                                                                                                  include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "                                                                                                                  include_reforecast_or_not=include_reforecast_or_not,\n",
    "                                                                                                                  observation_lag_list_not_RZSM=observation_lag_list_not_RZSM,\n",
    "                                                                                                                  lag_integer_list=lag_integer_list, \n",
    "                                                                                                                  input_directory=input_directory,\n",
    "                                                                                                                  training_size_shape=training_size_shape,\n",
    "                                                                                                                  validation_testing_size_shape=validation_testing_size_shape,\n",
    "                                                                                                                  RZSM_or_Tmax_or_both=RZSM_or_Tmax_or_both,\n",
    "                                                                                                                  experiment_test=experiment_test,\n",
    "                                                                                                                  ref_source=ref_source,\n",
    "                                                                                                                  obs_source=obs_source,\n",
    "                                                                                                                  experiment_name=experiment_name,\n",
    "                                                                                                                  experiment_name_out=experiment_name_out,\n",
    "                                                                                                                  region_name=region_name,\n",
    "                                                                                                                  final_testing_year=final_testing_year)\n",
    "                                                                                                        \n",
    "\n",
    "    return (final_input_train,final_input_validation,final_input_testing,channel_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84042a9e-5635-447c-a16a-679fcbd7624a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To try and save on memory, only load certain files at a time\n",
    "def return_only_train_validation(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                 observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                 validation_testing_size_shape,experiment_name):\n",
    "    \n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list \\\n",
    "    = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name,obs_source,ref_source)\n",
    "\n",
    "    return(reforecast_train_input, reforecast_validation_input,reforecast_testing_input,channel_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_testing_data_model_training(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name):\n",
    "\n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name,obs_source,ref_source)\n",
    "    return(reforecast_testing_input,channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023cfa8-d5b4-4bc2-8031-d4d71d939e39",
   "metadata": {},
   "source": [
    "# Load Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b606d2ec-7c9c-46a8-96df-1810e8c991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Testing\n",
    "# region_name=region_name\n",
    "# lead = lead_week\n",
    "# num_lags_obs_RZSM=3\n",
    "# include_lags_obs_pwat_spfh_tmax=True\n",
    "# include_reforecast_or_not=True\n",
    "# addtl_experiment = False\n",
    "# experiment_test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e37a45-e7c7-4e62-b3cf-31ef129dbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name,obs_source):\n",
    "    \n",
    "    experiment_name = CE.return_experiment_name(include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test)\n",
    "\n",
    "    if obs_source != 'ERA5':\n",
    "        if testing_scenario == 'None':\n",
    "            save_experiment_name = f'{experiment_name}_RZSM'\n",
    "            experiment_name_out = save_experiment_name\n",
    "        else:\n",
    "            save_experiment_name = f'{experiment_name}_RZSM'\n",
    "            experiment_name_out = f'{experiment_name}_{save_loss_name}_RZSM' #Need to manually change this if using different loss functions to keep track of things\n",
    "    else:\n",
    "        if testing_scenario == 'None':\n",
    "            save_experiment_name = f'{experiment_name}_ERA5_RZSM'\n",
    "            experiment_name_out = f'{experiment_name}_ERA5_RZSM'\n",
    "        else:\n",
    "            save_experiment_name = f'{experiment_name}_ERA5_RZSM'\n",
    "            experiment_name_out = f'{experiment_name}_{save_loss_name}_ERA5_RZSM' #Need to manually change this if using different loss functions to keep track of things\n",
    "             \n",
    "    \n",
    "    global lag_integer_list\n",
    "    lag_integer_list =  CE.return_num_day_lags_from_weekly_lags(num_lags_obs_RZSM) #For number of RZSM observation lags\n",
    "\n",
    "    #Where to save channel information\n",
    "    if ref_source == 'ECMWF':\n",
    "        save_experiment_dir = f'{conf.home}/Data/model_npy_input_data/{region_name}/Wk{lead}_ECMWF_EX_input_data'\n",
    "    else:\n",
    "        save_experiment_dir = f'{conf.home}/Data/model_npy_input_data/{region_name}/Wk{lead}_EX_input_data'\n",
    "    \n",
    "    channel_save_dir = f'{conf.home}/channel_list_information/Wk{lead}'\n",
    "    \n",
    "    checkpoint_filepath = f'{conf.home}/checkpoints/{region_name}/Wk{lead}/Wk{lead}_{experiment_name_out}'\n",
    "    \n",
    "    losses_dir = f'{conf.home}/Losses_with_OBS/{region_name}/Wk{lead}'\n",
    "    \n",
    "    save_checkpoint_dir =f'{conf.home}/checkpoints/{region_name}/Wk{lead}'\n",
    "    \n",
    "    os.system(f'mkdir -p {checkpoint_filepath} {channel_save_dir} {save_experiment_dir} {losses_dir} {save_checkpoint_dir}')\n",
    "\n",
    "    \n",
    "    #Set up files for either saving or loading\n",
    "    training_input_file = f'{save_experiment_dir}/{experiment_name_out}_training_input.npy'\n",
    "    validation_input_file = f'{save_experiment_dir}/{experiment_name_out}_validation_input.npy'\n",
    "    testing_input_file = f'{save_experiment_dir}/{experiment_name_out}_testing_input.npy'\n",
    "\n",
    "    \n",
    "    return(save_experiment_name,experiment_name_out,experiment_name,lag_integer_list,channel_save_dir,\n",
    "           training_input_file,validation_input_file,testing_input_file,checkpoint_filepath,\n",
    "          losses_dir,save_checkpoint_dir,save_experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93274b84-b5c7-4103-9412-2dd052ae1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_inputs(region_name,lead,include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test,ref_source):\n",
    "\n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name,obs_source)\n",
    "\n",
    "    if os.path.exists('redooo.nc'):\n",
    "    # if os.path.exists(training_input_file) and os.path.exists(validation_input_file) and os.path.exists(testing_input_file):\n",
    "        pass\n",
    "    else:\n",
    "        reforecast_train_input, reforecast_validation_input, reforecast_testing_input, channel_list \\\n",
    "        = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,region_name,experiment_name_out,obs_source,ref_source)\n",
    "    \n",
    "        #Save data to file\n",
    "        np.save(training_input_file,tf.convert_to_tensor(reforecast_train_input,dtype=tf.float32))\n",
    "        np.save(validation_input_file,tf.convert_to_tensor(reforecast_validation_input,dtype=tf.float32))\n",
    "        np.save(testing_input_file,tf.convert_to_tensor(reforecast_testing_input,dtype=tf.float32))\n",
    "        \n",
    "        image_size = reforecast_train_input.shape[1:]           \n",
    "        #Save channel list information to txt file\n",
    "    \n",
    "        with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'w') as file:\n",
    "            for idx,element in enumerate(channel_list):\n",
    "                if '-' in element:\n",
    "                    source_='OBSERVATIONS'\n",
    "                else:\n",
    "                    source_='REFORECAST'\n",
    "    \n",
    "                file.write(f'Channel_{idx} is from {source_} with lead or lag {str(element)}' + '\\n')\n",
    "\n",
    "    return(f'Completed writing lead {lead} model input data to {save_experiment_dir}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1cc6fa0-f9ae-4c0a-89db-5bbb73ddff50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size, lead, initial_learning_rate, beta_1,shuffle,patience, kernel_norm,deep_supervision,\n",
    "         num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,include_reforecast_or_not,\n",
    "          number_of_UNET_backbone_max_pool,permutation_test,make_additional_predictions_from_model_for_testing,\n",
    "         input_directory,training_size_shape,validation_testing_size_shape,addtl_experiment,experiment_test,region_name):\n",
    "    \n",
    "#For testing\n",
    "# lead=1\n",
    "# num_lags_obs_RZSM = 3\n",
    "# include_lags_obs_pwat_spfh_tmax = True\n",
    "# include_reforecast_or_not=True\n",
    "# deep_supervision = True\n",
    "# initial_learning_rate = 0.0001\n",
    "# beta_1 = 0.9\n",
    "# batch_size=66\n",
    "# epochs=1\n",
    "# shuffle=False\n",
    "# kernel_norm =  None\n",
    "# patience=10\n",
    "# permutation_test = False\n",
    "    \n",
    "    # print(addtl_experiment)\n",
    "    #Training data\n",
    "    #Needed for calculating the loss for individual UNET predictions (each has 4 predictions for each variable)\n",
    "    def return_training_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_train,-1)))\n",
    "\n",
    "    \n",
    "    #Validation data\n",
    "    def return_validation_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_validation,-1)))\n",
    "\n",
    "    \n",
    "    \n",
    "    def print_shape(file,name):\n",
    "        print(f'Shape of {name} is {file.shape}')\n",
    "        \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name,obs_source)\n",
    "\n",
    "    obs_final_train,obs_final_validation,obs_final_testing = f.load_verification_observations_updated(lead,verification_directory,obs_source)\n",
    "\n",
    "    print(f'\\nExperiment name out is {experiment_name_out}\\n')\n",
    "    # print('This is where the checkpoints will be saved')\n",
    "\n",
    "    print('Loading previously created data')\n",
    "    #Have to do this way because of memory issues\n",
    "    \n",
    "    if number_of_UNET_backbone_max_pool == 4:\n",
    "        if RZSM_or_Tmax_or_both == 'both':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM'),\n",
    "                                                                                 'tmax_output_1': return_training_verification_data('tmax'), 'tmax_output_2': return_training_verification_data('tmax'), 'tmax_output_3': return_training_verification_data('tmax')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM'),\n",
    "                                                                                 'tmax_output_1': return_validation_verification_data('tmax'), 'tmax_output_2': return_validation_verification_data('tmax'), 'tmax_output_3': return_validation_verification_data('tmax')}))\n",
    "            # reforecast_testing_input_tensor = tf.data.Dataset.from_tensor_slices((np.load(testing_input_file),obs_final_testing))\n",
    "            # reforecast_testing_input = np.load(testing_input_file)\n",
    "        elif RZSM_or_Tmax_or_both == 'RZSM':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM')}))\n",
    "\n",
    "        image_size = np.array(list(reforecast_train_input_tensor.element_spec)[0]['input_image'].shape)\n",
    "        \n",
    "    elif number_of_UNET_backbone_max_pool == 5:\n",
    "        if RZSM_or_Tmax_or_both == 'both':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM'),'RZSM_output_4': return_training_verification_data('RZSM'),\n",
    "                                                                                     'tmax_output_1': return_training_verification_data('tmax'), 'tmax_output_2': return_training_verification_data('tmax'), 'tmax_output_3': return_training_verification_data('tmax'),'tmax_output_4': return_training_verification_data('tmax')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM'),'RZSM_output_4': return_validation_verification_data('RZSM'),\n",
    "                                                                                     'tmax_output_1': return_validation_verification_data('tmax'), 'tmax_output_2': return_validation_verification_data('tmax'), 'tmax_output_3': return_validation_verification_data('tmax'), 'tmax_output_4': return_validation_verification_data('tmax')}))\n",
    "        elif RZSM_or_Tmax_or_both == 'RZSM':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM'),'RZSM_output_4': return_training_verification_data('RZSM')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM'),'RZSM_output_4': return_validation_verification_data('RZSM')}))\n",
    "            # reforecast_testing_input_tensor = tf.data.Dataset.from_tensor_slices((np.load(testing_input_file),obs_final_testing))\n",
    "            # reforecast_testing_input = np.load(testing_input_file)\n",
    "\n",
    "        image_size = np.array(list(reforecast_train_input_tensor.element_spec)[0]['input_image'].shape)\n",
    "\n",
    "        # reforecast_train_input = np.load(training_input_file)\n",
    "        # reforecast_validation_input  = np.load(validation_input_file)\n",
    "        # reforecast_testing_input  = np.load(testing_input_file)\n",
    "        # image_size = np.array(reforecast_train_input).shape\n",
    "  \n",
    "    \n",
    "    with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'r') as file:\n",
    "        # Read all lines from the file into a list\n",
    "        channel_list = file.readlines()\n",
    "\n",
    "    # print_shape(reforecast_train_input,'Training input')\n",
    "    # print_shape(reforecast_validation_input,'Validation input')\n",
    "    # print_shape(reforecast_testing_input,'Testing input')\n",
    "    # print_shape(obs_final_train,'Observation verification training')\n",
    "    # print_shape(obs_final_validation,'Observation verification validation')\n",
    "    # print_shape(obs_final_testing,'Observation verification testing')\n",
    "    \n",
    "\n",
    "    print('Actual channel order list')\n",
    "    print(channel_list)\n",
    "\n",
    "    inputs = Input(shape=image_size, name='input_image')\n",
    "    \n",
    "    print('\\nCompiling model\\n')\n",
    "    if RZSM_or_Tmax_or_both =='both':\n",
    "        build_model = UNETRzsmTmax.model_build_func(inputs=inputs, output_channels=1, \n",
    "                               using_deep_supervision=deep_supervision, \n",
    "                               kernel_norm = kernel_norm , var_name='RZSM_Tmax',\n",
    "                              number_of_UNET_backbone_max_pool = number_of_UNET_backbone_max_pool)\n",
    "        model = Model(inputs=inputs,\n",
    "                 outputs = build_model,\n",
    "                 name=\"UNET_tmax_RZSM\")\n",
    "        \n",
    "    elif RZSM_or_Tmax_or_both =='RZSM':\n",
    "        build_model = UNETRzsm.model_build_func(inputs=inputs, output_channels=1, \n",
    "                               using_deep_supervision=deep_supervision, \n",
    "                               kernel_norm = kernel_norm , var_name='RZSM',\n",
    "                              number_of_UNET_backbone_max_pool = number_of_UNET_backbone_max_pool)\n",
    "        model = Model(inputs=inputs,\n",
    "                 outputs = build_model,\n",
    "                 name=\"UNET_RZSM\")\n",
    "\n",
    "\n",
    "    \n",
    "    # print(model.summary())\n",
    "\n",
    "    if number_of_UNET_backbone_max_pool == 4:\n",
    "        if RZSM_or_Tmax_or_both =='both':\n",
    "            model.compile(loss= {'tmax_output_1':loss_fn, 'tmax_output_2':loss_fn, 'tmax_output_3':loss_fn, \n",
    "                                 'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn},\n",
    "                          metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "        elif RZSM_or_Tmax_or_both =='RZSM':\n",
    "            model.compile(loss= {'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn},\n",
    "                      metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "            \n",
    "    elif number_of_UNET_backbone_max_pool == 5:\n",
    "        if RZSM_or_Tmax_or_both =='both':\n",
    "        # With all return channels\n",
    "            model.compile(loss= {'tmax_output_1':loss_fn, 'tmax_output_2':loss_fn, 'tmax_output_3':loss_fn, 'tmax_output_4':loss_fn,\n",
    "                                 'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn, 'RZSM_output_4':loss_fn},\n",
    "                metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "        elif RZSM_or_Tmax_or_both =='RZSM':\n",
    "            model.compile(loss= {'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn, 'RZSM_output_4':loss_fn},\n",
    "                metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "\n",
    "\n",
    "    print(f'\\nCheckpoint is being saved into {save_checkpoint_dir}/Wk{lead}_{experiment_name_out}\\n')\n",
    "\n",
    "    # os.system(f'rm {checkpoint_filepath} -r') #must do this so that we can make a soft link\n",
    "    os.system(f'mkdir -p {save_checkpoint_dir}')\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=save_checkpoint_dir,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "    \n",
    "    my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=patience),model_checkpoint_callback, rlrop] \n",
    "    \n",
    "    unet_history=model.fit(\n",
    "        x=reforecast_train_input_tensor.batch(batch_size), \n",
    "        batch_size=batch_size, epochs=epochs, initial_epoch=0, shuffle=shuffle, callbacks=my_callbacks, \\\n",
    "        validation_data=reforecast_validation_input_tensor.batch(batch_size))\n",
    "\n",
    "    loss_out_df = pd.DataFrame(unet_history.history)\n",
    "    loss_out_df.to_csv(f'{losses_dir}/Wk{lead}_{experiment_name_out}')\n",
    "\n",
    "\n",
    "    ########### MODEL CHECKPOINTS ############################\n",
    "\n",
    "    model.save(f'{save_checkpoint_dir}/Wk{lead}_{experiment_name_out}')\n",
    "    # os.system(f'ln -s {save_checkpoint_dir_out}/Wk{lead}_{experiment_name_out} /glade/work/klesinger/FD_RZSM_deep_learning/{save_checkpoint_dir}/Wk{lead}_{experiment_name_out}')\n",
    "              \n",
    "    return(0)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26c37ba1-26be-47ea-b851-417c89a79bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # #Testing for model runs\n",
    "# permutation_test=False\n",
    "# lead=1\n",
    "# num_lags_obs_RZSM =3\n",
    "# include_lags_obs_pwat_spfh_tmax = True\n",
    "# include_reforecast_or_not=True\n",
    "# deep_supervision = True\n",
    "# initial_learning_rate = 0.0001\n",
    "# beta_1 = 0.9\n",
    "# batch_size=66\n",
    "# epochs=1\n",
    "# shuffle=False\n",
    "# kernel_norm =  None\n",
    "# patience=10\n",
    "# number_of_UNET_backbone_max_pool=4\n",
    "# make_additional_predictions_from_model_for_testing=False\n",
    "# addtl_experiment = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076b03f-80ee-49ad-b256-3450efcd55df",
   "metadata": {},
   "source": [
    "# Run the model for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddec9e60-e784-4dd7-88e9-d3c2aa086c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For experiments, you need to run the script once to make the data. Then restart the kernel to load the data. \n",
    "Otherwise the memory leaks are too high'''\n",
    "def run_EXPERIMENT(lead, num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax ,include_reforecast_or_not,addtl_experiment,experiment_test,region_name,ref_source):\n",
    "    if lead == 5:\n",
    "        patience=15\n",
    "    else:\n",
    "        patience = 10\n",
    "\n",
    "    #Options for num_lags_obs_RZSM weekly lags [ 3,6,9,12 ] ** this inc\n",
    "    #Options for num_lags_obs_pwat_spfh_tmax weekly lags [0 weeks or 2 weeks ]\n",
    "\n",
    "    train(epochs = 100, \n",
    "          batch_size = 66, \n",
    "          lead=lead, \n",
    "          initial_learning_rate=0.0001,\n",
    "          beta_1 = 0.9,\n",
    "          shuffle=False,\n",
    "          patience=patience,\n",
    "          kernel_norm = None,\n",
    "          deep_supervision = True,\n",
    "          num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "          include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "          include_reforecast_or_not=include_reforecast_or_not,\n",
    "          number_of_UNET_backbone_max_pool=4,\n",
    "          permutation_test = False,\n",
    "          make_additional_predictions_from_model_for_testing = False,\n",
    "          input_directory=input_directory,\n",
    "          training_size_shape=training_size_shape,\n",
    "          validation_testing_size_shape=validation_testing_size_shape,\n",
    "          addtl_experiment = addtl_experiment,\n",
    "          experiment_test =experiment_test,\n",
    "          region_name = region_name)\n",
    "    return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0cb1309-91f7-4ce8-bc2b-f4a3432913b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_predictions(lead, include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test, region_name,ref_source):\n",
    "    \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name,obs_source)\n",
    "\n",
    "    ########### MAKE PREDICTIONS ON TRAINING, TESTING, VALIDATION SET ############################\n",
    "    # model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_{experiment_name_out}',compile=False)\n",
    "\n",
    "    print(f'Starting single prediction for Experiment {experiment_name_out}')\n",
    "       \n",
    "    model = load_model(checkpoint_filepath,compile=False) #don't need the custom loss function for predictions\n",
    "    \n",
    "    #Load data\n",
    "    reforecast_training_input = np.load(training_input_file)\n",
    "    reforecast_validation_input = np.load(validation_input_file)\n",
    "    reforecast_testing_input = np.load(testing_input_file)\n",
    "    \n",
    "    ########### SAVE PREDICTIONS (SINGLE PREDICTIONS) ############################\n",
    "    train_val_dir = f'predictions/{region_name}/Wk{lead}_training_validation'\n",
    "    test_dir = f'predictions/{region_name}/Wk{lead}_testing'\n",
    "\n",
    "    os.system(f'mkdir -p {test_dir} {train_val_dir}')\n",
    "\n",
    "    mask = masks.load_mask(region_name)\n",
    "\n",
    "    \n",
    "    print('\\nCurrently only predicting the test dataset\\n')\n",
    "    predictions = model.predict(reforecast_testing_input)\n",
    "    # predictions.shape\n",
    "    np.save(f'{test_dir}/Wk{lead}_testing_{experiment_name_out}.npy',predictions)\n",
    "\n",
    "    print('\\nPredicting training and validation input')\n",
    "    predictions = model.predict(reforecast_training_input)\n",
    "    # predictions.shape\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_training_{experiment_name_out}.npy',predictions)\n",
    "    \n",
    "    predictions = model.predict(reforecast_validation_input)\n",
    "    # predictions.shape\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_validation_{experiment_name_out}.npy',predictions)\n",
    "    \n",
    "    return(f'Completed Experiment {experiment_name_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b03ba3d-c7da-44b0-88b6-2640278ec02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_model_and_prediction(experiment,ref_source):\n",
    "    global lead\n",
    "    for lead in [1,2,3,4]:\n",
    "\n",
    "    \n",
    "        generate_model_inputs(region_name=experiment['region_name'], lead = lead, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'],ref_source=ref_source)\n",
    "    \n",
    "        run_EXPERIMENT(region_name=experiment['region_name'], lead = lead, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'],ref_source=ref_source)\n",
    "    \n",
    "        make_single_predictions(region_name=experiment['region_name'], lead = lead, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'],ref_source=ref_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbea09-b7b1-422e-9ca2-708a8255c53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on setting up data for Experiment EX29 for lead 1\n",
      "\n",
      "Training input shape = (9185, 48, 96, 11)\n",
      "Index idx value is 2. Done adding RZSM obs.\n",
      "Loading observations for pwat_eatm and lag -1\n",
      "Index idx value is 3. Done adding pwat_eatm obs.\n",
      "Loading observations for spfh_2m and lag -1\n",
      "Index idx value is 4. Done adding spfh_2m obs.\n",
      "Loading observations for tmax_2m and lag -1\n",
      "Index idx value is 5. Done adding tmax_2m obs.\n",
      "Loading observations for diff_temp_2m and lag -1\n",
      "Index idx value is 6. Done adding diff_temp_2m obs.\n",
      "Loading observations for hgt_pres and lag -1\n",
      "Index idx value is 7. Done adding hgt_pres obs.\n",
      "Adding current reforecast data from week 1 for vars ['t2m', 'd2m', 'tcw']\n",
      "Index idx value is 8. Done adding t2m reforecast.\n",
      "Index idx value is 9. Done adding d2m reforecast.\n",
      "Index idx value is 10. Done adding tcw reforecast.\n",
      "[[0.50876665 0.50838268 0.50881857 ... 0.48928985 0.48989227 0.49088353]\n",
      " [0.50735468 0.50640953 0.5065304  ... 0.48905164 0.48970482 0.49053466]\n",
      " [0.50351727 0.5024305  0.50261784 ... 0.49078533 0.4911544  0.49152625]\n",
      " ...\n",
      " [0.42813241 0.42569488 0.4251107  ... 0.53738958 0.53729939 0.53962398]\n",
      " [0.42202312 0.41824275 0.41842484 ... 0.54211485 0.54247075 0.54346448]\n",
      " [0.42254141 0.41874033 0.41777006 ... 0.53662175 0.53662586 0.53708744]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 19:11:04.041977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31130 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Loading obs_soilw_bgrnd_GLEAM_lead_1_train_masked.npy\n",
      "\n",
      "Experiment name out is EX29_ECMWF_regular_RZSM\n",
      "\n",
      "Loading previously created data\n",
      "Actual channel order list\n",
      "['Channel_0 is from OBSERVATIONS with lead or lag RZSM_obs_lag-1\\n', 'Channel_1 is from OBSERVATIONS with lead or lag RZSM_obs_lag-7\\n', 'Channel_2 is from OBSERVATIONS with lead or lag RZSM_obs_lag-14\\n', 'Channel_3 is from OBSERVATIONS with lead or lag pwat_obs_lag-1\\n', 'Channel_4 is from OBSERVATIONS with lead or lag spfh_obs_lag-1\\n', 'Channel_5 is from OBSERVATIONS with lead or lag tmax_obs_lag-1\\n', 'Channel_6 is from OBSERVATIONS with lead or lag diff_temp_obs_lag-1\\n', 'Channel_7 is from OBSERVATIONS with lead or lag z200_obs_lag-1\\n', 'Channel_8 is from REFORECAST with lead or lag 2m_temp_ref_lead1\\n', 'Channel_9 is from REFORECAST with lead or lag 2m_dewpoint_ref_lead1\\n', 'Channel_10 is from REFORECAST with lead or lag pwat_eatm_ref_lead1\\n']\n",
      "\n",
      "Compiling model\n",
      "\n",
      "\n",
      "Checkpoint is being saved into /glade/derecho/scratch/klesinger/FD_RZSM_deep_learning/checkpoints/china/Wk1/Wk1_EX29_ECMWF_regular_RZSM\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 19:11:16.646680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype float and shape [9185,48,96,1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2025-03-17 19:11:16.752098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - ETA: 0s - loss: 0.2574 - RZSM_output_1_loss: 0.0978 - RZSM_output_2_loss: 0.0788 - RZSM_output_3_loss: 0.0808 - RZSM_output_1_mae: 0.1055 - RZSM_output_2_mae: 0.0847 - RZSM_output_3_mae: 0.0869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 19:14:12.213703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype float and shape [1144,48,96,1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 188s 902ms/step - loss: 0.2574 - RZSM_output_1_loss: 0.0978 - RZSM_output_2_loss: 0.0788 - RZSM_output_3_loss: 0.0808 - RZSM_output_1_mae: 0.1055 - RZSM_output_2_mae: 0.0847 - RZSM_output_3_mae: 0.0869 - val_loss: 0.4321 - val_RZSM_output_1_loss: 0.1583 - val_RZSM_output_2_loss: 0.1279 - val_RZSM_output_3_loss: 0.1458 - val_RZSM_output_1_mae: 0.1609 - val_RZSM_output_2_mae: 0.1302 - val_RZSM_output_3_mae: 0.1482 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 119s 850ms/step - loss: 0.1074 - RZSM_output_1_loss: 0.0402 - RZSM_output_2_loss: 0.0335 - RZSM_output_3_loss: 0.0337 - RZSM_output_1_mae: 0.0431 - RZSM_output_2_mae: 0.0357 - RZSM_output_3_mae: 0.0360 - val_loss: 0.1985 - val_RZSM_output_1_loss: 0.0672 - val_RZSM_output_2_loss: 0.0621 - val_RZSM_output_3_loss: 0.0692 - val_RZSM_output_1_mae: 0.0697 - val_RZSM_output_2_mae: 0.0642 - val_RZSM_output_3_mae: 0.0714 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 119s 848ms/step - loss: 0.0855 - RZSM_output_1_loss: 0.0308 - RZSM_output_2_loss: 0.0272 - RZSM_output_3_loss: 0.0274 - RZSM_output_1_mae: 0.0329 - RZSM_output_2_mae: 0.0289 - RZSM_output_3_mae: 0.0291 - val_loss: 0.1011 - val_RZSM_output_1_loss: 0.0355 - val_RZSM_output_2_loss: 0.0319 - val_RZSM_output_3_loss: 0.0337 - val_RZSM_output_1_mae: 0.0374 - val_RZSM_output_2_mae: 0.0335 - val_RZSM_output_3_mae: 0.0353 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 119s 848ms/step - loss: 0.0744 - RZSM_output_1_loss: 0.0265 - RZSM_output_2_loss: 0.0238 - RZSM_output_3_loss: 0.0241 - RZSM_output_1_mae: 0.0281 - RZSM_output_2_mae: 0.0251 - RZSM_output_3_mae: 0.0254 - val_loss: 0.0736 - val_RZSM_output_1_loss: 0.0262 - val_RZSM_output_2_loss: 0.0240 - val_RZSM_output_3_loss: 0.0234 - val_RZSM_output_1_mae: 0.0278 - val_RZSM_output_2_mae: 0.0253 - val_RZSM_output_3_mae: 0.0246 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 119s 849ms/step - loss: 0.0685 - RZSM_output_1_loss: 0.0239 - RZSM_output_2_loss: 0.0222 - RZSM_output_3_loss: 0.0223 - RZSM_output_1_mae: 0.0253 - RZSM_output_2_mae: 0.0234 - RZSM_output_3_mae: 0.0234 - val_loss: 0.0670 - val_RZSM_output_1_loss: 0.0250 - val_RZSM_output_2_loss: 0.0211 - val_RZSM_output_3_loss: 0.0208 - val_RZSM_output_1_mae: 0.0266 - val_RZSM_output_2_mae: 0.0223 - val_RZSM_output_3_mae: 0.0220 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 119s 848ms/step - loss: 0.0623 - RZSM_output_1_loss: 0.0218 - RZSM_output_2_loss: 0.0201 - RZSM_output_3_loss: 0.0204 - RZSM_output_1_mae: 0.0229 - RZSM_output_2_mae: 0.0211 - RZSM_output_3_mae: 0.0213 - val_loss: 0.0640 - val_RZSM_output_1_loss: 0.0235 - val_RZSM_output_2_loss: 0.0206 - val_RZSM_output_3_loss: 0.0200 - val_RZSM_output_1_mae: 0.0248 - val_RZSM_output_2_mae: 0.0217 - val_RZSM_output_3_mae: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 119s 850ms/step - loss: 0.0592 - RZSM_output_1_loss: 0.0204 - RZSM_output_2_loss: 0.0194 - RZSM_output_3_loss: 0.0193 - RZSM_output_1_mae: 0.0214 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0201 - val_loss: 0.0629 - val_RZSM_output_1_loss: 0.0232 - val_RZSM_output_2_loss: 0.0200 - val_RZSM_output_3_loss: 0.0196 - val_RZSM_output_1_mae: 0.0244 - val_RZSM_output_2_mae: 0.0210 - val_RZSM_output_3_mae: 0.0206 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 119s 849ms/step - loss: 0.0561 - RZSM_output_1_loss: 0.0194 - RZSM_output_2_loss: 0.0184 - RZSM_output_3_loss: 0.0182 - RZSM_output_1_mae: 0.0203 - RZSM_output_2_mae: 0.0192 - RZSM_output_3_mae: 0.0190 - val_loss: 0.0580 - val_RZSM_output_1_loss: 0.0210 - val_RZSM_output_2_loss: 0.0189 - val_RZSM_output_3_loss: 0.0180 - val_RZSM_output_1_mae: 0.0221 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0189 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 120s 858ms/step - loss: 0.0541 - RZSM_output_1_loss: 0.0187 - RZSM_output_2_loss: 0.0178 - RZSM_output_3_loss: 0.0176 - RZSM_output_1_mae: 0.0195 - RZSM_output_2_mae: 0.0185 - RZSM_output_3_mae: 0.0183 - val_loss: 0.0547 - val_RZSM_output_1_loss: 0.0194 - val_RZSM_output_2_loss: 0.0179 - val_RZSM_output_3_loss: 0.0174 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0187 - val_RZSM_output_3_mae: 0.0182 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 123s 877ms/step - loss: 0.0528 - RZSM_output_1_loss: 0.0181 - RZSM_output_2_loss: 0.0175 - RZSM_output_3_loss: 0.0172 - RZSM_output_1_mae: 0.0189 - RZSM_output_2_mae: 0.0182 - RZSM_output_3_mae: 0.0179 - val_loss: 0.0523 - val_RZSM_output_1_loss: 0.0184 - val_RZSM_output_2_loss: 0.0172 - val_RZSM_output_3_loss: 0.0167 - val_RZSM_output_1_mae: 0.0193 - val_RZSM_output_2_mae: 0.0179 - val_RZSM_output_3_mae: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 124s 884ms/step - loss: 0.0513 - RZSM_output_1_loss: 0.0175 - RZSM_output_2_loss: 0.0170 - RZSM_output_3_loss: 0.0168 - RZSM_output_1_mae: 0.0183 - RZSM_output_2_mae: 0.0176 - RZSM_output_3_mae: 0.0174 - val_loss: 0.0504 - val_RZSM_output_1_loss: 0.0174 - val_RZSM_output_2_loss: 0.0166 - val_RZSM_output_3_loss: 0.0164 - val_RZSM_output_1_mae: 0.0182 - val_RZSM_output_2_mae: 0.0173 - val_RZSM_output_3_mae: 0.0170 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 125s 890ms/step - loss: 0.0504 - RZSM_output_1_loss: 0.0172 - RZSM_output_2_loss: 0.0166 - RZSM_output_3_loss: 0.0165 - RZSM_output_1_mae: 0.0179 - RZSM_output_2_mae: 0.0172 - RZSM_output_3_mae: 0.0171 - val_loss: 0.0490 - val_RZSM_output_1_loss: 0.0171 - val_RZSM_output_2_loss: 0.0160 - val_RZSM_output_3_loss: 0.0159 - val_RZSM_output_1_mae: 0.0178 - val_RZSM_output_2_mae: 0.0167 - val_RZSM_output_3_mae: 0.0166 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 123s 881ms/step - loss: 0.0491 - RZSM_output_1_loss: 0.0168 - RZSM_output_2_loss: 0.0162 - RZSM_output_3_loss: 0.0161 - RZSM_output_1_mae: 0.0174 - RZSM_output_2_mae: 0.0168 - RZSM_output_3_mae: 0.0166 - val_loss: 0.0513 - val_RZSM_output_1_loss: 0.0177 - val_RZSM_output_2_loss: 0.0169 - val_RZSM_output_3_loss: 0.0167 - val_RZSM_output_1_mae: 0.0185 - val_RZSM_output_2_mae: 0.0176 - val_RZSM_output_3_mae: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 124s 885ms/step - loss: 0.0493 - RZSM_output_1_loss: 0.0167 - RZSM_output_2_loss: 0.0163 - RZSM_output_3_loss: 0.0163 - RZSM_output_1_mae: 0.0174 - RZSM_output_2_mae: 0.0169 - RZSM_output_3_mae: 0.0168 - val_loss: 0.0492 - val_RZSM_output_1_loss: 0.0171 - val_RZSM_output_2_loss: 0.0161 - val_RZSM_output_3_loss: 0.0160 - val_RZSM_output_1_mae: 0.0178 - val_RZSM_output_2_mae: 0.0168 - val_RZSM_output_3_mae: 0.0167 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 125s 892ms/step - loss: 0.0482 - RZSM_output_1_loss: 0.0163 - RZSM_output_2_loss: 0.0160 - RZSM_output_3_loss: 0.0159 - RZSM_output_1_mae: 0.0169 - RZSM_output_2_mae: 0.0166 - RZSM_output_3_mae: 0.0164 - val_loss: 0.0471 - val_RZSM_output_1_loss: 0.0163 - val_RZSM_output_2_loss: 0.0155 - val_RZSM_output_3_loss: 0.0154 - val_RZSM_output_1_mae: 0.0170 - val_RZSM_output_2_mae: 0.0160 - val_RZSM_output_3_mae: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 124s 885ms/step - loss: 0.0481 - RZSM_output_1_loss: 0.0163 - RZSM_output_2_loss: 0.0160 - RZSM_output_3_loss: 0.0158 - RZSM_output_1_mae: 0.0169 - RZSM_output_2_mae: 0.0165 - RZSM_output_3_mae: 0.0163 - val_loss: 0.0477 - val_RZSM_output_1_loss: 0.0165 - val_RZSM_output_2_loss: 0.0155 - val_RZSM_output_3_loss: 0.0157 - val_RZSM_output_1_mae: 0.0172 - val_RZSM_output_2_mae: 0.0161 - val_RZSM_output_3_mae: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 124s 883ms/step - loss: 0.0479 - RZSM_output_1_loss: 0.0161 - RZSM_output_2_loss: 0.0160 - RZSM_output_3_loss: 0.0158 - RZSM_output_1_mae: 0.0167 - RZSM_output_2_mae: 0.0165 - RZSM_output_3_mae: 0.0163 - val_loss: 0.0472 - val_RZSM_output_1_loss: 0.0164 - val_RZSM_output_2_loss: 0.0154 - val_RZSM_output_3_loss: 0.0154 - val_RZSM_output_1_mae: 0.0170 - val_RZSM_output_2_mae: 0.0160 - val_RZSM_output_3_mae: 0.0160 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 125s 894ms/step - loss: 0.0482 - RZSM_output_1_loss: 0.0162 - RZSM_output_2_loss: 0.0161 - RZSM_output_3_loss: 0.0159 - RZSM_output_1_mae: 0.0168 - RZSM_output_2_mae: 0.0166 - RZSM_output_3_mae: 0.0164 - val_loss: 0.0463 - val_RZSM_output_1_loss: 0.0161 - val_RZSM_output_2_loss: 0.0151 - val_RZSM_output_3_loss: 0.0150 - val_RZSM_output_1_mae: 0.0168 - val_RZSM_output_2_mae: 0.0157 - val_RZSM_output_3_mae: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 124s 883ms/step - loss: 0.0480 - RZSM_output_1_loss: 0.0161 - RZSM_output_2_loss: 0.0161 - RZSM_output_3_loss: 0.0158 - RZSM_output_1_mae: 0.0166 - RZSM_output_2_mae: 0.0166 - RZSM_output_3_mae: 0.0163 - val_loss: 0.0471 - val_RZSM_output_1_loss: 0.0163 - val_RZSM_output_2_loss: 0.0154 - val_RZSM_output_3_loss: 0.0154 - val_RZSM_output_1_mae: 0.0170 - val_RZSM_output_2_mae: 0.0160 - val_RZSM_output_3_mae: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 125s 894ms/step - loss: 0.0484 - RZSM_output_1_loss: 0.0162 - RZSM_output_2_loss: 0.0162 - RZSM_output_3_loss: 0.0160 - RZSM_output_1_mae: 0.0167 - RZSM_output_2_mae: 0.0167 - RZSM_output_3_mae: 0.0164 - val_loss: 0.0452 - val_RZSM_output_1_loss: 0.0157 - val_RZSM_output_2_loss: 0.0149 - val_RZSM_output_3_loss: 0.0147 - val_RZSM_output_1_mae: 0.0163 - val_RZSM_output_2_mae: 0.0154 - val_RZSM_output_3_mae: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 124s 884ms/step - loss: 0.0490 - RZSM_output_1_loss: 0.0163 - RZSM_output_2_loss: 0.0165 - RZSM_output_3_loss: 0.0162 - RZSM_output_1_mae: 0.0168 - RZSM_output_2_mae: 0.0170 - RZSM_output_3_mae: 0.0167 - val_loss: 0.0551 - val_RZSM_output_1_loss: 0.0166 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0172 - val_RZSM_output_2_mae: 0.0202 - val_RZSM_output_3_mae: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 123s 882ms/step - loss: 0.0499 - RZSM_output_1_loss: 0.0165 - RZSM_output_2_loss: 0.0169 - RZSM_output_3_loss: 0.0165 - RZSM_output_1_mae: 0.0171 - RZSM_output_2_mae: 0.0174 - RZSM_output_3_mae: 0.0169 - val_loss: 0.0471 - val_RZSM_output_1_loss: 0.0166 - val_RZSM_output_2_loss: 0.0155 - val_RZSM_output_3_loss: 0.0150 - val_RZSM_output_1_mae: 0.0173 - val_RZSM_output_2_mae: 0.0160 - val_RZSM_output_3_mae: 0.0155 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 123s 879ms/step - loss: 0.0482 - RZSM_output_1_loss: 0.0161 - RZSM_output_2_loss: 0.0162 - RZSM_output_3_loss: 0.0159 - RZSM_output_1_mae: 0.0166 - RZSM_output_2_mae: 0.0167 - RZSM_output_3_mae: 0.0163 - val_loss: 0.0480 - val_RZSM_output_1_loss: 0.0169 - val_RZSM_output_2_loss: 0.0157 - val_RZSM_output_3_loss: 0.0154 - val_RZSM_output_1_mae: 0.0175 - val_RZSM_output_2_mae: 0.0163 - val_RZSM_output_3_mae: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 123s 881ms/step - loss: 0.0480 - RZSM_output_1_loss: 0.0161 - RZSM_output_2_loss: 0.0161 - RZSM_output_3_loss: 0.0158 - RZSM_output_1_mae: 0.0166 - RZSM_output_2_mae: 0.0166 - RZSM_output_3_mae: 0.0162 - val_loss: 0.0454 - val_RZSM_output_1_loss: 0.0160 - val_RZSM_output_2_loss: 0.0148 - val_RZSM_output_3_loss: 0.0146 - val_RZSM_output_1_mae: 0.0166 - val_RZSM_output_2_mae: 0.0154 - val_RZSM_output_3_mae: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 123s 880ms/step - loss: 0.0470 - RZSM_output_1_loss: 0.0158 - RZSM_output_2_loss: 0.0158 - RZSM_output_3_loss: 0.0154 - RZSM_output_1_mae: 0.0163 - RZSM_output_2_mae: 0.0162 - RZSM_output_3_mae: 0.0158 - val_loss: 0.0464 - val_RZSM_output_1_loss: 0.0164 - val_RZSM_output_2_loss: 0.0151 - val_RZSM_output_3_loss: 0.0149 - val_RZSM_output_1_mae: 0.0170 - val_RZSM_output_2_mae: 0.0156 - val_RZSM_output_3_mae: 0.0154 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 125s 890ms/step - loss: 0.0452 - RZSM_output_1_loss: 0.0154 - RZSM_output_2_loss: 0.0149 - RZSM_output_3_loss: 0.0149 - RZSM_output_1_mae: 0.0159 - RZSM_output_2_mae: 0.0153 - RZSM_output_3_mae: 0.0153 - val_loss: 0.0424 - val_RZSM_output_1_loss: 0.0146 - val_RZSM_output_2_loss: 0.0140 - val_RZSM_output_3_loss: 0.0138 - val_RZSM_output_1_mae: 0.0151 - val_RZSM_output_2_mae: 0.0144 - val_RZSM_output_3_mae: 0.0143 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 125s 890ms/step - loss: 0.0449 - RZSM_output_1_loss: 0.0153 - RZSM_output_2_loss: 0.0148 - RZSM_output_3_loss: 0.0148 - RZSM_output_1_mae: 0.0158 - RZSM_output_2_mae: 0.0153 - RZSM_output_3_mae: 0.0152 - val_loss: 0.0421 - val_RZSM_output_1_loss: 0.0145 - val_RZSM_output_2_loss: 0.0139 - val_RZSM_output_3_loss: 0.0138 - val_RZSM_output_1_mae: 0.0150 - val_RZSM_output_2_mae: 0.0144 - val_RZSM_output_3_mae: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 125s 895ms/step - loss: 0.0447 - RZSM_output_1_loss: 0.0152 - RZSM_output_2_loss: 0.0148 - RZSM_output_3_loss: 0.0147 - RZSM_output_1_mae: 0.0157 - RZSM_output_2_mae: 0.0152 - RZSM_output_3_mae: 0.0151 - val_loss: 0.0420 - val_RZSM_output_1_loss: 0.0144 - val_RZSM_output_2_loss: 0.0139 - val_RZSM_output_3_loss: 0.0138 - val_RZSM_output_1_mae: 0.0149 - val_RZSM_output_2_mae: 0.0144 - val_RZSM_output_3_mae: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 125s 895ms/step - loss: 0.0446 - RZSM_output_1_loss: 0.0152 - RZSM_output_2_loss: 0.0148 - RZSM_output_3_loss: 0.0147 - RZSM_output_1_mae: 0.0157 - RZSM_output_2_mae: 0.0152 - RZSM_output_3_mae: 0.0151 - val_loss: 0.0419 - val_RZSM_output_1_loss: 0.0144 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0137 - val_RZSM_output_1_mae: 0.0149 - val_RZSM_output_2_mae: 0.0143 - val_RZSM_output_3_mae: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 124s 885ms/step - loss: 0.0445 - RZSM_output_1_loss: 0.0151 - RZSM_output_2_loss: 0.0148 - RZSM_output_3_loss: 0.0146 - RZSM_output_1_mae: 0.0156 - RZSM_output_2_mae: 0.0152 - RZSM_output_3_mae: 0.0150 - val_loss: 0.0419 - val_RZSM_output_1_loss: 0.0144 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0137 - val_RZSM_output_1_mae: 0.0149 - val_RZSM_output_2_mae: 0.0143 - val_RZSM_output_3_mae: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 124s 885ms/step - loss: 0.0446 - RZSM_output_1_loss: 0.0152 - RZSM_output_2_loss: 0.0148 - RZSM_output_3_loss: 0.0147 - RZSM_output_1_mae: 0.0157 - RZSM_output_2_mae: 0.0152 - RZSM_output_3_mae: 0.0151 - val_loss: 0.0419 - val_RZSM_output_1_loss: 0.0144 - val_RZSM_output_2_loss: 0.0139 - val_RZSM_output_3_loss: 0.0137 - val_RZSM_output_1_mae: 0.0149 - val_RZSM_output_2_mae: 0.0143 - val_RZSM_output_3_mae: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 125s 893ms/step - loss: 0.0444 - RZSM_output_1_loss: 0.0151 - RZSM_output_2_loss: 0.0147 - RZSM_output_3_loss: 0.0146 - RZSM_output_1_mae: 0.0156 - RZSM_output_2_mae: 0.0151 - RZSM_output_3_mae: 0.0150 - val_loss: 0.0419 - val_RZSM_output_1_loss: 0.0143 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0137 - val_RZSM_output_1_mae: 0.0149 - val_RZSM_output_2_mae: 0.0143 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 125s 893ms/step - loss: 0.0441 - RZSM_output_1_loss: 0.0150 - RZSM_output_2_loss: 0.0146 - RZSM_output_3_loss: 0.0145 - RZSM_output_1_mae: 0.0155 - RZSM_output_2_mae: 0.0150 - RZSM_output_3_mae: 0.0149 - val_loss: 0.0418 - val_RZSM_output_1_loss: 0.0143 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0137 - val_RZSM_output_1_mae: 0.0148 - val_RZSM_output_2_mae: 0.0143 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 125s 893ms/step - loss: 0.0443 - RZSM_output_1_loss: 0.0151 - RZSM_output_2_loss: 0.0146 - RZSM_output_3_loss: 0.0145 - RZSM_output_1_mae: 0.0156 - RZSM_output_2_mae: 0.0151 - RZSM_output_3_mae: 0.0149 - val_loss: 0.0417 - val_RZSM_output_1_loss: 0.0143 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0148 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 125s 890ms/step - loss: 0.0441 - RZSM_output_1_loss: 0.0150 - RZSM_output_2_loss: 0.0146 - RZSM_output_3_loss: 0.0145 - RZSM_output_1_mae: 0.0155 - RZSM_output_2_mae: 0.0150 - RZSM_output_3_mae: 0.0149 - val_loss: 0.0416 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 124s 883ms/step - loss: 0.0439 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0146 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0150 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0417 - val_RZSM_output_1_loss: 0.0143 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0148 - val_RZSM_output_2_mae: 0.0143 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 125s 891ms/step - loss: 0.0439 - RZSM_output_1_loss: 0.0150 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0416 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 124s 883ms/step - loss: 0.0439 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0146 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0150 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0417 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 125s 890ms/step - loss: 0.0438 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0415 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 125s 894ms/step - loss: 0.0438 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0415 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 123s 878ms/step - loss: 0.0438 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0415 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 123s 880ms/step - loss: 0.0435 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0417 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0138 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0143 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 124s 880ms/step - loss: 0.0438 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0415 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0141 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 125s 895ms/step - loss: 0.0439 - RZSM_output_1_loss: 0.0150 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 125s 891ms/step - loss: 0.0438 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 124s 887ms/step - loss: 0.0439 - RZSM_output_1_loss: 0.0150 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0150 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0413 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0136 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 121s 868ms/step - loss: 0.0438 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0144 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0148 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 122s 869ms/step - loss: 0.0437 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 121s 867ms/step - loss: 0.0436 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 123s 877ms/step - loss: 0.0436 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0413 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0136 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 121s 867ms/step - loss: 0.0437 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0154 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 122s 871ms/step - loss: 0.0436 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0413 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-07\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 123s 878ms/step - loss: 0.0436 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0145 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0149 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0412 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0136 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-07\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 121s 867ms/step - loss: 0.0434 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0142 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0146 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-07\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 121s 868ms/step - loss: 0.0435 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-07\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 122s 869ms/step - loss: 0.0434 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0142 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0146 - val_loss: 0.0413 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-07\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 122s 869ms/step - loss: 0.0435 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-08\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 122s 871ms/step - loss: 0.0434 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0142 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0146 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-08\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 124s 889ms/step - loss: 0.0436 - RZSM_output_1_loss: 0.0149 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0413 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-08\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 123s 882ms/step - loss: 0.0435 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0143 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0147 - val_loss: 0.0414 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-08\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 124s 883ms/step - loss: 0.0434 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0142 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0146 - val_loss: 0.0415 - val_RZSM_output_1_loss: 0.0142 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0136 - val_RZSM_output_1_mae: 0.0147 - val_RZSM_output_2_mae: 0.0142 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-08\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 123s 881ms/step - loss: 0.0435 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0142 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0146 - val_loss: 0.0413 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-09\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 124s 883ms/step - loss: 0.0435 - RZSM_output_1_loss: 0.0148 - RZSM_output_2_loss: 0.0144 - RZSM_output_3_loss: 0.0142 - RZSM_output_1_mae: 0.0153 - RZSM_output_2_mae: 0.0148 - RZSM_output_3_mae: 0.0146 - val_loss: 0.0413 - val_RZSM_output_1_loss: 0.0141 - val_RZSM_output_2_loss: 0.0137 - val_RZSM_output_3_loss: 0.0135 - val_RZSM_output_1_mae: 0.0146 - val_RZSM_output_2_mae: 0.0141 - val_RZSM_output_3_mae: 0.0140 - lr: 1.0000e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:31:46.629903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:46.651387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:46.672792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:46.694380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:46.859773: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.064184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.085801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.107337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.128453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.292859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.410350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.524109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.569209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.595626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.883207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.904729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.925757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.946676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.968858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:47.990294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:48.011644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:48.032486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:48.697719: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:48.816440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:48.838386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:48.860996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.114642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.144912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.383652: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.404936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.426486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.447677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.486262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.507330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.528380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.549866: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.905526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:49.948514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:50.243664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:50.507907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:50.546996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:50.591716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:50.634662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:50.943018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.069901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.186197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,24,48,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.235782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,12,24,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.336473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,6,12,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.530602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,12,24,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.556635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,24,48,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.586922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.808119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,24,48,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.827899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:31:56.958029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.114168: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.135465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.156136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.177040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.442953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.562964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.832400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.853661: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.874771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:03.896081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:04.163157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:04.265656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,24,48,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:04.376510: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:04.497573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,12,24,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:04.576741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:04.623060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:04.669000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.102231: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.123433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.144088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.164856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.191890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,6,12,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.207985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.228781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.249449: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.270015: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.641576: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.889045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.916860: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:05.947941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.160467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,12,24,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.212736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,24,48,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.241403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.352081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.413181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.758958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.780066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.801064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.821732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.843061: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.863803: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.884517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:06.905859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.415480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.436631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.633002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,24,48,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.655119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.765966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.940854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.961919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:07.982568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:08.003638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:08.272121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-17 21:32:08.373633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype half and shape [?,48,96,64]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 202). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/derecho/scratch/klesinger/FD_RZSM_deep_learning/checkpoints/china/Wk1/Wk1_EX29_ECMWF_regular_RZSM/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/derecho/scratch/klesinger/FD_RZSM_deep_learning/checkpoints/china/Wk1/Wk1_EX29_ECMWF_regular_RZSM/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting single prediction for Experiment EX29_ECMWF_regular_RZSM\n",
      "\n",
      "Currently only predicting the test dataset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:32:46.177896: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1780] (One-time warning): Not using XLA:CPU for cluster.\n",
      "\n",
      "If you want XLA:CPU, do one of the following:\n",
      "\n",
      " - set the TF_XLA_FLAGS to include \"--tf_xla_cpu_global_jit\", or\n",
      " - set cpu_global_jit to true on this session's OptimizerOptions, or\n",
      " - use experimental_jit_scope, or\n",
      " - use tf.function(jit_compile=True).\n",
      "\n",
      "To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a\n",
      "proper command-line flag, not via TF_XLA_FLAGS).\n",
      "2025-03-17 21:32:49.303606: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x55ebedd48930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-17 21:32:49.303649: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2025-03-17 21:32:50.019000: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-03-17 21:32:50.030150: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-03-17 21:32:56.312751: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'fusion_6', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-03-17 21:32:58.446897: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'fusion_6', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2025-03-17 21:33:05.904665: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'fusion_6', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 32s 154ms/step\n",
      "\n",
      "Predicting training and validation input\n",
      "288/288 [==============================] - 14s 50ms/step\n",
      "34/36 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:34:00.948433: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'fusion_6', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-03-17 21:34:02.941181: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'fusion_6', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2025-03-17 21:34:09.387807: I tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:328] ptxas warning : Registers are spilled to local memory in function 'fusion_6', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 22s 637ms/step\n",
      "\n",
      "Working on setting up data for Experiment EX29 for lead 2\n",
      "\n",
      "Training input shape = (9185, 48, 96, 12)\n",
      "Index idx value is 2. Done adding RZSM obs.\n",
      "Loading observations for pwat_eatm and lag -1\n",
      "Index idx value is 3. Done adding pwat_eatm obs.\n",
      "Loading observations for spfh_2m and lag -1\n",
      "Index idx value is 4. Done adding spfh_2m obs.\n",
      "Loading observations for tmax_2m and lag -1\n",
      "Index idx value is 5. Done adding tmax_2m obs.\n",
      "Loading observations for diff_temp_2m and lag -1\n",
      "Index idx value is 6. Done adding diff_temp_2m obs.\n",
      "Loading observations for hgt_pres and lag -1\n",
      "Index idx value is 7. Done adding hgt_pres obs.\n",
      "Adding previous RZSM prediction from week 1 as an input channel\n",
      "Loading data from previous week lead 1\n",
      "Adding RZSM training, validation, testing into index 8\n",
      "Adding current reforecast data from week 2 for vars ['t2m', 'd2m', 'tcw']\n",
      "Index idx value is 9. Done adding t2m reforecast.\n",
      "Index idx value is 10. Done adding d2m reforecast.\n",
      "Index idx value is 11. Done adding tcw reforecast.\n",
      "[[0.47826985 0.47954738 0.4794111  ... 0.50477463 0.50606394 0.50719893]\n",
      " [0.4836843  0.48559642 0.48499024 ... 0.50484169 0.50640476 0.50765306]\n",
      " [0.48649681 0.48803273 0.48770496 ... 0.50476956 0.5062387  0.50720859]\n",
      " ...\n",
      " [0.50864941 0.50711179 0.50617301 ... 0.58288014 0.58633947 0.58856052]\n",
      " [0.50635123 0.50420785 0.50312579 ... 0.59408772 0.59688407 0.59946209]\n",
      " [0.50224751 0.49851957 0.49577007 ... 0.59556144 0.59713072 0.59969956]]\n",
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Loading obs_soilw_bgrnd_GLEAM_lead_2_train_masked.npy\n",
      "\n",
      "Experiment name out is EX29_ECMWF_regular_RZSM\n",
      "\n",
      "Loading previously created data\n",
      "Actual channel order list\n",
      "['Channel_0 is from OBSERVATIONS with lead or lag RZSM_obs_lag-1\\n', 'Channel_1 is from OBSERVATIONS with lead or lag RZSM_obs_lag-7\\n', 'Channel_2 is from OBSERVATIONS with lead or lag RZSM_obs_lag-14\\n', 'Channel_3 is from OBSERVATIONS with lead or lag pwat_obs_lag-1\\n', 'Channel_4 is from OBSERVATIONS with lead or lag spfh_obs_lag-1\\n', 'Channel_5 is from OBSERVATIONS with lead or lag tmax_obs_lag-1\\n', 'Channel_6 is from OBSERVATIONS with lead or lag diff_temp_obs_lag-1\\n', 'Channel_7 is from OBSERVATIONS with lead or lag z200_obs_lag-1\\n', 'Channel_8 is from REFORECAST with lead or lag RZSM_prediction_lead1\\n', 'Channel_9 is from REFORECAST with lead or lag 2m_temp_ref_lead2\\n', 'Channel_10 is from REFORECAST with lead or lag 2m_dewpoint_ref_lead2\\n', 'Channel_11 is from REFORECAST with lead or lag pwat_eatm_ref_lead2\\n']\n",
      "\n",
      "Compiling model\n",
      "\n",
      "\n",
      "Checkpoint is being saved into /glade/derecho/scratch/klesinger/FD_RZSM_deep_learning/checkpoints/china/Wk2/Wk2_EX29_ECMWF_regular_RZSM\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:35:43.770927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype float and shape [9185,48,96,1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - ETA: 0s - loss: 0.2711 - RZSM_output_1_loss: 0.1000 - RZSM_output_2_loss: 0.0833 - RZSM_output_3_loss: 0.0878 - RZSM_output_1_mae: 0.1075 - RZSM_output_2_mae: 0.0894 - RZSM_output_3_mae: 0.0935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:37:38.907887: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype float and shape [1144,48,96,1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 129s 909ms/step - loss: 0.2711 - RZSM_output_1_loss: 0.1000 - RZSM_output_2_loss: 0.0833 - RZSM_output_3_loss: 0.0878 - RZSM_output_1_mae: 0.1075 - RZSM_output_2_mae: 0.0894 - RZSM_output_3_mae: 0.0935 - val_loss: 0.4346 - val_RZSM_output_1_loss: 0.1420 - val_RZSM_output_2_loss: 0.1439 - val_RZSM_output_3_loss: 0.1487 - val_RZSM_output_1_mae: 0.1448 - val_RZSM_output_2_mae: 0.1462 - val_RZSM_output_3_mae: 0.1511 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 127s 907ms/step - loss: 0.1103 - RZSM_output_1_loss: 0.0410 - RZSM_output_2_loss: 0.0351 - RZSM_output_3_loss: 0.0343 - RZSM_output_1_mae: 0.0438 - RZSM_output_2_mae: 0.0372 - RZSM_output_3_mae: 0.0363 - val_loss: 0.1976 - val_RZSM_output_1_loss: 0.0643 - val_RZSM_output_2_loss: 0.0636 - val_RZSM_output_3_loss: 0.0696 - val_RZSM_output_1_mae: 0.0667 - val_RZSM_output_2_mae: 0.0657 - val_RZSM_output_3_mae: 0.0716 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 128s 911ms/step - loss: 0.0898 - RZSM_output_1_loss: 0.0324 - RZSM_output_2_loss: 0.0291 - RZSM_output_3_loss: 0.0283 - RZSM_output_1_mae: 0.0344 - RZSM_output_2_mae: 0.0307 - RZSM_output_3_mae: 0.0297 - val_loss: 0.1108 - val_RZSM_output_1_loss: 0.0380 - val_RZSM_output_2_loss: 0.0353 - val_RZSM_output_3_loss: 0.0376 - val_RZSM_output_1_mae: 0.0398 - val_RZSM_output_2_mae: 0.0368 - val_RZSM_output_3_mae: 0.0390 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 128s 912ms/step - loss: 0.0799 - RZSM_output_1_loss: 0.0283 - RZSM_output_2_loss: 0.0261 - RZSM_output_3_loss: 0.0254 - RZSM_output_1_mae: 0.0299 - RZSM_output_2_mae: 0.0274 - RZSM_output_3_mae: 0.0265 - val_loss: 0.0874 - val_RZSM_output_1_loss: 0.0292 - val_RZSM_output_2_loss: 0.0282 - val_RZSM_output_3_loss: 0.0301 - val_RZSM_output_1_mae: 0.0307 - val_RZSM_output_2_mae: 0.0294 - val_RZSM_output_3_mae: 0.0312 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 127s 910ms/step - loss: 0.0754 - RZSM_output_1_loss: 0.0266 - RZSM_output_2_loss: 0.0247 - RZSM_output_3_loss: 0.0242 - RZSM_output_1_mae: 0.0279 - RZSM_output_2_mae: 0.0258 - RZSM_output_3_mae: 0.0251 - val_loss: 0.0775 - val_RZSM_output_1_loss: 0.0262 - val_RZSM_output_2_loss: 0.0250 - val_RZSM_output_3_loss: 0.0263 - val_RZSM_output_1_mae: 0.0276 - val_RZSM_output_2_mae: 0.0261 - val_RZSM_output_3_mae: 0.0272 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 127s 907ms/step - loss: 0.0714 - RZSM_output_1_loss: 0.0249 - RZSM_output_2_loss: 0.0234 - RZSM_output_3_loss: 0.0231 - RZSM_output_1_mae: 0.0260 - RZSM_output_2_mae: 0.0243 - RZSM_output_3_mae: 0.0240 - val_loss: 0.0715 - val_RZSM_output_1_loss: 0.0244 - val_RZSM_output_2_loss: 0.0232 - val_RZSM_output_3_loss: 0.0239 - val_RZSM_output_1_mae: 0.0256 - val_RZSM_output_2_mae: 0.0242 - val_RZSM_output_3_mae: 0.0248 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 128s 911ms/step - loss: 0.0689 - RZSM_output_1_loss: 0.0237 - RZSM_output_2_loss: 0.0228 - RZSM_output_3_loss: 0.0224 - RZSM_output_1_mae: 0.0247 - RZSM_output_2_mae: 0.0236 - RZSM_output_3_mae: 0.0232 - val_loss: 0.0666 - val_RZSM_output_1_loss: 0.0229 - val_RZSM_output_2_loss: 0.0218 - val_RZSM_output_3_loss: 0.0218 - val_RZSM_output_1_mae: 0.0240 - val_RZSM_output_2_mae: 0.0227 - val_RZSM_output_3_mae: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 128s 911ms/step - loss: 0.0670 - RZSM_output_1_loss: 0.0229 - RZSM_output_2_loss: 0.0221 - RZSM_output_3_loss: 0.0219 - RZSM_output_1_mae: 0.0238 - RZSM_output_2_mae: 0.0229 - RZSM_output_3_mae: 0.0226 - val_loss: 0.0650 - val_RZSM_output_1_loss: 0.0223 - val_RZSM_output_2_loss: 0.0214 - val_RZSM_output_3_loss: 0.0212 - val_RZSM_output_1_mae: 0.0233 - val_RZSM_output_2_mae: 0.0222 - val_RZSM_output_3_mae: 0.0220 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 128s 912ms/step - loss: 0.0656 - RZSM_output_1_loss: 0.0223 - RZSM_output_2_loss: 0.0217 - RZSM_output_3_loss: 0.0215 - RZSM_output_1_mae: 0.0232 - RZSM_output_2_mae: 0.0225 - RZSM_output_3_mae: 0.0222 - val_loss: 0.0643 - val_RZSM_output_1_loss: 0.0217 - val_RZSM_output_2_loss: 0.0212 - val_RZSM_output_3_loss: 0.0213 - val_RZSM_output_1_mae: 0.0226 - val_RZSM_output_2_mae: 0.0220 - val_RZSM_output_3_mae: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 128s 912ms/step - loss: 0.0646 - RZSM_output_1_loss: 0.0219 - RZSM_output_2_loss: 0.0215 - RZSM_output_3_loss: 0.0213 - RZSM_output_1_mae: 0.0227 - RZSM_output_2_mae: 0.0222 - RZSM_output_3_mae: 0.0219 - val_loss: 0.0638 - val_RZSM_output_1_loss: 0.0213 - val_RZSM_output_2_loss: 0.0211 - val_RZSM_output_3_loss: 0.0213 - val_RZSM_output_1_mae: 0.0222 - val_RZSM_output_2_mae: 0.0219 - val_RZSM_output_3_mae: 0.0220 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 128s 913ms/step - loss: 0.0637 - RZSM_output_1_loss: 0.0215 - RZSM_output_2_loss: 0.0212 - RZSM_output_3_loss: 0.0210 - RZSM_output_1_mae: 0.0223 - RZSM_output_2_mae: 0.0219 - RZSM_output_3_mae: 0.0216 - val_loss: 0.0620 - val_RZSM_output_1_loss: 0.0209 - val_RZSM_output_2_loss: 0.0205 - val_RZSM_output_3_loss: 0.0206 - val_RZSM_output_1_mae: 0.0217 - val_RZSM_output_2_mae: 0.0212 - val_RZSM_output_3_mae: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 126s 901ms/step - loss: 0.0634 - RZSM_output_1_loss: 0.0213 - RZSM_output_2_loss: 0.0212 - RZSM_output_3_loss: 0.0210 - RZSM_output_1_mae: 0.0220 - RZSM_output_2_mae: 0.0218 - RZSM_output_3_mae: 0.0216 - val_loss: 0.0633 - val_RZSM_output_1_loss: 0.0212 - val_RZSM_output_2_loss: 0.0210 - val_RZSM_output_3_loss: 0.0211 - val_RZSM_output_1_mae: 0.0220 - val_RZSM_output_2_mae: 0.0216 - val_RZSM_output_3_mae: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 126s 899ms/step - loss: 0.0627 - RZSM_output_1_loss: 0.0210 - RZSM_output_2_loss: 0.0209 - RZSM_output_3_loss: 0.0208 - RZSM_output_1_mae: 0.0217 - RZSM_output_2_mae: 0.0215 - RZSM_output_3_mae: 0.0214 - val_loss: 0.0662 - val_RZSM_output_1_loss: 0.0220 - val_RZSM_output_2_loss: 0.0220 - val_RZSM_output_3_loss: 0.0223 - val_RZSM_output_1_mae: 0.0227 - val_RZSM_output_2_mae: 0.0226 - val_RZSM_output_3_mae: 0.0229 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 126s 903ms/step - loss: 0.0630 - RZSM_output_1_loss: 0.0211 - RZSM_output_2_loss: 0.0211 - RZSM_output_3_loss: 0.0208 - RZSM_output_1_mae: 0.0218 - RZSM_output_2_mae: 0.0217 - RZSM_output_3_mae: 0.0214 - val_loss: 0.0659 - val_RZSM_output_1_loss: 0.0216 - val_RZSM_output_2_loss: 0.0219 - val_RZSM_output_3_loss: 0.0224 - val_RZSM_output_1_mae: 0.0223 - val_RZSM_output_2_mae: 0.0225 - val_RZSM_output_3_mae: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 126s 902ms/step - loss: 0.0628 - RZSM_output_1_loss: 0.0209 - RZSM_output_2_loss: 0.0210 - RZSM_output_3_loss: 0.0209 - RZSM_output_1_mae: 0.0216 - RZSM_output_2_mae: 0.0216 - RZSM_output_3_mae: 0.0214 - val_loss: 0.0630 - val_RZSM_output_1_loss: 0.0207 - val_RZSM_output_2_loss: 0.0208 - val_RZSM_output_3_loss: 0.0215 - val_RZSM_output_1_mae: 0.0214 - val_RZSM_output_2_mae: 0.0214 - val_RZSM_output_3_mae: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 127s 906ms/step - loss: 0.0633 - RZSM_output_1_loss: 0.0211 - RZSM_output_2_loss: 0.0212 - RZSM_output_3_loss: 0.0210 - RZSM_output_1_mae: 0.0217 - RZSM_output_2_mae: 0.0217 - RZSM_output_3_mae: 0.0216 - val_loss: 0.0671 - val_RZSM_output_1_loss: 0.0216 - val_RZSM_output_2_loss: 0.0220 - val_RZSM_output_3_loss: 0.0235 - val_RZSM_output_1_mae: 0.0223 - val_RZSM_output_2_mae: 0.0228 - val_RZSM_output_3_mae: 0.0242 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 128s 915ms/step - loss: 0.0617 - RZSM_output_1_loss: 0.0208 - RZSM_output_2_loss: 0.0205 - RZSM_output_3_loss: 0.0204 - RZSM_output_1_mae: 0.0214 - RZSM_output_2_mae: 0.0211 - RZSM_output_3_mae: 0.0210 - val_loss: 0.0590 - val_RZSM_output_1_loss: 0.0200 - val_RZSM_output_2_loss: 0.0195 - val_RZSM_output_3_loss: 0.0194 - val_RZSM_output_1_mae: 0.0207 - val_RZSM_output_2_mae: 0.0201 - val_RZSM_output_3_mae: 0.0200 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 127s 908ms/step - loss: 0.0611 - RZSM_output_1_loss: 0.0206 - RZSM_output_2_loss: 0.0203 - RZSM_output_3_loss: 0.0202 - RZSM_output_1_mae: 0.0212 - RZSM_output_2_mae: 0.0208 - RZSM_output_3_mae: 0.0208 - val_loss: 0.0590 - val_RZSM_output_1_loss: 0.0200 - val_RZSM_output_2_loss: 0.0196 - val_RZSM_output_3_loss: 0.0194 - val_RZSM_output_1_mae: 0.0207 - val_RZSM_output_2_mae: 0.0202 - val_RZSM_output_3_mae: 0.0200 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 127s 911ms/step - loss: 0.0610 - RZSM_output_1_loss: 0.0206 - RZSM_output_2_loss: 0.0202 - RZSM_output_3_loss: 0.0202 - RZSM_output_1_mae: 0.0212 - RZSM_output_2_mae: 0.0208 - RZSM_output_3_mae: 0.0207 - val_loss: 0.0589 - val_RZSM_output_1_loss: 0.0200 - val_RZSM_output_2_loss: 0.0195 - val_RZSM_output_3_loss: 0.0194 - val_RZSM_output_1_mae: 0.0206 - val_RZSM_output_2_mae: 0.0201 - val_RZSM_output_3_mae: 0.0200 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 128s 912ms/step - loss: 0.0606 - RZSM_output_1_loss: 0.0205 - RZSM_output_2_loss: 0.0201 - RZSM_output_3_loss: 0.0201 - RZSM_output_1_mae: 0.0211 - RZSM_output_2_mae: 0.0206 - RZSM_output_3_mae: 0.0206 - val_loss: 0.0588 - val_RZSM_output_1_loss: 0.0199 - val_RZSM_output_2_loss: 0.0195 - val_RZSM_output_3_loss: 0.0194 - val_RZSM_output_1_mae: 0.0206 - val_RZSM_output_2_mae: 0.0201 - val_RZSM_output_3_mae: 0.0200 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 124s 887ms/step - loss: 0.0605 - RZSM_output_1_loss: 0.0205 - RZSM_output_2_loss: 0.0201 - RZSM_output_3_loss: 0.0200 - RZSM_output_1_mae: 0.0211 - RZSM_output_2_mae: 0.0206 - RZSM_output_3_mae: 0.0206 - val_loss: 0.0588 - val_RZSM_output_1_loss: 0.0199 - val_RZSM_output_2_loss: 0.0195 - val_RZSM_output_3_loss: 0.0194 - val_RZSM_output_1_mae: 0.0206 - val_RZSM_output_2_mae: 0.0201 - val_RZSM_output_3_mae: 0.0200 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 124s 886ms/step - loss: 0.0604 - RZSM_output_1_loss: 0.0204 - RZSM_output_2_loss: 0.0200 - RZSM_output_3_loss: 0.0200 - RZSM_output_1_mae: 0.0210 - RZSM_output_2_mae: 0.0206 - RZSM_output_3_mae: 0.0205 - val_loss: 0.0587 - val_RZSM_output_1_loss: 0.0199 - val_RZSM_output_2_loss: 0.0195 - val_RZSM_output_3_loss: 0.0194 - val_RZSM_output_1_mae: 0.0205 - val_RZSM_output_2_mae: 0.0200 - val_RZSM_output_3_mae: 0.0199 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 124s 889ms/step - loss: 0.0604 - RZSM_output_1_loss: 0.0204 - RZSM_output_2_loss: 0.0200 - RZSM_output_3_loss: 0.0200 - RZSM_output_1_mae: 0.0210 - RZSM_output_2_mae: 0.0206 - RZSM_output_3_mae: 0.0205 - val_loss: 0.0585 - val_RZSM_output_1_loss: 0.0198 - val_RZSM_output_2_loss: 0.0194 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0205 - val_RZSM_output_2_mae: 0.0200 - val_RZSM_output_3_mae: 0.0199 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 122s 875ms/step - loss: 0.0602 - RZSM_output_1_loss: 0.0204 - RZSM_output_2_loss: 0.0199 - RZSM_output_3_loss: 0.0199 - RZSM_output_1_mae: 0.0210 - RZSM_output_2_mae: 0.0205 - RZSM_output_3_mae: 0.0205 - val_loss: 0.0586 - val_RZSM_output_1_loss: 0.0198 - val_RZSM_output_2_loss: 0.0194 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0205 - val_RZSM_output_2_mae: 0.0200 - val_RZSM_output_3_mae: 0.0199 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 124s 884ms/step - loss: 0.0600 - RZSM_output_1_loss: 0.0203 - RZSM_output_2_loss: 0.0199 - RZSM_output_3_loss: 0.0199 - RZSM_output_1_mae: 0.0209 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0204 - val_loss: 0.0585 - val_RZSM_output_1_loss: 0.0198 - val_RZSM_output_2_loss: 0.0194 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0200 - val_RZSM_output_3_mae: 0.0199 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 121s 868ms/step - loss: 0.0600 - RZSM_output_1_loss: 0.0203 - RZSM_output_2_loss: 0.0199 - RZSM_output_3_loss: 0.0199 - RZSM_output_1_mae: 0.0209 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0204 - val_loss: 0.0585 - val_RZSM_output_1_loss: 0.0198 - val_RZSM_output_2_loss: 0.0194 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0200 - val_RZSM_output_3_mae: 0.0199 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 117s 832ms/step - loss: 0.0601 - RZSM_output_1_loss: 0.0203 - RZSM_output_2_loss: 0.0199 - RZSM_output_3_loss: 0.0199 - RZSM_output_1_mae: 0.0209 - RZSM_output_2_mae: 0.0205 - RZSM_output_3_mae: 0.0204 - val_loss: 0.0584 - val_RZSM_output_1_loss: 0.0198 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 114s 816ms/step - loss: 0.0600 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0199 - RZSM_output_3_loss: 0.0199 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0204 - val_loss: 0.0584 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0194 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 120s 856ms/step - loss: 0.0599 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0583 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 114s 815ms/step - loss: 0.0598 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0204 - val_loss: 0.0582 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 120s 860ms/step - loss: 0.0597 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0583 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0194 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 113s 807ms/step - loss: 0.0596 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0197 - RZSM_output_3_loss: 0.0197 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0202 - val_loss: 0.0582 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 112s 804ms/step - loss: 0.0596 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0197 - RZSM_output_3_loss: 0.0197 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0202 - val_loss: 0.0583 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 118s 841ms/step - loss: 0.0595 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0197 - RZSM_output_3_loss: 0.0197 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0202 - val_loss: 0.0583 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 117s 838ms/step - loss: 0.0599 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0199 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0584 - val_RZSM_output_1_loss: 0.0198 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0193 - val_RZSM_output_1_mae: 0.0204 - val_RZSM_output_2_mae: 0.0199 - val_RZSM_output_3_mae: 0.0198 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 119s 849ms/step - loss: 0.0599 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0199 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0582 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 119s 853ms/step - loss: 0.0597 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0192 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 118s 843ms/step - loss: 0.0599 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 114s 815ms/step - loss: 0.0599 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0580 - val_RZSM_output_1_loss: 0.0196 - val_RZSM_output_2_loss: 0.0192 - val_RZSM_output_3_loss: 0.0191 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 118s 844ms/step - loss: 0.0597 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 113s 807ms/step - loss: 0.0597 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 113s 804ms/step - loss: 0.0598 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 118s 843ms/step - loss: 0.0596 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0197 - RZSM_output_3_loss: 0.0197 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0580 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0192 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 113s 805ms/step - loss: 0.0598 - RZSM_output_1_loss: 0.0202 - RZSM_output_2_loss: 0.0198 - RZSM_output_3_loss: 0.0198 - RZSM_output_1_mae: 0.0208 - RZSM_output_2_mae: 0.0204 - RZSM_output_3_mae: 0.0203 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0192 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 113s 806ms/step - loss: 0.0595 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0197 - RZSM_output_3_loss: 0.0197 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0202 - RZSM_output_3_mae: 0.0202 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-07\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 113s 806ms/step - loss: 0.0594 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0197 - RZSM_output_3_loss: 0.0196 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0202 - RZSM_output_3_mae: 0.0202 - val_loss: 0.0580 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0192 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-07\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 113s 803ms/step - loss: 0.0596 - RZSM_output_1_loss: 0.0201 - RZSM_output_2_loss: 0.0197 - RZSM_output_3_loss: 0.0197 - RZSM_output_1_mae: 0.0207 - RZSM_output_2_mae: 0.0203 - RZSM_output_3_mae: 0.0202 - val_loss: 0.0581 - val_RZSM_output_1_loss: 0.0197 - val_RZSM_output_2_loss: 0.0193 - val_RZSM_output_3_loss: 0.0192 - val_RZSM_output_1_mae: 0.0203 - val_RZSM_output_2_mae: 0.0198 - val_RZSM_output_3_mae: 0.0197 - lr: 1.0000e-07\n",
      "Epoch 48/100\n",
      " 26/140 [====>.........................] - ETA: 1:26 - loss: 0.0568 - RZSM_output_1_loss: 0.0193 - RZSM_output_2_loss: 0.0187 - RZSM_output_3_loss: 0.0188 - RZSM_output_1_mae: 0.0199 - RZSM_output_2_mae: 0.0193 - RZSM_output_3_mae: 0.0193"
     ]
    }
   ],
   "source": [
    "run_model_and_prediction(EX29,ref_source)\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6801867-0c6f-4143-9c81-96c00f3b6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "t\n",
    "\n",
    "experiment=EX27\n",
    "#for testing\n",
    "lead,lead_week = 1,1\n",
    "\n",
    "experiment['region_name']\n",
    "lead = lead_week\n",
    "num_lags_obs_RZSM=experiment['num_lags_obs_RZSM']\n",
    "include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax']\n",
    "include_reforecast_or_not=experiment['include_reforecast_or_not']\n",
    "addtl_experiment = experiment['addtl_experiment']\n",
    "experiment_test = experiment['experiment_test']\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 66\n",
    "initial_learning_rate=0.0001\n",
    "beta_1 = 0.9\n",
    "shuffle=False\n",
    "patience=10\n",
    "kernel_norm = None\n",
    "deep_supervision = True\n",
    "number_of_UNET_backbone_max_pool=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1fd7c8-f10e-4cfb-bd3c-1e85b79a0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # #EX27\n",
    "    # generate_model_inputs(region_name=region_name,lead = lead_week,num_lags_obs_RZSM=3,include_lags_obs_pwat_spfh_tmax=True,include_reforecast_or_not=True, addtl_experiment = False, experiment_test = 1)\n",
    "    # #EX27\n",
    "    # run_EXPERIMENT(region_name=region_name,lead = lead_week,num_lags_obs_RZSM=3,include_lags_obs_pwat_spfh_tmax=True,include_reforecast_or_not=True, addtl_experiment = False, experiment_test = 1)\n",
    "    # #EX27\n",
    "    # make_single_predictions(lead = lead_week,num_lags_obs_RZSM=3,include_lags_obs_pwat_spfh_tmax=True,include_reforecast_or_not=True, addtl_experiment = False, experiment_test = 1,region_name=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cdc899-5d63-4933-8cb2-6e2a7f9a42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_fully_autoregressive_EX26(lead):\n",
    "\n",
    "    #We can manually select the best models and create a week N estimate based on them (this implies that all the information from the observations is contained in the first \n",
    "    #Set of leads\n",
    "\n",
    "    best_models = []\n",
    "    \n",
    "    if lead == 2:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM']\n",
    "    elif lead == 3:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM','EX20_RZSM']\n",
    "    elif lead == 4:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM']\n",
    "    elif lead == 5:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM']\n",
    "\n",
    "    return(previous_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841654ad-976c-41c1-95fe-5e8425812c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6f059b4-d62a-4ccf-8fb5-d2a6571d3655",
   "metadata": {},
   "source": [
    "# Permutation test only (ONLY FOR CONUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8b234-f132-49d2-b806-501aa3681406",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert region_name == 'CONUS', 'Must only use CONUS as the region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804ef1f-53e3-47a2-87ff-f275f5a52e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_plot_permutation(lead,dictionary,metric):\n",
    "    test=pd.DataFrame(dictionary,index=[metric])\n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ab024-d7a8-4fe8-a21d-d0cc94658802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/barplots/{region_name}/Wk{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "    \n",
    "    mae = setup_plot_permutation(lead,save_for_plot_mae,'MAE')\n",
    "    rmse = setup_plot_permutation(lead,save_for_plot_rmse,'RMSE')\n",
    "       \n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(2)\n",
    "    \n",
    "    # Plot for DataFrame 1\n",
    "    mae.plot(kind='bar', ax=axs[0])\n",
    "    axs[0].set_title('MAE')\n",
    "    \n",
    "    # Plot for DataFrame 2\n",
    "    rmse.plot(kind='bar', ax=axs[1])\n",
    "    axs[1].set_title('RMSE')\n",
    "    \n",
    "    # Adjust layout\n",
    "    # plt.tight_layout()\n",
    "    plt.savefig(f'{save_permutation_figures}/{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    return(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c45487-1bb2-457b-987d-f5683ca766ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_plot_permutation(lead,max_RZSM_value,region_name):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/{region_name}/plots/Wk{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "\n",
    "    # del plot_['Lead']\n",
    "    plot_ = plot_.T #Must transpose to make it plot properly\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "\n",
    "    plot_.RZSM.plot(kind='bar', color='red',width=0.3, ax=ax, position=1)\n",
    "\n",
    "    ax.set_ylabel('RZSM anomaly MAE')\n",
    "    ax.set_ylim(0, max_RZSM_value)\n",
    "\n",
    "    # plot_.plot(kind='bar')\n",
    "    # plt.ylabel(f'{error_}')\n",
    "    plt.suptitle(f'Permutation Test\\nObservation values are in legend\\nWk{lead} {experiment_name_out}',fontsize=10)\n",
    "    \n",
    "    legend1 = ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1))\n",
    "\n",
    "    ax.set_xlabel('\\nPermutated Channels',weight='bold')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{save_permutation_figures}/{experiment_name_out}.png')\n",
    "    #plt.savefig(f'{save_permutation_figures}/{experiment_name}.tiff', format='tiff', dpi=300)\n",
    "    #tiff.imsave(f'{save_permutation_figures}/{experiment_name}.tiff', data_array)\n",
    "    plt.show()\n",
    "\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03da91-3339-4f73-a399-0ef119aba4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num):\n",
    "        \n",
    "    obs_final_train,obs_final_validation,obs_final_testing = verifications.open_obs_for_verification(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end)\n",
    "\n",
    "    obs_final_testing = obs_final_testing.sel(L=day_num)\n",
    "    '''Now that we have the observations, we need to loop through each of the testing files and permutate them'''\n",
    "    \n",
    "    save_permutation_figures = f'Outputs/permutation_data/{region_name}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "\n",
    "    #Get the files from the correct location (we need to loop through each of the models.\n",
    "    # exps = sorted(glob(f'checkpoints/{region_name}/Wk{lead}/*'))\n",
    "    exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "\n",
    "    exps = [i for i in exps if 'RZSM' in i]\n",
    "    exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "\n",
    "    #Make a list of the experiment names. We only need to grab a single file since they all have the same data\n",
    "    '''We are going to seperate by hybrid and obs.driven. So remove EX0 and EX13'''\n",
    "    EX_list = [f'EX{i}' for i in range(26)]\n",
    "    EX_list = EX_list+['EX27']+['EX28']\n",
    "    EX_list = [i for i in EX_list if 'EX0' not in i ]\n",
    "    EX_list = [i for i in EX_list if 'EX13' not in i ]\n",
    "    # EX_list = [i for i in EX_list if 'EX10' not in i ]\n",
    "\n",
    "    return(obs_final_train,obs_final_validation,obs_final_testing,EX_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7f2e9-8d72-4c3e-8388-f8e5ef2a494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_the_experiment_input(exps,file,lead):\n",
    "    '''First find the experiment name within the file'''\n",
    "    ex_num = file.split(f'Wk{lead}_')[-1].split('_')[0]\n",
    "\n",
    "    '''Now loop through exps to grab the correct input'''\n",
    "    correct_file = [i for i in exps if ex_num in i]\n",
    "    correct_file = [i for i in correct_file if 'XGBOOST' not in i]\n",
    "\n",
    "    return(np.load(correct_file[0]),ex_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d3d34-cc2d-4644-9523-5d2735cd401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_by_lead_save_MAE_RMSE(lead, test_year):\n",
    "    #test \n",
    "    # lead = 1\n",
    "    # test_year=2019\n",
    "\n",
    "    day_num = (lead*7) -1\n",
    "    \n",
    "    file_path = f'Outputs/permutation_tests/mae_rmse_results'\n",
    "    file_rmse_save = f'{file_path}/Wk{lead}_rmse_vals.pkl'\n",
    "    file_mae_save = f'{file_path}/Wk{lead}_mae_vals.pkl'\n",
    "    complete_rmse = f'{file_path}/Wk{lead}_rmse_complete.pkl'\n",
    "    complete_mae = f'{file_path}/Wk{lead}_mae_complete.pkl'\n",
    "    \n",
    "    os.system(f'mkdir -p {file_path}')\n",
    "\n",
    "    rmse_output, mae_output, rmse_complete, mae_complete = putils.return_rmse_and_mae_pickle_files(file_rmse_save, file_mae_save, complete_mae, complete_rmse)\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "    leads = [6,13,20,27,34]\n",
    "\n",
    "    obs_final_train,obs_final_validation,obs_final_testing,EX_list = return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num)\n",
    "\n",
    "    obs_final_testing_arr = obs_final_testing[putils.xarray_varname(obs_final_testing)].to_numpy()\n",
    "    '''These are the actual experiment names below'''\n",
    "    BC,OBS,HYB = verifications.return_experiment_colors_and_names()\n",
    "\n",
    "    '''Loop through each model checkpoint'''\n",
    "    checkpt_dir = f'checkpoints/{region_name}/Wk{lead}'\n",
    "    file_list = sorted(glob(f'{checkpt_dir}/*regular*'))\n",
    "    file_list = [i for i in file_list if '.' not in i] \n",
    "    file_list = [i for i in file_list if '/checkpoint' not in i]\n",
    "    file_list = [i for i in file_list if 'ECMWF' not in i] #don't do ECMWF. We haven't coded it with different varabiles yet\n",
    "     file_list = [i for i in file_list if 'ERA5' not in i] #don't do ERA5. We haven't coded it with different varabiles yet\n",
    "    file_list = [i for i in file_list if '2012' not in i]\n",
    "\n",
    "    ##########################################################################\n",
    "    if test_year == 2019:\n",
    "        file_list = [i for i in file_list if '2012' not in i]\n",
    "    else:\n",
    "        file_list = [i for i in file_list if str(pd.to_datetime(test_end).year) in i]\n",
    "\n",
    "    '''Experiment saved inputs'''\n",
    "    exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "    exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "    exps = [i for i in exps if 'mean' not in i]\n",
    "\n",
    "    print(f'Working on file list {file_list}')\n",
    "\n",
    "    #For masking\n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "    mask_zero = RZSM_validation_obs.squeeze()\n",
    "    \n",
    "    for file in file_list:\n",
    "        print(f'Working on file experiment {file}')\n",
    "        # break\n",
    "        try:\n",
    "            testing_input,ex_num = return_the_experiment_input(exps,file,lead)\n",
    "            channel_list = f.load_channel_list_permutation(ex_num, lead)\n",
    "            dont_continue=False\n",
    "        except IndexError:\n",
    "            dont_continue = True\n",
    "\n",
    "        try:\n",
    "            model = load_model(file,compile=False)\n",
    "            dont_continue = False\n",
    "        except OSError:\n",
    "            dont_continue = True # No model information found\n",
    "            \n",
    "        if dont_continue:\n",
    "            pass\n",
    "        else:\n",
    "            if (len(channel_list) == testing_input.shape[-1]):\n",
    "\n",
    "                model_name = file.split('/')[-1].split('_testing')[0]\n",
    "                \n",
    "                #These will contain the average MAE and RMSE across CONUS to plot\n",
    "                save_for_plot_mae = {}\n",
    "                save_for_plot_rmse = {}\n",
    "\n",
    "                continue_ = False\n",
    "                \n",
    "                for idx,channel in enumerate(channel_list):\n",
    "                    # break\n",
    "                    '''Check if we have already completed it'''\n",
    "                    unit_test = putils.check_if_already_completed_permuatation(rmse_complete, mae_complete, ex_num,  OBS, HYB, channel, model_name)\n",
    "\n",
    "                    '''Check if there is a .csv file already saved'''\n",
    "                    \n",
    "                    if unit_test == 'Not-Completed':\n",
    "                        # break\n",
    "                        print(f'\\nPermutating channel {channel}\\n')\n",
    "    \n",
    "                        new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(testing_input,channel,idx,file,region_name,day_num,test_year,lead)\n",
    "    \n",
    "                        try:\n",
    "                            prediction_ = np.array(model.predict(new_input_with_noise))\n",
    "                            prediction_.shape\n",
    "                            \n",
    "                            '''Just choose the very last prediction made'''\n",
    "                            prediction_ = prediction_[-1,:,:,:,0]\n",
    "        \n",
    "                            yhat = verifications.reverse_min_max_scaling_for_permutations(prediction_,region_name,day_num,'GEFSv12',test_year,'soilw_bgrnd')\n",
    "            \n",
    "                            yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat)\n",
    "                            yhat = np.where(mask_zero == 0, np.nan, yhat)\n",
    "                            # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "                            yhat = np.reshape(yhat,(yhat.shape[0]//11,11,yhat.shape[1],yhat.shape[2]))\n",
    "                \n",
    "                            RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  yhat),axis=(0,1))\n",
    "                \n",
    "                            RZSM_rmse = np.nanmean((obs_final_testing_arr -  yhat)**2,axis=(0,1))\n",
    "    \n",
    "                            save_for_plot_rmse[channel] = np.nanmean(RZSM_rmse)\n",
    "                            save_for_plot_mae[channel] = np.nanmean(RZSM_mae)\n",
    "                        \n",
    "                            '''Now add to the dictionary for RMSE'''\n",
    "                            if ex_num in OBS:\n",
    "                                try:\n",
    "                                    # if output['OBS'][channel]['Value']\n",
    "                                    rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "                                    rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "                                    rmse_complete['OBS'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "                                    rmse_complete = putils.append_to_complete_list(rmse_complete, model_name, channel, 'OBS')\n",
    "                                    \n",
    "                            elif ex_num in HYB:\n",
    "                                try:\n",
    "                                    rmse_output['HYB'][channel]['Value'] = rmse_output['HYB'][channel]['Value'] + RZSM_rmse\n",
    "                                    rmse_output['HYB'][channel]['Num_experiments'] = rmse_output['HYB'][channel]['Num_experiments'] + 1\n",
    "                                    rmse_complete['HYB'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    rmse_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "                                    rmse_complete = putils.append_to_complete_list(rmse_complete, model_name, channel, 'HYB')\n",
    "\n",
    "                                    \n",
    "                            '''Now add to the dictionary for MAE only'''\n",
    "                            if ex_num in OBS:\n",
    "                                try:\n",
    "                                    mae_output['OBS'][channel]['Value'] = mae_output['OBS'][channel]['Value'] + RZSM_mae\n",
    "                                    mae_output['OBS'][channel]['Num_experiments'] = mae_output['OBS'][channel]['Num_experiments'] + 1\n",
    "                                    mae_complete['OBS'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    mae_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "                                    mae_complete = putils.append_to_complete_list(mae_complete, model_name, channel, 'OBS')\n",
    "\n",
    "                            elif ex_num in HYB:\n",
    "                                try:\n",
    "                                    mae_output['HYB'][channel]['Value'] = mae_output['HYB'][channel]['Value'] + RZSM_mae\n",
    "                                    mae_output['HYB'][channel]['Num_experiments'] = mae_output['HYB'][channel]['Num_experiments'] + 1\n",
    "                                    mae_complete['HYB'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    mae_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "                                    mae_complete = putils.append_to_complete_list(mae_complete, model_name, channel, 'HYB')\n",
    "\n",
    "    \n",
    "                            continue_ = True\n",
    "                        \n",
    "                        except ValueError:\n",
    "                            continue_ = False\n",
    "                            pass\n",
    "                        \n",
    "                if continue_:\n",
    "                    plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name)\n",
    "                    \n",
    "            \n",
    "        '''Saves after each file is completed'''\n",
    "        with open(file_rmse_save, 'wb') as file:\n",
    "            pickle.dump(rmse_output, file)\n",
    "    \n",
    "        with open(file_mae_save, 'wb') as file:\n",
    "            pickle.dump(mae_output, file)\n",
    "        \n",
    "        with open(complete_rmse, 'wb') as file:\n",
    "            pickle.dump(rmse_complete, file)\n",
    "    \n",
    "        with open(complete_mae, 'wb') as file:\n",
    "            pickle.dump(mae_complete, file)\n",
    "\n",
    "    return(f'Completed week {lead}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2452bf0-15a8-40a6-97e1-0bf70c0d5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Permutation test'''\n",
    "# for lead in [1,2,3,4]:\n",
    "#     permutation_test_by_lead_save_MAE_RMSE(lead=lead, test_year=2019) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692838dc-5c79-4d45-9d8d-6e46ab2dbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_save_csv(lead,experiment,train,val,test):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/Wk_{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "    \n",
    "    day_num = (lead*7)-1\n",
    "    \n",
    "    num_lags_obs_RZSM=experiment['num_lags_obs_RZSM']\n",
    "    include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax']\n",
    "    include_reforecast_or_not=experiment['include_reforecast_or_not']\n",
    "    addtl_experiment = experiment['addtl_experiment']\n",
    "    experiment_test = experiment['experiment_test']\n",
    "\n",
    "    experiment_name = CE.return_experiment_name(include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test)\n",
    "    experiment_name_out = f'{experiment_name}_RZSM'\n",
    "    \n",
    "    save_csv_path = f'{save_permutation_figures}/{experiment_name_out}.csv'    \n",
    "    obs_final_testing_arr = test.RZSM.values\n",
    "\n",
    "    obs_final_testing_arr = np.reshape(obs_final_testing_arr,(1144,48,96))\n",
    "    \n",
    "    ref_data = f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/{experiment_name_out}_testing_input.npy'\n",
    "    \n",
    "    if os.path.exists('redoooo.nc'):\n",
    "    # if os.path.exists(save_csv_path):\n",
    "        print(f'Already saved the csv file into path {save_csv_path}')\n",
    "    elif os.path.exists(ref_data):\n",
    "        reg_name = f'{experiment_name_out.split(\"_\")[0]}_regular_RZSM'\n",
    "\n",
    "        print(f'\\n\\n Starting permutation test with experiment {reg_name} \\n\\n')\n",
    "        \n",
    "        reforecast_testing_input = np.load(ref_data)\n",
    "        \n",
    "        #Load model \n",
    "        try:\n",
    "            model = load_model(f'checkpoints/{region_name}/Wk{lead}/Wk{lead}_{reg_name}',compile=False) #don't need the custom loss function for predictions\n",
    "            channel_list = f.load_channel_list_permutation(experiment_name_out, lead)\n",
    "        except OSError:\n",
    "            model_name = f'checkpoints/{region_name}/Wk{lead}/Wk{lead}_{experiment_name_out}'\n",
    "            model = load_model(model_name,compile=False) #don't need the custom loss function for predictions\n",
    "            channel_list = f.load_channel_list_permutation(experiment_name_out, lead)\n",
    "\n",
    "        \n",
    "        out_dict = {}\n",
    "        for idx,channel in enumerate(channel_list):\n",
    "            print(f'\\nPermutating channel {channel}\\n')\n",
    "            # break\n",
    "            '''Take the input, reverse back to anomaly, find mean and std, add gaussian noise according to the mean and std, get min max, then rescale to min max'''\n",
    "            new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(reforecast_testing_input,channel,idx,'GEFSv12',region_name,day_num,test_year,lead)\n",
    "            #The output is now min max scaled\n",
    "            new_input_with_noise = tf.convert_to_tensor(new_input_with_noise,dtype=tf.float32)\n",
    "            pred_ = np.array(model.predict(new_input_with_noise))\n",
    "            '''Just choose the very last prediction made'''\n",
    "            pred_ = pred_[-1,:,:,:,0]\n",
    "\n",
    "            #Reverse the min max scaling from prediction back to anomaly\n",
    "            # pred_ = pred_ *(var_noise_max-var_noise_min)+var_noise_min \n",
    "            pred_ = verifications.reverse_min_max_scaling(pred_, region_name, day_num, 'GEFSv12',2019) #We only want the last channel\n",
    "            '''rescale back to anomaly with the min and max from the noisy dataset'''\n",
    "            #Now data is in the anomaly form\n",
    "\n",
    "            \n",
    "            pred_ = np.where(np.isnan(reforecast_nan),np.nan,pred_)\n",
    "            pred_ = np.where(np.isnan(obs_final_testing_arr), np.nan, pred_) #observation mask\n",
    "            # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "            # pred_ = np.reshape(pred_,(pred_.shape[0]//11,11,pred_.shape[1],pred_.shape[2]))\n",
    "\n",
    "            RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  pred_))\n",
    "            # RZSM_rmse = np.nanmean((obs_final_testing_arr -  prediction_)**2)\n",
    "\n",
    "            out_dict[f'{channel}'] = np.nanmean(RZSM_mae)\n",
    "            print(f'RZSM MAE of channel {channel} is {np.nanmean(RZSM_mae)}')\n",
    "            contn = True\n",
    "            # except ValueError:\n",
    "            #     print('We could not complete this file, there is something wrong with the shape of the inputs''')\n",
    "            #     contn = False\n",
    "            #     break\n",
    "                \n",
    "        if contn:\n",
    "            csv_dict = {}\n",
    "            #Experiment_name\n",
    "            # Remove 'E', 'X', and '_RZSM' from the string\n",
    "            result_string = experiment_name_out.replace('E', '').replace('X', '').replace('_RZSM', '')\n",
    "        \n",
    "            csv_dict['Experiment'] = int(result_string)\n",
    "            for i in list(out_dict.keys()):\n",
    "                csv_dict[i] = out_dict[i]\n",
    "                \n",
    "            #Write to csv file for later processing\n",
    "            with open(save_csv_path, 'w') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=list(csv_dict.keys()))\n",
    "                writer.writeheader()\n",
    "                writer.writerows([csv_dict])\n",
    "    \n",
    "        # create_plot_permutation(setup_plot_permutation(lead,out_dict,RZSM_or_Tmax_or_both),lead,experiment_name_out,save_permutation_figures,max_RZSM_value,max_tmax_value,RZSM_or_Tmax_or_both)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee88533-eba1-43c1-84af-4617b4cd46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #Testing the input layer for issues\n",
    "#         for experiment in range(0,13):\n",
    "#             print(f'Loading EX{experiment}')\n",
    "#             model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_EX{experiment}',compile=False) #don't need the custom loss function for predictions\n",
    "\n",
    "#             summary_str = None\n",
    "#             with StringIO() as buffer, redirect_stdout(buffer):\n",
    "#                 model.summary()\n",
    "#                 summary_str = buffer.getvalue()\n",
    "\n",
    "#             # Print the head of the summary\n",
    "#             head_lines = 5  # Adjust the number of lines you want to print\n",
    "#             print(\"\\n\".join(summary_str.splitlines()[:head_lines]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb724be1-9990-43e1-b331-d0182b8858a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data, setup experiments to permutate\n",
    "\n",
    "all_exps = [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX12,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "obs_final_train,obs_final_validation,obs_final_testing = verifications.open_obs_for_verification(region_name, [6,13,20,27],train_start, train_end, val_start, val_end, test_start, test_end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1cac9-02dd-43d5-82ef-47dc34a4d36f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_exps = [EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "\n",
    "redo_2thru_4 = [EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,]\n",
    "sub_exps = [EX29]\n",
    "for lead in [1,2,3,4]:\n",
    "    day_num = (lead*7)-1\n",
    "    train = obs_final_train.sel(L=day_num)\n",
    "    val = obs_final_validation.sel(L=day_num)\n",
    "    test = obs_final_testing.sel(L=day_num)\n",
    "    # for experiment in all_exps:\n",
    "    for experiment in sub_exps:\n",
    "        permutation_test_save_csv(lead,experiment,train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574232f-cc94-4169-b760-da2d01d1ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def permutation_test_by_lead_by_experiment(lead, test_year, experiment_number):\n",
    "#     #test \n",
    "#     # lead = 1\n",
    "#     # test_year=2019\n",
    "    \n",
    "#     day_num = (lead*7) -1\n",
    "\n",
    "#     try:\n",
    "#         with open(file_rmse_save, \"rb\") as f:\n",
    "#             rmse_output = pickle.load(f)\n",
    "    \n",
    "#         with open(file_mae_save, \"rb\") as f:\n",
    "#             mae_output = pickle.load(f)    \n",
    "#     except FileNotFoundError:\n",
    "#         rmse_output = {}\n",
    "#         rmse_output['OBS'] = {}\n",
    "#         rmse_output['HYB'] = {}\n",
    "    \n",
    "#         mae_output = {}\n",
    "#         mae_output['OBS'] = {}\n",
    "#         mae_output['HYB'] = {}\n",
    "\n",
    "    \n",
    "#     leads = [6,13,20,27,34]\n",
    "\n",
    "#     obs_final_train,obs_final_validation,obs_final_testing,EX_list = return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num)\n",
    "\n",
    "#     obs_final_testing_arr = obs_final_testing[putils.xarray_varname(obs_final_testing)].to_numpy()\n",
    "#     '''These are the actual experiment names below'''\n",
    "#     BC,OBS,HYB = verifications.return_experiment_colors_and_names()\n",
    "\n",
    "\n",
    "#     '''Loop through each model checkpoint'''\n",
    "#     checkpt_dir = f'checkpoints/{region_name}/Wk{lead}'\n",
    "#     file_list = sorted(glob(f'{checkpt_dir}/*{experiment_number}_regular*'))\n",
    "  \n",
    "    \n",
    "#     if test_year == 2019:\n",
    "#         file_list = [i for i in file_list if '2012' not in i]\n",
    "#     else:\n",
    "#         file_list = [i for i in file_list if str(pd.to_datetime(test_end).year) in i]\n",
    "\n",
    "#     '''Experiment saved inputs'''\n",
    "#     exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "#     exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "#     exps = [i for i in exps if 'mean' not in i]\n",
    "\n",
    "#     print(f'Working on file list {file_list}')\n",
    "\n",
    "#     #For masking\n",
    "#     RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "#     mask_zero = RZSM_validation_obs.squeeze()\n",
    "    \n",
    "#     for file in file_list:\n",
    "#         print(f'Working on file experiment {file}')\n",
    "#         try:\n",
    "#             testing_input,ex_num = return_the_experiment_input(exps,file,lead)\n",
    "#             channel_list = f.load_channel_list_permutation(ex_num, lead)\n",
    "#             dont_continue=False\n",
    "            \n",
    "#         except IndexError:\n",
    "#             dont_continue = True\n",
    "\n",
    "#         if dont_continue:\n",
    "#             pass\n",
    "#         else:\n",
    "#             if len(channel_list) == testing_input.shape[-1]:\n",
    "#                 model = load_model(file,compile=False) \n",
    "#                 model_name = file.split('/')[-1].split('_testing')[0]\n",
    "                \n",
    "#                 #These will contain the average MAE and RMSE across CONUS to plot\n",
    "#                 save_for_plot_mae = {}\n",
    "#                 save_for_plot_rmse = {}\n",
    "                \n",
    "#                 for idx,channel in enumerate(channel_list):\n",
    "#                     '''Now add to the dictionary'''\n",
    "#                     if ex_num in OBS:\n",
    "#                         try:\n",
    "#                             rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "#                             rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                         except KeyError:\n",
    "#                             rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "#                     elif ex_num in HYB:\n",
    "                        \n",
    "                \n",
    "#                     # idx,channel = 6, 'pwat_obs_lag-1'\n",
    "#                     # idx, channel = 0, 'RZSM_obs_lag-1'\n",
    "                    \n",
    "#                     new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(testing_input,channel,idx,file,region_name,day_num,test_year,lead)\n",
    "\n",
    "#                     try:\n",
    "#                         prediction_ = np.array(model.predict(new_input_with_noise))\n",
    "#                         prediction_.shape\n",
    "                        \n",
    "#                         '''Just choose the very last prediction made'''\n",
    "#                         prediction_ = prediction_[-1,:,:,:,0]\n",
    "        \n",
    "#                         yhat = verifications.reverse_min_max_scaling_for_permutations(prediction_,region_name,day_num,'GEFSv12',test_year,'soilw_bgrnd')\n",
    "        \n",
    "#                         yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat)\n",
    "#                         yhat = np.where(mask_zero == 0, np.nan, yhat)\n",
    "#                         # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "#                         yhat = np.reshape(yhat,(yhat.shape[0]//11,11,yhat.shape[1],yhat.shape[2]))\n",
    "            \n",
    "#                         RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  yhat),axis=(0,1))\n",
    "            \n",
    "#                         RZSM_rmse = np.nanmean((obs_final_testing_arr -  yhat)**2,axis=(0,1))\n",
    "    \n",
    "#                         save_for_plot_rmse[channel] = np.nanmean(RZSM_rmse)\n",
    "#                         save_for_plot_mae[channel] = np.nanmean(RZSM_mae)\n",
    "                        \n",
    "#                         '''Now add to the dictionary'''\n",
    "#                         if ex_num in OBS:\n",
    "#                             try:\n",
    "#                                 rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "#                                 rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "#                         elif ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 rmse_output['HYB'][channel]['Value'] = rmse_output['HYB'][channel]['Value'] + RZSM_rmse\n",
    "#                                 rmse_output['HYB'][channel]['Num_experiments'] = rmse_output['HYB'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 rmse_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "    \n",
    "    \n",
    "#                         '''Now add to the dictionary'''\n",
    "#                         if ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 mae_output['OBS'][channel]['Value'] = mae_output['OBS'][channel]['Value'] + RZSM_mae\n",
    "#                                 mae_output['OBS'][channel]['Num_experiments'] = mae_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 mae_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "#                         elif ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 mae_output['HYB'][channel]['Value'] = mae_output['HYB'][channel]['Value'] + RZSM_mae\n",
    "#                                 mae_output['HYB'][channel]['Num_experiments'] = mae_output['HYB'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 mae_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "\n",
    "#                         continue_ = True\n",
    "                    \n",
    "            \n",
    "                    \n",
    "#                     except ValueError:\n",
    "#                         continue_ = False\n",
    "#                         pass\n",
    "                        \n",
    "#                 if continue_:\n",
    "#                     plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name)\n",
    "                    \n",
    "\n",
    "#     return(f'Completed week {lead}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu_new]",
   "language": "python",
   "name": "conda-env-tf212gpu_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
